{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=32\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensor to a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "torch.Size([60, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([45, 1, 32, 32, 32])\n",
      "validation torch.Size([15, 1, 32, 32, 32])\n",
      "train_target torch.Size([45, 32, 32, 32])\n",
      "validation_target torch.Size([15, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target,batch_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:, 0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, 1, grid_size, grid_size, grid_size).float())\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, 1, grid_size, grid_size, grid_size).float())\n",
    "\n",
    "labels_train = preprocessed_input_train_target.float()\n",
    "labels_validation = preprocessed_input_validation_target.float()\n",
    "\n",
    "print('train', train_input.shape)\n",
    "print('validation', validation_input.shape)\n",
    "print('train_target', labels_train.shape)\n",
    "print('validation_target', labels_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n",
      "Epoch Number :  0\n",
      "\t Training accuracy:  64.96602376302083\n",
      "\t Validation accuracy  65.4388427734375\n",
      "\t Epoch Loss  2.0841779708862305\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  79.36876085069444\n",
      "\t Validation accuracy  80.45918782552083\n",
      "\t Epoch Loss  2.043081760406494\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  85.40181477864583\n",
      "\t Validation accuracy  86.31917317708333\n",
      "\t Epoch Loss  1.9918403625488281\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  86.71773274739583\n",
      "\t Validation accuracy  87.52583821614583\n",
      "\t Epoch Loss  1.9349089860916138\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  88.53719075520833\n",
      "\t Validation accuracy  89.25435384114583\n",
      "\t Epoch Loss  1.881852149963379\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  90.76571994357639\n",
      "\t Validation accuracy  91.4459228515625\n",
      "\t Epoch Loss  1.8280900716781616\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  92.5506591796875\n",
      "\t Validation accuracy  93.24849446614583\n",
      "\t Epoch Loss  1.7747764587402344\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  93.93751356336806\n",
      "\t Validation accuracy  94.622802734375\n",
      "\t Epoch Loss  1.7307281494140625\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  94.62897406684027\n",
      "\t Validation accuracy  95.31453450520833\n",
      "\t Epoch Loss  1.69358491897583\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  94.59221733940973\n",
      "\t Validation accuracy  95.26896158854167\n",
      "\t Epoch Loss  1.6636093854904175\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  94.58875868055556\n",
      "\t Validation accuracy  95.25777180989583\n",
      "\t Epoch Loss  1.6377534866333008\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  94.69082302517361\n",
      "\t Validation accuracy  95.35420735677083\n",
      "\t Epoch Loss  1.6132278442382812\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  94.90254720052083\n",
      "\t Validation accuracy  95.55318196614583\n",
      "\t Epoch Loss  1.5925096273422241\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  95.48563639322917\n",
      "\t Validation accuracy  96.13362630208333\n",
      "\t Epoch Loss  1.5732219219207764\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  96.029052734375\n",
      "\t Validation accuracy  96.51163736979167\n",
      "\t Epoch Loss  1.5467779636383057\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  96.41411675347223\n",
      "\t Validation accuracy  96.6937255859375\n",
      "\t Epoch Loss  1.5280871391296387\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  96.44083658854167\n",
      "\t Validation accuracy  96.71915690104167\n",
      "\t Epoch Loss  1.5063869953155518\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  96.5008544921875\n",
      "\t Validation accuracy  96.82820638020833\n",
      "\t Epoch Loss  1.492129921913147\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  96.51699490017361\n",
      "\t Validation accuracy  96.89798990885417\n",
      "\t Epoch Loss  1.4771695137023926\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  96.52703179253473\n",
      "\t Validation accuracy  96.9244384765625\n",
      "\t Epoch Loss  1.466470718383789\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  96.55531141493056\n",
      "\t Validation accuracy  96.96268717447917\n",
      "\t Epoch Loss  1.458236813545227\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  96.58440483940973\n",
      "\t Validation accuracy  97.01090494791667\n",
      "\t Epoch Loss  1.4539070129394531\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  96.62183973524306\n",
      "\t Validation accuracy  97.05851236979167\n",
      "\t Epoch Loss  1.4508554935455322\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  96.66015625\n",
      "\t Validation accuracy  97.09920247395833\n",
      "\t Epoch Loss  1.4459519386291504\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  96.69908311631944\n",
      "\t Validation accuracy  97.13155110677083\n",
      "\t Epoch Loss  1.4416782855987549\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  96.74323187934027\n",
      "\t Validation accuracy  97.171630859375\n",
      "\t Epoch Loss  1.4339313507080078\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  96.802978515625\n",
      "\t Validation accuracy  97.22757975260417\n",
      "\t Epoch Loss  1.4235162734985352\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  96.87018500434027\n",
      "\t Validation accuracy  97.27986653645833\n",
      "\t Epoch Loss  1.4181783199310303\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  96.91067165798611\n",
      "\t Validation accuracy  97.31038411458333\n",
      "\t Epoch Loss  1.412921667098999\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  96.95271809895833\n",
      "\t Validation accuracy  97.34090169270833\n",
      "\t Epoch Loss  1.4088988304138184\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  96.99937608506944\n",
      "\t Validation accuracy  97.3724365234375\n",
      "\t Epoch Loss  1.4063853025436401\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  97.03769259982639\n",
      "\t Validation accuracy  97.388916015625\n",
      "\t Epoch Loss  1.4049715995788574\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  97.07784016927083\n",
      "\t Validation accuracy  97.412109375\n",
      "\t Epoch Loss  1.4031392335891724\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  97.12510850694444\n",
      "\t Validation accuracy  97.45402018229167\n",
      "\t Epoch Loss  1.4006153345108032\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  97.16647677951389\n",
      "\t Validation accuracy  97.49186197916667\n",
      "\t Epoch Loss  1.3965718746185303\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  97.21157497829861\n",
      "\t Validation accuracy  97.5341796875\n",
      "\t Epoch Loss  1.3939785957336426\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  97.25321451822917\n",
      "\t Validation accuracy  97.56876627604167\n",
      "\t Epoch Loss  1.3909367322921753\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  97.28847927517361\n",
      "\t Validation accuracy  97.60640462239583\n",
      "\t Epoch Loss  1.3813103437423706\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  97.32442220052083\n",
      "\t Validation accuracy  97.63346354166667\n",
      "\t Epoch Loss  1.3750934600830078\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  97.36178927951389\n",
      "\t Validation accuracy  97.6556396484375\n",
      "\t Epoch Loss  1.3713924884796143\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  97.39603678385417\n",
      "\t Validation accuracy  97.67659505208333\n",
      "\t Epoch Loss  1.367941975593567\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  97.41739908854167\n",
      "\t Validation accuracy  97.69144694010417\n",
      "\t Epoch Loss  1.3637757301330566\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  97.45571560329861\n",
      "\t Validation accuracy  97.71158854166667\n",
      "\t Epoch Loss  1.3609225749969482\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  97.48867458767361\n",
      "\t Validation accuracy  97.70751953125\n",
      "\t Epoch Loss  1.3587990999221802\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  97.52468532986111\n",
      "\t Validation accuracy  97.71586100260417\n",
      "\t Epoch Loss  1.3574657440185547\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  97.54075792100694\n",
      "\t Validation accuracy  97.72359212239583\n",
      "\t Epoch Loss  1.3563246726989746\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  97.55784776475694\n",
      "\t Validation accuracy  97.73335774739583\n",
      "\t Epoch Loss  1.354883074760437\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  97.60009765625\n",
      "\t Validation accuracy  97.7264404296875\n",
      "\t Epoch Loss  1.3534010648727417\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  97.64662000868056\n",
      "\t Validation accuracy  97.72725423177083\n",
      "\t Epoch Loss  1.3501744270324707\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  97.70107693142361\n",
      "\t Validation accuracy  97.65380859375\n",
      "\t Epoch Loss  1.347578525543213\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  97.68839518229167\n",
      "\t Validation accuracy  97.8167724609375\n",
      "\t Epoch Loss  1.3471848964691162\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  97.69646538628473\n",
      "\t Validation accuracy  97.85054524739583\n",
      "\t Epoch Loss  1.344656229019165\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  97.71721733940973\n",
      "\t Validation accuracy  97.8314208984375\n",
      "\t Epoch Loss  1.3406479358673096\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  97.71226671006944\n",
      "\t Validation accuracy  97.8485107421875\n",
      "\t Epoch Loss  1.3320114612579346\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  97.71531846788194\n",
      "\t Validation accuracy  97.7362060546875\n",
      "\t Epoch Loss  1.3279962539672852\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  97.69463433159723\n",
      "\t Validation accuracy  97.77852376302083\n",
      "\t Epoch Loss  1.32431960105896\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  97.81704372829861\n",
      "\t Validation accuracy  97.82755533854167\n",
      "\t Epoch Loss  1.3213989734649658\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  97.76665581597223\n",
      "\t Validation accuracy  97.87638346354167\n",
      "\t Epoch Loss  1.318263292312622\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  97.80131022135417\n",
      "\t Validation accuracy  97.96366373697917\n",
      "\t Epoch Loss  1.3146947622299194\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  97.83738878038194\n",
      "\t Validation accuracy  98.04239908854167\n",
      "\t Epoch Loss  1.312155842781067\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  97.87692599826389\n",
      "\t Validation accuracy  97.96244303385417\n",
      "\t Epoch Loss  1.3100457191467285\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  97.91022406684027\n",
      "\t Validation accuracy  97.97749837239583\n",
      "\t Epoch Loss  1.3086426258087158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  62\n",
      "\t Training accuracy:  97.91978624131944\n",
      "\t Validation accuracy  98.05419921875\n",
      "\t Epoch Loss  1.307877540588379\n",
      "Epoch Number :  63\n",
      "\t Training accuracy:  97.86329481336806\n",
      "\t Validation accuracy  97.9876708984375\n",
      "\t Epoch Loss  1.3074092864990234\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  97.92826334635417\n",
      "\t Validation accuracy  98.00394694010417\n",
      "\t Epoch Loss  1.3065658807754517\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  97.98848470052083\n",
      "\t Validation accuracy  97.989501953125\n",
      "\t Epoch Loss  1.3049371242523193\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  97.93531629774306\n",
      "\t Validation accuracy  98.08573404947917\n",
      "\t Epoch Loss  1.3049880266189575\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  97.83426920572917\n",
      "\t Validation accuracy  97.98929850260417\n",
      "\t Epoch Loss  1.3031405210494995\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  98.02842881944444\n",
      "\t Validation accuracy  98.03263346354167\n",
      "\t Epoch Loss  1.300304651260376\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  97.90961371527777\n",
      "\t Validation accuracy  98.11991373697917\n",
      "\t Epoch Loss  1.2979623079299927\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  98.00537109375\n",
      "\t Validation accuracy  98.02286783854167\n",
      "\t Epoch Loss  1.296026587486267\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  97.97437879774306\n",
      "\t Validation accuracy  98.1744384765625\n",
      "\t Epoch Loss  1.2946486473083496\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  98.00143771701389\n",
      "\t Validation accuracy  98.14982096354167\n",
      "\t Epoch Loss  1.2936574220657349\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  98.079833984375\n",
      "\t Validation accuracy  97.97200520833333\n",
      "\t Epoch Loss  1.2885652780532837\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  97.94033474392361\n",
      "\t Validation accuracy  98.1365966796875\n",
      "\t Epoch Loss  1.2805986404418945\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  98.04796006944444\n",
      "\t Validation accuracy  98.123779296875\n",
      "\t Epoch Loss  1.2777788639068604\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  97.99818250868056\n",
      "\t Validation accuracy  98.138427734375\n",
      "\t Epoch Loss  1.2745370864868164\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  98.03826226128473\n",
      "\t Validation accuracy  98.187255859375\n",
      "\t Epoch Loss  1.272889494895935\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  98.11550564236111\n",
      "\t Validation accuracy  98.18705240885417\n",
      "\t Epoch Loss  1.271862268447876\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  98.04918077256944\n",
      "\t Validation accuracy  98.216552734375\n",
      "\t Epoch Loss  1.2699064016342163\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  98.06830512152777\n",
      "\t Validation accuracy  98.22347005208333\n",
      "\t Epoch Loss  1.2661107778549194\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  98.13503689236111\n",
      "\t Validation accuracy  98.1988525390625\n",
      "\t Epoch Loss  1.2640477418899536\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  98.13157823350694\n",
      "\t Validation accuracy  98.18705240885417\n",
      "\t Epoch Loss  1.2626341581344604\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  98.08505588107639\n",
      "\t Validation accuracy  98.18929036458333\n",
      "\t Epoch Loss  1.2614954710006714\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  98.16433376736111\n",
      "\t Validation accuracy  98.15165201822917\n",
      "\t Epoch Loss  1.2611262798309326\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  98.14860026041667\n",
      "\t Validation accuracy  98.23649088541667\n",
      "\t Epoch Loss  1.2606987953186035\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  98.09943305121527\n",
      "\t Validation accuracy  98.22367350260417\n",
      "\t Epoch Loss  1.2600905895233154\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  98.3056640625\n",
      "\t Validation accuracy  98.08980305989583\n",
      "\t Epoch Loss  1.25962233543396\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  98.15233018663194\n",
      "\t Validation accuracy  98.19091796875\n",
      "\t Epoch Loss  1.2606594562530518\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  98.16236707899306\n",
      "\t Validation accuracy  98.15511067708333\n",
      "\t Epoch Loss  1.2583025693893433\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  98.16962348090277\n",
      "\t Validation accuracy  98.18522135416667\n",
      "\t Epoch Loss  1.2575492858886719\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  98.21906195746527\n",
      "\t Validation accuracy  98.1982421875\n",
      "\t Epoch Loss  1.2557493448257446\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  98.22842068142361\n",
      "\t Validation accuracy  98.20658365885417\n",
      "\t Epoch Loss  1.2539918422698975\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  98.28904893663194\n",
      "\t Validation accuracy  98.17342122395833\n",
      "\t Epoch Loss  1.250610113143921\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  98.24022081163194\n",
      "\t Validation accuracy  98.23832194010417\n",
      "\t Epoch Loss  1.2485578060150146\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  98.31305609809027\n",
      "\t Validation accuracy  98.22102864583333\n",
      "\t Epoch Loss  1.2468446493148804\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  98.29969618055556\n",
      "\t Validation accuracy  98.22977701822917\n",
      "\t Epoch Loss  1.2453709840774536\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  98.33089192708333\n",
      "\t Validation accuracy  98.27901204427083\n",
      "\t Epoch Loss  1.2435517311096191\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  98.33218044704861\n",
      "\t Validation accuracy  98.233642578125\n",
      "\t Epoch Loss  1.2412760257720947\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  98.3184814453125\n",
      "\t Validation accuracy  98.26700846354167\n",
      "\t Epoch Loss  1.237848162651062\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  98.39714898003473\n",
      "\t Validation accuracy  98.238525390625\n",
      "\t Epoch Loss  1.2335138320922852\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  98.39070638020833\n",
      "\t Validation accuracy  98.24381510416667\n",
      "\t Epoch Loss  1.2295269966125488\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  98.41057671440973\n",
      "\t Validation accuracy  98.28206380208333\n",
      "\t Epoch Loss  1.2268182039260864\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  98.42922634548611\n",
      "\t Validation accuracy  98.25826009114583\n",
      "\t Epoch Loss  1.225142002105713\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  98.44774034288194\n",
      "\t Validation accuracy  98.28450520833333\n",
      "\t Epoch Loss  1.2234854698181152\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  98.39728461371527\n",
      "\t Validation accuracy  98.29264322916667\n",
      "\t Epoch Loss  1.222090721130371\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  98.59415690104167\n",
      "\t Validation accuracy  98.25480143229167\n",
      "\t Epoch Loss  1.2207242250442505\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  98.44075520833333\n",
      "\t Validation accuracy  98.30912272135417\n",
      "\t Epoch Loss  1.2188351154327393\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  98.50192599826389\n",
      "\t Validation accuracy  98.3074951171875\n",
      "\t Epoch Loss  1.2166799306869507\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  98.60575358072917\n",
      "\t Validation accuracy  98.23221842447917\n",
      "\t Epoch Loss  1.2150083780288696\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  98.47703721788194\n",
      "\t Validation accuracy  98.3038330078125\n",
      "\t Epoch Loss  1.2135897874832153\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  98.560791015625\n",
      "\t Validation accuracy  98.33882649739583\n",
      "\t Epoch Loss  1.2123007774353027\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  98.65926106770833\n",
      "\t Validation accuracy  98.24747721354167\n",
      "\t Epoch Loss  1.2112828493118286\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  98.51725260416667\n",
      "\t Validation accuracy  98.37381998697917\n",
      "\t Epoch Loss  1.2104480266571045\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  98.67390950520833\n",
      "\t Validation accuracy  98.2989501953125\n",
      "\t Epoch Loss  1.2098009586334229\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  98.6431884765625\n",
      "\t Validation accuracy  98.29386393229167\n",
      "\t Epoch Loss  1.2090128660202026\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  98.61368815104167\n",
      "\t Validation accuracy  98.38053385416667\n",
      "\t Epoch Loss  1.2083956003189087\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  98.71229383680556\n",
      "\t Validation accuracy  98.2952880859375\n",
      "\t Epoch Loss  1.207653522491455\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  98.70517306857639\n",
      "\t Validation accuracy  98.31013997395833\n",
      "\t Epoch Loss  1.206979751586914\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  98.66475423177083\n",
      "\t Validation accuracy  98.37890625\n",
      "\t Epoch Loss  1.2058777809143066\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  98.75250922309027\n",
      "\t Validation accuracy  98.262939453125\n",
      "\t Epoch Loss  1.2054332494735718\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  98.85606553819444\n",
      "\t Validation accuracy  98.27799479166667\n",
      "\t Epoch Loss  1.2046575546264648\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  98.65966796875\n",
      "\t Validation accuracy  98.42264811197917\n",
      "\t Epoch Loss  1.2034310102462769\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  98.98403591579861\n",
      "\t Validation accuracy  98.15531412760417\n",
      "\t Epoch Loss  1.2018935680389404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  124\n",
      "\t Training accuracy:  98.72016059027777\n",
      "\t Validation accuracy  98.31298828125\n",
      "\t Epoch Loss  1.2015063762664795\n",
      "Epoch Number :  125\n",
      "\t Training accuracy:  98.80513509114583\n",
      "\t Validation accuracy  98.32255045572917\n",
      "\t Epoch Loss  1.198525071144104\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  98.97650824652777\n",
      "\t Validation accuracy  98.29569498697917\n",
      "\t Epoch Loss  1.1974866390228271\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  98.61436631944444\n",
      "\t Validation accuracy  98.28267415364583\n",
      "\t Epoch Loss  1.196487545967102\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  98.9666748046875\n",
      "\t Validation accuracy  98.28084309895833\n",
      "\t Epoch Loss  1.1956039667129517\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  98.78533257378473\n",
      "\t Validation accuracy  98.31827799479167\n",
      "\t Epoch Loss  1.193110466003418\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  98.82527669270833\n",
      "\t Validation accuracy  98.4637451171875\n",
      "\t Epoch Loss  1.1915693283081055\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  98.93900553385417\n",
      "\t Validation accuracy  98.2958984375\n",
      "\t Epoch Loss  1.1904478073120117\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  98.765869140625\n",
      "\t Validation accuracy  98.40535481770833\n",
      "\t Epoch Loss  1.1871947050094604\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  99.12000868055556\n",
      "\t Validation accuracy  98.26619466145833\n",
      "\t Epoch Loss  1.1845113039016724\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  98.74199761284723\n",
      "\t Validation accuracy  98.41593424479167\n",
      "\t Epoch Loss  1.181596279144287\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  99.11329481336806\n",
      "\t Validation accuracy  98.30668131510417\n",
      "\t Epoch Loss  1.1803078651428223\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  98.75895182291667\n",
      "\t Validation accuracy  98.299560546875\n",
      "\t Epoch Loss  1.1778323650360107\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  99.09030490451389\n",
      "\t Validation accuracy  98.4033203125\n",
      "\t Epoch Loss  1.1758310794830322\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  98.91621907552083\n",
      "\t Validation accuracy  98.36934407552083\n",
      "\t Epoch Loss  1.1742339134216309\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  99.03347439236111\n",
      "\t Validation accuracy  98.41776529947917\n",
      "\t Epoch Loss  1.1724488735198975\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  99.00404188368056\n",
      "\t Validation accuracy  98.26497395833333\n",
      "\t Epoch Loss  1.1707711219787598\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  98.94334581163194\n",
      "\t Validation accuracy  98.4716796875\n",
      "\t Epoch Loss  1.1688292026519775\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  99.0936279296875\n",
      "\t Validation accuracy  98.28633626302083\n",
      "\t Epoch Loss  1.1673284769058228\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  98.89031304253473\n",
      "\t Validation accuracy  98.414306640625\n",
      "\t Epoch Loss  1.165316104888916\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  99.23380533854167\n",
      "\t Validation accuracy  98.33333333333333\n",
      "\t Epoch Loss  1.1638174057006836\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  99.04052734375\n",
      "\t Validation accuracy  98.38114420572917\n",
      "\t Epoch Loss  1.1618682146072388\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  99.16551378038194\n",
      "\t Validation accuracy  98.40861002604167\n",
      "\t Epoch Loss  1.1606322526931763\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  99.19162326388889\n",
      "\t Validation accuracy  98.328857421875\n",
      "\t Epoch Loss  1.1590659618377686\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  99.06663682725694\n",
      "\t Validation accuracy  98.4552001953125\n",
      "\t Epoch Loss  1.1576486825942993\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  99.34719509548611\n",
      "\t Validation accuracy  98.33699544270833\n",
      "\t Epoch Loss  1.1565337181091309\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  99.20484754774306\n",
      "\t Validation accuracy  98.39111328125\n",
      "\t Epoch Loss  1.1552408933639526\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  99.26988389756944\n",
      "\t Validation accuracy  98.4124755859375\n",
      "\t Epoch Loss  1.1542203426361084\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  99.3682861328125\n",
      "\t Validation accuracy  98.34248860677083\n",
      "\t Epoch Loss  1.153242588043213\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  99.09044053819444\n",
      "\t Validation accuracy  98.43729654947917\n",
      "\t Epoch Loss  1.1526954174041748\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  99.44315592447917\n",
      "\t Validation accuracy  98.31685384114583\n",
      "\t Epoch Loss  1.1519498825073242\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  99.29796006944444\n",
      "\t Validation accuracy  98.38948567708333\n",
      "\t Epoch Loss  1.1510531902313232\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  99.34149848090277\n",
      "\t Validation accuracy  98.3953857421875\n",
      "\t Epoch Loss  1.1501277685165405\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  99.48513454861111\n",
      "\t Validation accuracy  98.3526611328125\n",
      "\t Epoch Loss  1.1491386890411377\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  99.3658447265625\n",
      "\t Validation accuracy  98.4228515625\n",
      "\t Epoch Loss  1.1483657360076904\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  99.40327962239583\n",
      "\t Validation accuracy  98.40616861979167\n",
      "\t Epoch Loss  1.1473337411880493\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  99.49334038628473\n",
      "\t Validation accuracy  98.37158203125\n",
      "\t Epoch Loss  1.1463778018951416\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  99.49273003472223\n",
      "\t Validation accuracy  98.41451009114583\n",
      "\t Epoch Loss  1.1454522609710693\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  99.29022894965277\n",
      "\t Validation accuracy  98.46028645833333\n",
      "\t Epoch Loss  1.144263505935669\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  99.56231011284723\n",
      "\t Validation accuracy  98.31441243489583\n",
      "\t Epoch Loss  1.1434063911437988\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  99.5196533203125\n",
      "\t Validation accuracy  98.39701334635417\n",
      "\t Epoch Loss  1.1421903371810913\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  99.41006130642361\n",
      "\t Validation accuracy  98.44991048177083\n",
      "\t Epoch Loss  1.1407179832458496\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  99.41691080729167\n",
      "\t Validation accuracy  98.43912760416667\n",
      "\t Epoch Loss  1.1394624710083008\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  99.63134765625\n",
      "\t Validation accuracy  98.236083984375\n",
      "\t Epoch Loss  1.1385504007339478\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  99.22105577256944\n",
      "\t Validation accuracy  98.52823893229167\n",
      "\t Epoch Loss  1.137786865234375\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  99.58997938368056\n",
      "\t Validation accuracy  98.2830810546875\n",
      "\t Epoch Loss  1.1366146802902222\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  99.49476453993056\n",
      "\t Validation accuracy  98.41267903645833\n",
      "\t Epoch Loss  1.1348083019256592\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  99.48472764756944\n",
      "\t Validation accuracy  98.3203125\n",
      "\t Epoch Loss  1.133404016494751\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  99.61174858940973\n",
      "\t Validation accuracy  98.36385091145833\n",
      "\t Epoch Loss  1.1324800252914429\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  99.4256591796875\n",
      "\t Validation accuracy  98.4222412109375\n",
      "\t Epoch Loss  1.1314743757247925\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  99.70743815104167\n",
      "\t Validation accuracy  98.3587646484375\n",
      "\t Epoch Loss  1.130014181137085\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  99.38761393229167\n",
      "\t Validation accuracy  98.536376953125\n",
      "\t Epoch Loss  1.1286243200302124\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  99.68214246961806\n",
      "\t Validation accuracy  98.31705729166667\n",
      "\t Epoch Loss  1.1276153326034546\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  99.547119140625\n",
      "\t Validation accuracy  98.44014485677083\n",
      "\t Epoch Loss  1.1261835098266602\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  99.60910373263889\n",
      "\t Validation accuracy  98.47086588541667\n",
      "\t Epoch Loss  1.1246113777160645\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  99.60883246527777\n",
      "\t Validation accuracy  98.468017578125\n",
      "\t Epoch Loss  1.1233203411102295\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  99.537353515625\n",
      "\t Validation accuracy  98.50667317708333\n",
      "\t Epoch Loss  1.1218472719192505\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  99.66505262586806\n",
      "\t Validation accuracy  98.41837565104167\n",
      "\t Epoch Loss  1.1195653676986694\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  99.70967610677083\n",
      "\t Validation accuracy  98.404541015625\n",
      "\t Epoch Loss  1.117752194404602\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  99.69089084201389\n",
      "\t Validation accuracy  98.4063720703125\n",
      "\t Epoch Loss  1.1158860921859741\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  99.65996636284723\n",
      "\t Validation accuracy  98.48103841145833\n",
      "\t Epoch Loss  1.1144953966140747\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  99.76392957899306\n",
      "\t Validation accuracy  98.30464680989583\n",
      "\t Epoch Loss  1.1136291027069092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  186\n",
      "\t Training accuracy:  99.47367350260417\n",
      "\t Validation accuracy  98.50056966145833\n",
      "\t Epoch Loss  1.1128132343292236\n",
      "Epoch Number :  187\n",
      "\t Training accuracy:  99.68241373697917\n",
      "\t Validation accuracy  98.1939697265625\n",
      "\t Epoch Loss  1.1121227741241455\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  99.18436686197917\n",
      "\t Validation accuracy  98.48409016927083\n",
      "\t Epoch Loss  1.1115702390670776\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  99.56888834635417\n",
      "\t Validation accuracy  98.20515950520833\n",
      "\t Epoch Loss  1.1121652126312256\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  99.62002224392361\n",
      "\t Validation accuracy  98.48307291666667\n",
      "\t Epoch Loss  1.1123788356781006\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  99.47347005208333\n",
      "\t Validation accuracy  98.47330729166667\n",
      "\t Epoch Loss  1.1103061437606812\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  99.56169976128473\n",
      "\t Validation accuracy  98.32478841145833\n",
      "\t Epoch Loss  1.1086558103561401\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  99.46438259548611\n",
      "\t Validation accuracy  98.47981770833333\n",
      "\t Epoch Loss  1.1086748838424683\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  99.7125244140625\n",
      "\t Validation accuracy  98.37870279947917\n",
      "\t Epoch Loss  1.1063960790634155\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  99.57234700520833\n",
      "\t Validation accuracy  98.55367024739583\n",
      "\t Epoch Loss  1.104663610458374\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  99.76406521267361\n",
      "\t Validation accuracy  98.38033040364583\n",
      "\t Epoch Loss  1.1027356386184692\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  99.73456488715277\n",
      "\t Validation accuracy  98.44868977864583\n",
      "\t Epoch Loss  1.101377010345459\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  99.71998426649306\n",
      "\t Validation accuracy  98.51155598958333\n",
      "\t Epoch Loss  1.099967122077942\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  99.79207356770833\n",
      "\t Validation accuracy  98.287353515625\n",
      "\t Epoch Loss  1.0988249778747559\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  99.72466362847223\n",
      "\t Validation accuracy  98.5040283203125\n",
      "\t Epoch Loss  1.097503662109375\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  99.80787489149306\n",
      "\t Validation accuracy  98.40433756510417\n",
      "\t Epoch Loss  1.0966506004333496\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  99.80211046006944\n",
      "\t Validation accuracy  98.3843994140625\n",
      "\t Epoch Loss  1.095710277557373\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  99.78495279947917\n",
      "\t Validation accuracy  98.49080403645833\n",
      "\t Epoch Loss  1.094700813293457\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  99.82455783420139\n",
      "\t Validation accuracy  98.30220540364583\n",
      "\t Epoch Loss  1.0939905643463135\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  99.81153700086806\n",
      "\t Validation accuracy  98.38236490885417\n",
      "\t Epoch Loss  1.0931169986724854\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  99.79051378038194\n",
      "\t Validation accuracy  98.41471354166667\n",
      "\t Epoch Loss  1.0924022197723389\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  99.82774522569444\n",
      "\t Validation accuracy  98.35225423177083\n",
      "\t Epoch Loss  1.0916082859039307\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  99.82991536458333\n",
      "\t Validation accuracy  98.36263020833333\n",
      "\t Epoch Loss  1.0906442403793335\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  99.83615451388889\n",
      "\t Validation accuracy  98.36344401041667\n",
      "\t Epoch Loss  1.0899564027786255\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  99.86253526475694\n",
      "\t Validation accuracy  98.33251953125\n",
      "\t Epoch Loss  1.089304804801941\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  99.84490288628473\n",
      "\t Validation accuracy  98.30668131510417\n",
      "\t Epoch Loss  1.0886961221694946\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  99.83900282118056\n",
      "\t Validation accuracy  98.36893717447917\n",
      "\t Epoch Loss  1.088181495666504\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  99.86545138888889\n",
      "\t Validation accuracy  98.34615071614583\n",
      "\t Epoch Loss  1.0877279043197632\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  99.87094455295139\n",
      "\t Validation accuracy  98.26985677083333\n",
      "\t Epoch Loss  1.087201476097107\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  99.871826171875\n",
      "\t Validation accuracy  98.29325358072917\n",
      "\t Epoch Loss  1.086959958076477\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  99.85602484809027\n",
      "\t Validation accuracy  98.40047200520833\n",
      "\t Epoch Loss  1.0864324569702148\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  99.85568576388889\n",
      "\t Validation accuracy  98.34615071614583\n",
      "\t Epoch Loss  1.086517572402954\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  99.87440321180556\n",
      "\t Validation accuracy  98.11136881510417\n",
      "\t Epoch Loss  1.0858705043792725\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  99.88884819878473\n",
      "\t Validation accuracy  98.28572591145833\n",
      "\t Epoch Loss  1.0877553224563599\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  99.55647786458333\n",
      "\t Validation accuracy  98.56526692708333\n",
      "\t Epoch Loss  1.0873093605041504\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  99.71835666232639\n",
      "\t Validation accuracy  98.095703125\n",
      "\t Epoch Loss  1.088537335395813\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  99.79383680555556\n",
      "\t Validation accuracy  98.46048990885417\n",
      "\t Epoch Loss  1.087772011756897\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  99.77186414930556\n",
      "\t Validation accuracy  98.3966064453125\n",
      "\t Epoch Loss  1.0864955186843872\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  99.83608669704861\n",
      "\t Validation accuracy  98.2220458984375\n",
      "\t Epoch Loss  1.0856022834777832\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  99.72208658854167\n",
      "\t Validation accuracy  98.46232096354167\n",
      "\t Epoch Loss  1.0848838090896606\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  99.87209743923611\n",
      "\t Validation accuracy  98.15775553385417\n",
      "\t Epoch Loss  1.0846374034881592\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  99.85995822482639\n",
      "\t Validation accuracy  98.34269205729167\n",
      "\t Epoch Loss  1.0837604999542236\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  99.81363932291667\n",
      "\t Validation accuracy  98.4100341796875\n",
      "\t Epoch Loss  1.082597255706787\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  99.90403917100694\n",
      "\t Validation accuracy  98.20556640625\n",
      "\t Epoch Loss  1.081739902496338\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  99.81614854600694\n",
      "\t Validation accuracy  98.40616861979167\n",
      "\t Epoch Loss  1.0809917449951172\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  99.91034613715277\n",
      "\t Validation accuracy  98.27921549479167\n",
      "\t Epoch Loss  1.0799965858459473\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  99.92228190104167\n",
      "\t Validation accuracy  98.29915364583333\n",
      "\t Epoch Loss  1.0789787769317627\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  99.87630208333333\n",
      "\t Validation accuracy  98.47696940104167\n",
      "\t Epoch Loss  1.078258991241455\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  99.92119683159723\n",
      "\t Validation accuracy  98.09183756510417\n",
      "\t Epoch Loss  1.0786125659942627\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  99.82198079427083\n",
      "\t Validation accuracy  98.45601399739583\n",
      "\t Epoch Loss  1.0788547992706299\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  99.86836751302083\n",
      "\t Validation accuracy  98.18277994791667\n",
      "\t Epoch Loss  1.0782995223999023\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  99.859619140625\n",
      "\t Validation accuracy  98.33251953125\n",
      "\t Epoch Loss  1.0766483545303345\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  99.91556803385417\n",
      "\t Validation accuracy  98.44441731770833\n",
      "\t Epoch Loss  1.075604796409607\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  99.89949544270833\n",
      "\t Validation accuracy  98.21919759114583\n",
      "\t Epoch Loss  1.0745923519134521\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  99.89990234375\n",
      "\t Validation accuracy  98.40840657552083\n",
      "\t Epoch Loss  1.0740407705307007\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  99.93543836805556\n",
      "\t Validation accuracy  98.27006022135417\n",
      "\t Epoch Loss  1.0734825134277344\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  99.93170844184027\n",
      "\t Validation accuracy  98.2989501953125\n",
      "\t Epoch Loss  1.0721887350082397\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  99.9407958984375\n",
      "\t Validation accuracy  98.31380208333333\n",
      "\t Epoch Loss  1.071623682975769\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  99.94405110677083\n",
      "\t Validation accuracy  98.31787109375\n",
      "\t Epoch Loss  1.0709375143051147\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  99.95164659288194\n",
      "\t Validation accuracy  98.385009765625\n",
      "\t Epoch Loss  1.0705124139785767\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  99.93130154079861\n",
      "\t Validation accuracy  98.20048014322917\n",
      "\t Epoch Loss  1.0696303844451904\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  99.95205349392361\n",
      "\t Validation accuracy  98.40230305989583\n",
      "\t Epoch Loss  1.0687758922576904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  248\n",
      "\t Training accuracy:  99.94757758246527\n",
      "\t Validation accuracy  98.31136067708333\n",
      "\t Epoch Loss  1.0679733753204346\n",
      "Epoch Number :  249\n",
      "\t Training accuracy:  99.95517306857639\n",
      "\t Validation accuracy  98.3441162109375\n",
      "\t Epoch Loss  1.0671279430389404\n",
      "Epoch Number :  250\n",
      "\t Training accuracy:  99.95307074652777\n",
      "\t Validation accuracy  98.363037109375\n",
      "\t Epoch Loss  1.066465973854065\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  99.95659722222223\n",
      "\t Validation accuracy  98.37381998697917\n",
      "\t Epoch Loss  1.065845012664795\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  99.95686848958333\n",
      "\t Validation accuracy  98.27596028645833\n",
      "\t Epoch Loss  1.0654391050338745\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  99.9505615234375\n",
      "\t Validation accuracy  98.4246826171875\n",
      "\t Epoch Loss  1.064955472946167\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  99.95876736111111\n",
      "\t Validation accuracy  98.22896321614583\n",
      "\t Epoch Loss  1.0650272369384766\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  99.94357638888889\n",
      "\t Validation accuracy  98.41023763020833\n",
      "\t Epoch Loss  1.064418077468872\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  99.95985243055556\n",
      "\t Validation accuracy  98.26517740885417\n",
      "\t Epoch Loss  1.0643079280853271\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  99.937744140625\n",
      "\t Validation accuracy  98.35835774739583\n",
      "\t Epoch Loss  1.0630136728286743\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  99.95551215277777\n",
      "\t Validation accuracy  98.30220540364583\n",
      "\t Epoch Loss  1.0622475147247314\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  99.96046278211806\n",
      "\t Validation accuracy  98.3966064453125\n",
      "\t Epoch Loss  1.061539649963379\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  99.9530029296875\n",
      "\t Validation accuracy  98.29203287760417\n",
      "\t Epoch Loss  1.0606895685195923\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  99.9627685546875\n",
      "\t Validation accuracy  98.341064453125\n",
      "\t Epoch Loss  1.059611201286316\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  99.95964898003473\n",
      "\t Validation accuracy  98.3270263671875\n",
      "\t Epoch Loss  1.0589042901992798\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  99.9639892578125\n",
      "\t Validation accuracy  98.29732259114583\n",
      "\t Epoch Loss  1.0579413175582886\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  99.96046278211806\n",
      "\t Validation accuracy  98.32926432291667\n",
      "\t Epoch Loss  1.0572192668914795\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  99.967041015625\n",
      "\t Validation accuracy  98.33353678385417\n",
      "\t Epoch Loss  1.0564825534820557\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  99.96378580729167\n",
      "\t Validation accuracy  98.30342610677083\n",
      "\t Epoch Loss  1.0557942390441895\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  99.96636284722223\n",
      "\t Validation accuracy  98.33984375\n",
      "\t Epoch Loss  1.0551117658615112\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  99.96663411458333\n",
      "\t Validation accuracy  98.32621256510417\n",
      "\t Epoch Loss  1.0545482635498047\n",
      "Epoch Number :  269\n",
      "\t Training accuracy:  99.96663411458333\n",
      "\t Validation accuracy  98.34004720052083\n",
      "\t Epoch Loss  1.0539751052856445\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  99.96826171875\n",
      "\t Validation accuracy  98.3050537109375\n",
      "\t Epoch Loss  1.0534870624542236\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  99.96663411458333\n",
      "\t Validation accuracy  98.36181640625\n",
      "\t Epoch Loss  1.0529810190200806\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  99.96744791666667\n",
      "\t Validation accuracy  98.27982584635417\n",
      "\t Epoch Loss  1.0526190996170044\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  99.96541341145833\n",
      "\t Validation accuracy  98.42244466145833\n",
      "\t Epoch Loss  1.052141785621643\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  99.9688720703125\n",
      "\t Validation accuracy  98.2122802734375\n",
      "\t Epoch Loss  1.0520521402359009\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  99.95205349392361\n",
      "\t Validation accuracy  98.43098958333333\n",
      "\t Epoch Loss  1.0514748096466064\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  99.94954427083333\n",
      "\t Validation accuracy  98.05745442708333\n",
      "\t Epoch Loss  1.0516144037246704\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  99.95964898003473\n",
      "\t Validation accuracy  98.43241373697917\n",
      "\t Epoch Loss  1.0511260032653809\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  99.971923828125\n",
      "\t Validation accuracy  98.29243977864583\n",
      "\t Epoch Loss  1.0500386953353882\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  99.96812608506944\n",
      "\t Validation accuracy  98.37117513020833\n",
      "\t Epoch Loss  1.0493415594100952\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  99.96975368923611\n",
      "\t Validation accuracy  98.3367919921875\n",
      "\t Epoch Loss  1.0488475561141968\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  99.96982150607639\n",
      "\t Validation accuracy  98.33251953125\n",
      "\t Epoch Loss  1.0483555793762207\n",
      "Epoch Number :  282\n",
      "\t Training accuracy:  99.970703125\n",
      "\t Validation accuracy  98.33760579427083\n",
      "\t Epoch Loss  1.047863245010376\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target).long()  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True).long() # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    Noutputs = 1\n",
    "    \n",
    "Nbatches = int(math.ceil(Ntrain/batch_size)) #batch_size is defined above\n",
    "Nepochs = 1000\n",
    "Nrep = 1\n",
    "        \n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "model = UnetGenerator_3d(in_dim=1, out_dim=Noutputs, num_filter=4)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.90)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "#optimizer = optim.RMSprop(model.parameters())\n",
    "#optimizer = optim.Rprop(model.parameters())\n",
    " \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_ep in range(Nepochs):\n",
    "    for b_start in range(0, Ntrain, batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "        if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "        else:\n",
    "            #if delta model is chosen\n",
    "            #batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output.view(bsize_eff,grid_size,grid_size,grid_size), train_target.narrow(0, b_start, bsize_eff))\n",
    "        ep_loss[i_ep] += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step(ep_loss[i_ep])\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target, batch_size, criterion)\n",
    "    nb_validation_errs = compute_nb_errors(model, validation_input, validation_target, batch_size, criterion)\n",
    "\n",
    "    Ntrain_nb = Ntrain*grid_size**3\n",
    "    Nvalidation_nb = Nvalidation*grid_size**3\n",
    "    print(\"Epoch Number : \", i_ep)\n",
    "    print(\"\\t Training accuracy: \", (100*(Ntrain_nb-nb_train_errs)/Ntrain_nb))\n",
    "    print(\"\\t Validation accuracy \",(100*(Nvalidation_nb-nb_validation_errs)/Nvalidation_nb))\n",
    "\n",
    "    print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "\n",
    "    train_errors[i_ep] = nb_train_errs\n",
    "    validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target[44,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[14,1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array(100*(Ntrain_nb-train_errors)/Ntrain_nb)\n",
    "validation_accurcy = np.array(100*(Nvalidation_nb-validation_errors)/Nvalidation_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accurcy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visualisation = output[14,1,:,:,:].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = np.array(test_visualisation.data)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels)\n",
    "fig.savefig('VoxelizedFinal.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def summary(input_size, model):\n",
    "        def register_hook(module):\n",
    "            def hook(module, input, output):\n",
    "                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "                module_idx = len(summary)\n",
    "\n",
    "                m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "                summary[m_key] = OrderedDict()\n",
    "                summary[m_key]['input_shape'] = list(input[0].size())\n",
    "                summary[m_key]['input_shape'][0] = -1\n",
    "                summary[m_key]['output_shape'] = list(output.size())\n",
    "                summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "                params = 0\n",
    "                if hasattr(module, 'weight'):\n",
    "                    params += th.prod(th.LongTensor(list(module.weight.size())))\n",
    "                    if module.weight.requires_grad:\n",
    "                        summary[m_key]['trainable'] = True\n",
    "                    else:\n",
    "                        summary[m_key]['trainable'] = False\n",
    "                if hasattr(module, 'bias'):\n",
    "                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n",
    "                summary[m_key]['nb_params'] = params\n",
    "                \n",
    "            if not isinstance(module, nn.Sequential) and \\\n",
    "               not isinstance(module, nn.ModuleList) and \\\n",
    "               not (module == model):\n",
    "                hooks.append(module.register_forward_hook(hook))\n",
    "                \n",
    "        dtype = th.cuda.FloatTensor\n",
    "        \n",
    "        # check if there are multiple inputs to the network\n",
    "        if isinstance(input_size[0], (list, tuple)):\n",
    "            x = [Variable(th.rand(1,*in_size)).type(dtype) for in_size in input_size]\n",
    "        else:\n",
    "            x = Variable(th.rand(1,*input_size)).type(dtype)\n",
    "            \n",
    "        print(x.shape)\n",
    "        print(type(x[0]))\n",
    "        # create properties\n",
    "        summary = OrderedDict()\n",
    "        hooks = []\n",
    "        # register hook\n",
    "        model.apply(register_hook)\n",
    "        # make a forward pass\n",
    "        model(x)\n",
    "        # remove these hooks\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        print('----------------------------------------------------------------')\n",
    "        line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shpae', 'Param #')\n",
    "        print(line_new)\n",
    "        print('================================================================')\n",
    "        total_params = 0\n",
    "        trainable_params = 0\n",
    "        for layer in summary:\n",
    "            ## input_shape, output_shape, trainable, nb_params\n",
    "            line_new = '{:>20}  {:>25} {:>15}'.format(layer, summary[layer]['output_shape'], summary[layer]['nb_params'])\n",
    "            total_params += summary[layer]['nb_params']\n",
    "            if 'trainable' in summary[layer]:\n",
    "                if summary[layer]['trainable'] == True:\n",
    "                    trainable_params += summary[layer]['nb_params']\n",
    "            print(line_new)\n",
    "        print('================================================================')\n",
    "        print('Total params: ' + str(total_params))\n",
    "        print('Trainable params: ' + str(trainable_params))\n",
    "        print('Non-trainable params: ' + str(total_params - trainable_params))\n",
    "        print('----------------------------------------------------------------')\n",
    "        return summary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
