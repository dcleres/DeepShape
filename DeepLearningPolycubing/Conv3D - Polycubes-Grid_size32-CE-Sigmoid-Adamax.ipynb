{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=32\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensor to a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "torch.Size([60, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([45, 1, 32, 32, 32])\n",
      "validation torch.Size([15, 1, 32, 32, 32])\n",
      "train_target torch.Size([45, 32, 32, 32])\n",
      "validation_target torch.Size([15, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target,batch_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:, 0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, 1, grid_size, grid_size, grid_size).float())\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, 1, grid_size, grid_size, grid_size).float())\n",
    "\n",
    "labels_train = preprocessed_input_train_target.float()\n",
    "labels_validation = preprocessed_input_validation_target.float()\n",
    "\n",
    "print('train', train_input.shape)\n",
    "print('validation', validation_input.shape)\n",
    "print('train_target', labels_train.shape)\n",
    "print('validation_target', labels_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n",
      "Epoch Number :  0\n",
      "\t Training accuracy:  66.04831271701389\n",
      "\t Validation accuracy  66.0455322265625\n",
      "\t Epoch Loss  2.036289691925049\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  65.71723090277777\n",
      "\t Validation accuracy  65.61665852864583\n",
      "\t Epoch Loss  2.0176684856414795\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  68.03724500868056\n",
      "\t Validation accuracy  67.91890462239583\n",
      "\t Epoch Loss  2.0087900161743164\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  70.12240939670139\n",
      "\t Validation accuracy  70.1513671875\n",
      "\t Epoch Loss  2.001417398452759\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  72.22032335069444\n",
      "\t Validation accuracy  72.30000813802083\n",
      "\t Epoch Loss  1.9965221881866455\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  71.492919921875\n",
      "\t Validation accuracy  71.53340657552083\n",
      "\t Epoch Loss  1.9916551113128662\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  71.29808213975694\n",
      "\t Validation accuracy  71.27176920572917\n",
      "\t Epoch Loss  1.9871602058410645\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  71.50438096788194\n",
      "\t Validation accuracy  71.47379557291667\n",
      "\t Epoch Loss  1.984194040298462\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  71.4337158203125\n",
      "\t Validation accuracy  71.41357421875\n",
      "\t Epoch Loss  1.9812424182891846\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  71.41316731770833\n",
      "\t Validation accuracy  71.38997395833333\n",
      "\t Epoch Loss  1.9783039093017578\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  71.29401312934027\n",
      "\t Validation accuracy  71.24654134114583\n",
      "\t Epoch Loss  1.9758120775222778\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  70.79671223958333\n",
      "\t Validation accuracy  70.74259440104167\n",
      "\t Epoch Loss  1.9738917350769043\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  70.86466471354167\n",
      "\t Validation accuracy  70.79569498697917\n",
      "\t Epoch Loss  1.9717278480529785\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  71.20381673177083\n",
      "\t Validation accuracy  71.15987141927083\n",
      "\t Epoch Loss  1.9693368673324585\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  71.33646647135417\n",
      "\t Validation accuracy  71.285400390625\n",
      "\t Epoch Loss  1.9668508768081665\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  71.48125542534723\n",
      "\t Validation accuracy  71.44571940104167\n",
      "\t Epoch Loss  1.96426260471344\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  71.51299370659723\n",
      "\t Validation accuracy  71.46931966145833\n",
      "\t Epoch Loss  1.9617074728012085\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  71.64076063368056\n",
      "\t Validation accuracy  71.58854166666667\n",
      "\t Epoch Loss  1.9590792655944824\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  71.91114637586806\n",
      "\t Validation accuracy  71.817626953125\n",
      "\t Epoch Loss  1.9564485549926758\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  72.11697048611111\n",
      "\t Validation accuracy  71.99178059895833\n",
      "\t Epoch Loss  1.9537452459335327\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  72.32523600260417\n",
      "\t Validation accuracy  72.17427571614583\n",
      "\t Epoch Loss  1.9511427879333496\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  72.39549424913194\n",
      "\t Validation accuracy  72.24527994791667\n",
      "\t Epoch Loss  1.9486918449401855\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  72.54109700520833\n",
      "\t Validation accuracy  72.3834228515625\n",
      "\t Epoch Loss  1.94631826877594\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  72.66988118489583\n",
      "\t Validation accuracy  72.50712076822917\n",
      "\t Epoch Loss  1.94391930103302\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  72.86234537760417\n",
      "\t Validation accuracy  72.69266764322917\n",
      "\t Epoch Loss  1.9414777755737305\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  73.13198513454861\n",
      "\t Validation accuracy  72.91544596354167\n",
      "\t Epoch Loss  1.9389979839324951\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  73.28158908420139\n",
      "\t Validation accuracy  73.09061686197917\n",
      "\t Epoch Loss  1.9365918636322021\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  73.26666937934027\n",
      "\t Validation accuracy  73.08349609375\n",
      "\t Epoch Loss  1.9339344501495361\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  73.48063151041667\n",
      "\t Validation accuracy  73.30952962239583\n",
      "\t Epoch Loss  1.931414246559143\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  73.760986328125\n",
      "\t Validation accuracy  73.494873046875\n",
      "\t Epoch Loss  1.9287457466125488\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  73.91194661458333\n",
      "\t Validation accuracy  73.65681966145833\n",
      "\t Epoch Loss  1.9262561798095703\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  73.87240939670139\n",
      "\t Validation accuracy  73.68428548177083\n",
      "\t Epoch Loss  1.9236395359039307\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  74.45326063368056\n",
      "\t Validation accuracy  74.1009521484375\n",
      "\t Epoch Loss  1.9210844039916992\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  74.32169596354167\n",
      "\t Validation accuracy  74.12841796875\n",
      "\t Epoch Loss  1.9185302257537842\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  74.61480034722223\n",
      "\t Validation accuracy  74.45210774739583\n",
      "\t Epoch Loss  1.9160311222076416\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  74.74751790364583\n",
      "\t Validation accuracy  74.46431477864583\n",
      "\t Epoch Loss  1.913503646850586\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  75.03363715277777\n",
      "\t Validation accuracy  74.80143229166667\n",
      "\t Epoch Loss  1.9107248783111572\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  75.31711154513889\n",
      "\t Validation accuracy  75.059814453125\n",
      "\t Epoch Loss  1.9083198308944702\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  75.6719970703125\n",
      "\t Validation accuracy  75.31005859375\n",
      "\t Epoch Loss  1.9054447412490845\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  76.01487901475694\n",
      "\t Validation accuracy  75.62825520833333\n",
      "\t Epoch Loss  1.9028725624084473\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  76.03441026475694\n",
      "\t Validation accuracy  75.74076334635417\n",
      "\t Epoch Loss  1.9003422260284424\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  76.60834418402777\n",
      "\t Validation accuracy  76.004638671875\n",
      "\t Epoch Loss  1.8975763320922852\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  76.75286187065973\n",
      "\t Validation accuracy  76.24104817708333\n",
      "\t Epoch Loss  1.8952841758728027\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  76.82508680555556\n",
      "\t Validation accuracy  76.552734375\n",
      "\t Epoch Loss  1.8930087089538574\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  77.23904079861111\n",
      "\t Validation accuracy  76.68233235677083\n",
      "\t Epoch Loss  1.8903565406799316\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  77.37358940972223\n",
      "\t Validation accuracy  76.92220052083333\n",
      "\t Epoch Loss  1.8876843452453613\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  78.07156032986111\n",
      "\t Validation accuracy  77.38321940104167\n",
      "\t Epoch Loss  1.8851313591003418\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  78.08261447482639\n",
      "\t Validation accuracy  77.54048665364583\n",
      "\t Epoch Loss  1.882628083229065\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  78.09685601128473\n",
      "\t Validation accuracy  77.637939453125\n",
      "\t Epoch Loss  1.8801555633544922\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  78.73697916666667\n",
      "\t Validation accuracy  78.09529622395833\n",
      "\t Epoch Loss  1.8776640892028809\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  79.0521240234375\n",
      "\t Validation accuracy  78.46781412760417\n",
      "\t Epoch Loss  1.8752689361572266\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  79.07307942708333\n",
      "\t Validation accuracy  78.4906005859375\n",
      "\t Epoch Loss  1.8727569580078125\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  79.54555935329861\n",
      "\t Validation accuracy  78.714599609375\n",
      "\t Epoch Loss  1.870365023612976\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  79.68844943576389\n",
      "\t Validation accuracy  78.94673665364583\n",
      "\t Epoch Loss  1.8683555126190186\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  79.60673014322917\n",
      "\t Validation accuracy  79.06412760416667\n",
      "\t Epoch Loss  1.8658368587493896\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  80.30571831597223\n",
      "\t Validation accuracy  79.41019694010417\n",
      "\t Epoch Loss  1.8639378547668457\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  80.47281901041667\n",
      "\t Validation accuracy  79.720458984375\n",
      "\t Epoch Loss  1.8615686893463135\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  80.75602213541667\n",
      "\t Validation accuracy  80.04292805989583\n",
      "\t Epoch Loss  1.8590943813323975\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  80.9954833984375\n",
      "\t Validation accuracy  80.19266764322917\n",
      "\t Epoch Loss  1.8572568893432617\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  81.40021430121527\n",
      "\t Validation accuracy  80.57393391927083\n",
      "\t Epoch Loss  1.8552221059799194\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  81.37281629774306\n",
      "\t Validation accuracy  80.65287272135417\n",
      "\t Epoch Loss  1.8530895709991455\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  82.04379611545139\n",
      "\t Validation accuracy  81.072998046875\n",
      "\t Epoch Loss  1.8508086204528809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  62\n",
      "\t Training accuracy:  82.28807237413194\n",
      "\t Validation accuracy  81.2896728515625\n",
      "\t Epoch Loss  1.8489274978637695\n",
      "Epoch Number :  63\n",
      "\t Training accuracy:  82.1759033203125\n",
      "\t Validation accuracy  81.07014973958333\n",
      "\t Epoch Loss  1.846801996231079\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  82.52794053819444\n",
      "\t Validation accuracy  81.53951009114583\n",
      "\t Epoch Loss  1.8447597026824951\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  82.7410888671875\n",
      "\t Validation accuracy  81.52099609375\n",
      "\t Epoch Loss  1.8429195880889893\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  82.58477105034723\n",
      "\t Validation accuracy  81.49922688802083\n",
      "\t Epoch Loss  1.8404505252838135\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  82.92453342013889\n",
      "\t Validation accuracy  81.7388916015625\n",
      "\t Epoch Loss  1.838486671447754\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  83.28226725260417\n",
      "\t Validation accuracy  81.95454915364583\n",
      "\t Epoch Loss  1.8363502025604248\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  83.04050021701389\n",
      "\t Validation accuracy  81.84163411458333\n",
      "\t Epoch Loss  1.8341892957687378\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  82.962646484375\n",
      "\t Validation accuracy  81.7547607421875\n",
      "\t Epoch Loss  1.8320562839508057\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  83.47052680121527\n",
      "\t Validation accuracy  82.09309895833333\n",
      "\t Epoch Loss  1.82979416847229\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  83.59151204427083\n",
      "\t Validation accuracy  82.28047688802083\n",
      "\t Epoch Loss  1.82746160030365\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  83.38222927517361\n",
      "\t Validation accuracy  82.1234130859375\n",
      "\t Epoch Loss  1.8250682353973389\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  83.34994845920139\n",
      "\t Validation accuracy  82.26114908854167\n",
      "\t Epoch Loss  1.8228627443313599\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  83.87369791666667\n",
      "\t Validation accuracy  82.427978515625\n",
      "\t Epoch Loss  1.8205299377441406\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  83.95894368489583\n",
      "\t Validation accuracy  82.56144205729167\n",
      "\t Epoch Loss  1.8182146549224854\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  83.68448893229167\n",
      "\t Validation accuracy  82.572021484375\n",
      "\t Epoch Loss  1.8157305717468262\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  83.67255316840277\n",
      "\t Validation accuracy  82.54984537760417\n",
      "\t Epoch Loss  1.8138176202774048\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  84.22017415364583\n",
      "\t Validation accuracy  82.78361002604167\n",
      "\t Epoch Loss  1.8111737966537476\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  84.17304144965277\n",
      "\t Validation accuracy  82.95267740885417\n",
      "\t Epoch Loss  1.8089585304260254\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  84.18131510416667\n",
      "\t Validation accuracy  82.95613606770833\n",
      "\t Epoch Loss  1.8066315650939941\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  84.38252766927083\n",
      "\t Validation accuracy  83.19376627604167\n",
      "\t Epoch Loss  1.804643154144287\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  84.67990451388889\n",
      "\t Validation accuracy  83.436279296875\n",
      "\t Epoch Loss  1.8022511005401611\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  84.76793077256944\n",
      "\t Validation accuracy  83.58500162760417\n",
      "\t Epoch Loss  1.8000140190124512\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  85.0732421875\n",
      "\t Validation accuracy  83.90726725260417\n",
      "\t Epoch Loss  1.7980190515518188\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  85.28428819444444\n",
      "\t Validation accuracy  84.1510009765625\n",
      "\t Epoch Loss  1.7960103750228882\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  85.75385199652777\n",
      "\t Validation accuracy  84.52921549479167\n",
      "\t Epoch Loss  1.7936652898788452\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  85.83916558159723\n",
      "\t Validation accuracy  84.6630859375\n",
      "\t Epoch Loss  1.7916336059570312\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  86.18523491753473\n",
      "\t Validation accuracy  84.92268880208333\n",
      "\t Epoch Loss  1.7892208099365234\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  86.47264268663194\n",
      "\t Validation accuracy  85.21931966145833\n",
      "\t Epoch Loss  1.7871301174163818\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  86.58786349826389\n",
      "\t Validation accuracy  85.3668212890625\n",
      "\t Epoch Loss  1.7852067947387695\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  87.130126953125\n",
      "\t Validation accuracy  85.8416748046875\n",
      "\t Epoch Loss  1.7836554050445557\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  87.32089572482639\n",
      "\t Validation accuracy  85.91756184895833\n",
      "\t Epoch Loss  1.7812907695770264\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  87.58775499131944\n",
      "\t Validation accuracy  86.36311848958333\n",
      "\t Epoch Loss  1.7789247035980225\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  88.33543565538194\n",
      "\t Validation accuracy  86.81193033854167\n",
      "\t Epoch Loss  1.7774254083633423\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  88.30702039930556\n",
      "\t Validation accuracy  86.97469075520833\n",
      "\t Epoch Loss  1.7751080989837646\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  88.89973958333333\n",
      "\t Validation accuracy  87.857666015625\n",
      "\t Epoch Loss  1.7730991840362549\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  89.00058322482639\n",
      "\t Validation accuracy  87.61800130208333\n",
      "\t Epoch Loss  1.7711372375488281\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  88.97359212239583\n",
      "\t Validation accuracy  87.51424153645833\n",
      "\t Epoch Loss  1.7685019969940186\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  89.83812120225694\n",
      "\t Validation accuracy  88.32661946614583\n",
      "\t Epoch Loss  1.766550898551941\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  90.25790744357639\n",
      "\t Validation accuracy  88.89933268229167\n",
      "\t Epoch Loss  1.7640734910964966\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  90.19965277777777\n",
      "\t Validation accuracy  89.00655110677083\n",
      "\t Epoch Loss  1.7620623111724854\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  90.81319173177083\n",
      "\t Validation accuracy  89.490966796875\n",
      "\t Epoch Loss  1.7599072456359863\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  91.27543131510417\n",
      "\t Validation accuracy  90.06062825520833\n",
      "\t Epoch Loss  1.757697343826294\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  91.21019151475694\n",
      "\t Validation accuracy  90.03153483072917\n",
      "\t Epoch Loss  1.7557374238967896\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  91.36406792534723\n",
      "\t Validation accuracy  90.1904296875\n",
      "\t Epoch Loss  1.7538986206054688\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  91.50953504774306\n",
      "\t Validation accuracy  90.25553385416667\n",
      "\t Epoch Loss  1.7514647245407104\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  91.85445149739583\n",
      "\t Validation accuracy  90.6890869140625\n",
      "\t Epoch Loss  1.7491002082824707\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  91.99022081163194\n",
      "\t Validation accuracy  90.74076334635417\n",
      "\t Epoch Loss  1.7471122741699219\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  92.09893120659723\n",
      "\t Validation accuracy  91.00423177083333\n",
      "\t Epoch Loss  1.7449538707733154\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  92.41719563802083\n",
      "\t Validation accuracy  91.34053548177083\n",
      "\t Epoch Loss  1.742835283279419\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  92.35114203559027\n",
      "\t Validation accuracy  91.16190592447917\n",
      "\t Epoch Loss  1.7408376932144165\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  92.72664388020833\n",
      "\t Validation accuracy  91.6131591796875\n",
      "\t Epoch Loss  1.7383490800857544\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  92.8717041015625\n",
      "\t Validation accuracy  91.86055501302083\n",
      "\t Epoch Loss  1.73619544506073\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  93.01608615451389\n",
      "\t Validation accuracy  92.02290852864583\n",
      "\t Epoch Loss  1.7339602708816528\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  93.23493109809027\n",
      "\t Validation accuracy  92.2308349609375\n",
      "\t Epoch Loss  1.732111930847168\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  93.37293836805556\n",
      "\t Validation accuracy  92.15311686197917\n",
      "\t Epoch Loss  1.7299689054489136\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  93.67472330729167\n",
      "\t Validation accuracy  92.54740397135417\n",
      "\t Epoch Loss  1.7279704809188843\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  93.73928493923611\n",
      "\t Validation accuracy  92.93680826822917\n",
      "\t Epoch Loss  1.7266181707382202\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  93.8519287109375\n",
      "\t Validation accuracy  92.34293619791667\n",
      "\t Epoch Loss  1.7244749069213867\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  93.94402398003473\n",
      "\t Validation accuracy  92.89326985677083\n",
      "\t Epoch Loss  1.722241997718811\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  94.39222547743056\n",
      "\t Validation accuracy  93.43465169270833\n",
      "\t Epoch Loss  1.7205524444580078\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  94.41684299045139\n",
      "\t Validation accuracy  93.62569173177083\n",
      "\t Epoch Loss  1.7180893421173096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  124\n",
      "\t Training accuracy:  94.4287109375\n",
      "\t Validation accuracy  93.62080891927083\n",
      "\t Epoch Loss  1.716664433479309\n",
      "Epoch Number :  125\n",
      "\t Training accuracy:  94.5318603515625\n",
      "\t Validation accuracy  93.62833658854167\n",
      "\t Epoch Loss  1.7145006656646729\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  94.61317274305556\n",
      "\t Validation accuracy  93.71968587239583\n",
      "\t Epoch Loss  1.712980031967163\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  94.68682183159723\n",
      "\t Validation accuracy  93.70869954427083\n",
      "\t Epoch Loss  1.710875391960144\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  94.75111219618056\n",
      "\t Validation accuracy  93.95182291666667\n",
      "\t Epoch Loss  1.7092715501785278\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  94.84185112847223\n",
      "\t Validation accuracy  93.90401204427083\n",
      "\t Epoch Loss  1.70768404006958\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  94.89732530381944\n",
      "\t Validation accuracy  93.96484375\n",
      "\t Epoch Loss  1.7059741020202637\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  94.92974175347223\n",
      "\t Validation accuracy  94.11153157552083\n",
      "\t Epoch Loss  1.7043461799621582\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  95.02888997395833\n",
      "\t Validation accuracy  94.02608235677083\n",
      "\t Epoch Loss  1.702867031097412\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  95.27567545572917\n",
      "\t Validation accuracy  94.28751627604167\n",
      "\t Epoch Loss  1.701468586921692\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  95.406494140625\n",
      "\t Validation accuracy  94.4195556640625\n",
      "\t Epoch Loss  1.6996955871582031\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  95.66128200954861\n",
      "\t Validation accuracy  94.700927734375\n",
      "\t Epoch Loss  1.6981689929962158\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  95.61482747395833\n",
      "\t Validation accuracy  94.77742513020833\n",
      "\t Epoch Loss  1.696352243423462\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  95.91762966579861\n",
      "\t Validation accuracy  94.92818196614583\n",
      "\t Epoch Loss  1.695138692855835\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  96.21426052517361\n",
      "\t Validation accuracy  95.316162109375\n",
      "\t Epoch Loss  1.6930906772613525\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  96.37383355034723\n",
      "\t Validation accuracy  95.4376220703125\n",
      "\t Epoch Loss  1.6914904117584229\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  96.75055609809027\n",
      "\t Validation accuracy  95.73811848958333\n",
      "\t Epoch Loss  1.689915657043457\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  97.14694552951389\n",
      "\t Validation accuracy  96.16923014322917\n",
      "\t Epoch Loss  1.687509536743164\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  97.49667697482639\n",
      "\t Validation accuracy  96.59423828125\n",
      "\t Epoch Loss  1.6854838132858276\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  97.85603841145833\n",
      "\t Validation accuracy  96.9818115234375\n",
      "\t Epoch Loss  1.6834224462509155\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  97.96800401475694\n",
      "\t Validation accuracy  97.14335123697917\n",
      "\t Epoch Loss  1.6813783645629883\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  97.87197536892361\n",
      "\t Validation accuracy  96.95027669270833\n",
      "\t Epoch Loss  1.6798197031021118\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  98.01133897569444\n",
      "\t Validation accuracy  97.132568359375\n",
      "\t Epoch Loss  1.6786675453186035\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  97.97003851996527\n",
      "\t Validation accuracy  97.18709309895833\n",
      "\t Epoch Loss  1.677006721496582\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  97.90167914496527\n",
      "\t Validation accuracy  97.10917154947917\n",
      "\t Epoch Loss  1.6757123470306396\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  98.057861328125\n",
      "\t Validation accuracy  97.2393798828125\n",
      "\t Epoch Loss  1.6742379665374756\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  97.87000868055556\n",
      "\t Validation accuracy  96.92586263020833\n",
      "\t Epoch Loss  1.6721221208572388\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  98.03398980034723\n",
      "\t Validation accuracy  97.26399739583333\n",
      "\t Epoch Loss  1.6700854301452637\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  97.95267740885417\n",
      "\t Validation accuracy  97.27783203125\n",
      "\t Epoch Loss  1.6682024002075195\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  97.98739963107639\n",
      "\t Validation accuracy  97.18363444010417\n",
      "\t Epoch Loss  1.6664308309555054\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  98.065185546875\n",
      "\t Validation accuracy  97.19278971354167\n",
      "\t Epoch Loss  1.6635448932647705\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  97.93748643663194\n",
      "\t Validation accuracy  97.10245768229167\n",
      "\t Epoch Loss  1.661566138267517\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  98.06098090277777\n",
      "\t Validation accuracy  97.1844482421875\n",
      "\t Epoch Loss  1.6588013172149658\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  97.92928059895833\n",
      "\t Validation accuracy  97.11181640625\n",
      "\t Epoch Loss  1.6568403244018555\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  98.00632052951389\n",
      "\t Validation accuracy  97.25423177083333\n",
      "\t Epoch Loss  1.6540849208831787\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  97.94691297743056\n",
      "\t Validation accuracy  97.24222819010417\n",
      "\t Epoch Loss  1.6524910926818848\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  97.9595947265625\n",
      "\t Validation accuracy  97.26521809895833\n",
      "\t Epoch Loss  1.6499600410461426\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  97.99730088975694\n",
      "\t Validation accuracy  97.25667317708333\n",
      "\t Epoch Loss  1.6481471061706543\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  97.92934841579861\n",
      "\t Validation accuracy  97.20926920572917\n",
      "\t Epoch Loss  1.6464903354644775\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  97.98583984375\n",
      "\t Validation accuracy  97.2906494140625\n",
      "\t Epoch Loss  1.6449501514434814\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  97.95125325520833\n",
      "\t Validation accuracy  97.21333821614583\n",
      "\t Epoch Loss  1.6436185836791992\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  97.97227647569444\n",
      "\t Validation accuracy  97.19563802083333\n",
      "\t Epoch Loss  1.6422820091247559\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  97.96434190538194\n",
      "\t Validation accuracy  97.18424479166667\n",
      "\t Epoch Loss  1.6409817934036255\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  97.97078450520833\n",
      "\t Validation accuracy  97.19156901041667\n",
      "\t Epoch Loss  1.6398370265960693\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  97.97641330295139\n",
      "\t Validation accuracy  97.19685872395833\n",
      "\t Epoch Loss  1.6386845111846924\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  97.98760308159723\n",
      "\t Validation accuracy  97.1966552734375\n",
      "\t Epoch Loss  1.6376506090164185\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  97.99323187934027\n",
      "\t Validation accuracy  97.19950358072917\n",
      "\t Epoch Loss  1.6365680694580078\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  98.00130208333333\n",
      "\t Validation accuracy  97.2125244140625\n",
      "\t Epoch Loss  1.6355043649673462\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  97.99329969618056\n",
      "\t Validation accuracy  97.20255533854167\n",
      "\t Epoch Loss  1.6344249248504639\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  98.00937228732639\n",
      "\t Validation accuracy  97.21333821614583\n",
      "\t Epoch Loss  1.6333222389221191\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  98.00998263888889\n",
      "\t Validation accuracy  97.21964518229167\n",
      "\t Epoch Loss  1.6321332454681396\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  98.01913791232639\n",
      "\t Validation accuracy  97.222900390625\n",
      "\t Epoch Loss  1.6309621334075928\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  98.02883572048611\n",
      "\t Validation accuracy  97.22147623697917\n",
      "\t Epoch Loss  1.6296820640563965\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  98.02266438802083\n",
      "\t Validation accuracy  97.21476236979167\n",
      "\t Epoch Loss  1.628343105316162\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  98.03690592447917\n",
      "\t Validation accuracy  97.22391764322917\n",
      "\t Epoch Loss  1.6269378662109375\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  98.03677029079861\n",
      "\t Validation accuracy  97.22005208333333\n",
      "\t Epoch Loss  1.6253429651260376\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  98.04090711805556\n",
      "\t Validation accuracy  97.22513834635417\n",
      "\t Epoch Loss  1.6235380172729492\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  98.0511474609375\n",
      "\t Validation accuracy  97.23164876302083\n",
      "\t Epoch Loss  1.621535301208496\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  98.04802788628473\n",
      "\t Validation accuracy  97.22554524739583\n",
      "\t Epoch Loss  1.6194615364074707\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  98.05697970920139\n",
      "\t Validation accuracy  97.23368326822917\n",
      "\t Epoch Loss  1.6173388957977295\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  98.05921766493056\n",
      "\t Validation accuracy  97.23124186197917\n",
      "\t Epoch Loss  1.615180253982544\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  98.05989583333333\n",
      "\t Validation accuracy  97.2344970703125\n",
      "\t Epoch Loss  1.6130554676055908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  186\n",
      "\t Training accuracy:  98.070068359375\n",
      "\t Validation accuracy  97.2412109375\n",
      "\t Epoch Loss  1.6109910011291504\n",
      "Epoch Number :  187\n",
      "\t Training accuracy:  98.06593153211806\n",
      "\t Validation accuracy  97.23124186197917\n",
      "\t Epoch Loss  1.6090035438537598\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  98.0706787109375\n",
      "\t Validation accuracy  97.24385579427083\n",
      "\t Epoch Loss  1.6069560050964355\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  98.08057996961806\n",
      "\t Validation accuracy  97.24507649739583\n",
      "\t Epoch Loss  1.6050009727478027\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  98.07284884982639\n",
      "\t Validation accuracy  97.2406005859375\n",
      "\t Epoch Loss  1.6031994819641113\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  98.08600531684027\n",
      "\t Validation accuracy  97.25301106770833\n",
      "\t Epoch Loss  1.6014494895935059\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  98.08505588107639\n",
      "\t Validation accuracy  97.24344889322917\n",
      "\t Epoch Loss  1.5999717712402344\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  98.08620876736111\n",
      "\t Validation accuracy  97.2515869140625\n",
      "\t Epoch Loss  1.5986080169677734\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  98.10017903645833\n",
      "\t Validation accuracy  97.2528076171875\n",
      "\t Epoch Loss  1.5973936319351196\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  98.09149848090277\n",
      "\t Validation accuracy  97.2406005859375\n",
      "\t Epoch Loss  1.5963239669799805\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  98.10289171006944\n",
      "\t Validation accuracy  97.25362141927083\n",
      "\t Epoch Loss  1.5952837467193604\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  98.1060791015625\n",
      "\t Validation accuracy  97.24873860677083\n",
      "\t Epoch Loss  1.5943869352340698\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  98.10404459635417\n",
      "\t Validation accuracy  97.2576904296875\n",
      "\t Epoch Loss  1.5934885740280151\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  98.12459309895833\n",
      "\t Validation accuracy  97.264404296875\n",
      "\t Epoch Loss  1.592697262763977\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  98.12167697482639\n",
      "\t Validation accuracy  97.24609375\n",
      "\t Epoch Loss  1.5918657779693604\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  98.14032660590277\n",
      "\t Validation accuracy  97.26521809895833\n",
      "\t Epoch Loss  1.5911893844604492\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  98.15884060329861\n",
      "\t Validation accuracy  97.25789388020833\n",
      "\t Epoch Loss  1.5904076099395752\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  98.16419813368056\n",
      "\t Validation accuracy  97.27457682291667\n",
      "\t Epoch Loss  1.5896694660186768\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  98.184814453125\n",
      "\t Validation accuracy  97.276611328125\n",
      "\t Epoch Loss  1.5889452695846558\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  98.19315592447917\n",
      "\t Validation accuracy  97.27823893229167\n",
      "\t Epoch Loss  1.588139533996582\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  98.21051703559027\n",
      "\t Validation accuracy  97.2857666015625\n",
      "\t Epoch Loss  1.5873517990112305\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  98.21702745225694\n",
      "\t Validation accuracy  97.274169921875\n",
      "\t Epoch Loss  1.5864248275756836\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  98.22292751736111\n",
      "\t Validation accuracy  97.286376953125\n",
      "\t Epoch Loss  1.5855227708816528\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  98.23967827690973\n",
      "\t Validation accuracy  97.28983561197917\n",
      "\t Epoch Loss  1.5845952033996582\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  98.2427978515625\n",
      "\t Validation accuracy  97.2955322265625\n",
      "\t Epoch Loss  1.5835845470428467\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  98.26633029513889\n",
      "\t Validation accuracy  97.30367024739583\n",
      "\t Epoch Loss  1.5825707912445068\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  98.26097276475694\n",
      "\t Validation accuracy  97.303466796875\n",
      "\t Epoch Loss  1.5814409255981445\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  98.27480740017361\n",
      "\t Validation accuracy  97.31180826822917\n",
      "\t Epoch Loss  1.5803258419036865\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  98.29230414496527\n",
      "\t Validation accuracy  97.32035319010417\n",
      "\t Epoch Loss  1.5790650844573975\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  98.28742133246527\n",
      "\t Validation accuracy  97.32157389322917\n",
      "\t Epoch Loss  1.5776716470718384\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  98.3135986328125\n",
      "\t Validation accuracy  97.3175048828125\n",
      "\t Epoch Loss  1.5760486125946045\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  98.32329644097223\n",
      "\t Validation accuracy  97.327880859375\n",
      "\t Epoch Loss  1.574148178100586\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  98.31400553385417\n",
      "\t Validation accuracy  97.33113606770833\n",
      "\t Epoch Loss  1.5723851919174194\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  98.3734130859375\n",
      "\t Validation accuracy  97.32625325520833\n",
      "\t Epoch Loss  1.5704857110977173\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  98.34547254774306\n",
      "\t Validation accuracy  97.33805338541667\n",
      "\t Epoch Loss  1.5686495304107666\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  98.37022569444444\n",
      "\t Validation accuracy  97.34375\n",
      "\t Epoch Loss  1.566725730895996\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  98.4332275390625\n",
      "\t Validation accuracy  97.32340494791667\n",
      "\t Epoch Loss  1.5648627281188965\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  98.408203125\n",
      "\t Validation accuracy  97.33601888020833\n",
      "\t Epoch Loss  1.5632386207580566\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  98.45364040798611\n",
      "\t Validation accuracy  97.3187255859375\n",
      "\t Epoch Loss  1.5614113807678223\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  98.50151909722223\n",
      "\t Validation accuracy  97.320556640625\n",
      "\t Epoch Loss  1.5597968101501465\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  98.4722900390625\n",
      "\t Validation accuracy  97.32157389322917\n",
      "\t Epoch Loss  1.558192491531372\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  98.57096354166667\n",
      "\t Validation accuracy  97.30611165364583\n",
      "\t Epoch Loss  1.5561587810516357\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  98.5491943359375\n",
      "\t Validation accuracy  97.31831868489583\n",
      "\t Epoch Loss  1.5547566413879395\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  98.57896592881944\n",
      "\t Validation accuracy  97.31526692708333\n",
      "\t Epoch Loss  1.5532050132751465\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  98.72870551215277\n",
      "\t Validation accuracy  97.3162841796875\n",
      "\t Epoch Loss  1.5518839359283447\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  98.64169650607639\n",
      "\t Validation accuracy  97.31669108072917\n",
      "\t Epoch Loss  1.5507898330688477\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  98.78207736545139\n",
      "\t Validation accuracy  97.3046875\n",
      "\t Epoch Loss  1.549509882926941\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  98.82826063368056\n",
      "\t Validation accuracy  97.30733235677083\n",
      "\t Epoch Loss  1.5485665798187256\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  98.8897705078125\n",
      "\t Validation accuracy  97.301025390625\n",
      "\t Epoch Loss  1.5475233793258667\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  99.18497721354167\n",
      "\t Validation accuracy  97.35921223958333\n",
      "\t Epoch Loss  1.5465583801269531\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  98.990478515625\n",
      "\t Validation accuracy  97.27823893229167\n",
      "\t Epoch Loss  1.5455045700073242\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  99.456787109375\n",
      "\t Validation accuracy  97.559814453125\n",
      "\t Epoch Loss  1.5445783138275146\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  99.52623155381944\n",
      "\t Validation accuracy  97.46866861979167\n",
      "\t Epoch Loss  1.544961929321289\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  99.02865939670139\n",
      "\t Validation accuracy  97.24019368489583\n",
      "\t Epoch Loss  1.5437648296356201\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  99.58530002170139\n",
      "\t Validation accuracy  97.4053955078125\n",
      "\t Epoch Loss  1.5432419776916504\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  99.29490831163194\n",
      "\t Validation accuracy  97.39461263020833\n",
      "\t Epoch Loss  1.5415310859680176\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  99.60422092013889\n",
      "\t Validation accuracy  97.54475911458333\n",
      "\t Epoch Loss  1.5412776470184326\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  99.29667154947917\n",
      "\t Validation accuracy  97.4713134765625\n",
      "\t Epoch Loss  1.5402297973632812\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  99.40782335069444\n",
      "\t Validation accuracy  97.38850911458333\n",
      "\t Epoch Loss  1.539977788925171\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  99.30453830295139\n",
      "\t Validation accuracy  97.31180826822917\n",
      "\t Epoch Loss  1.5384572744369507\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  99.39385308159723\n",
      "\t Validation accuracy  97.45768229166667\n",
      "\t Epoch Loss  1.537152886390686\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  99.49869791666667\n",
      "\t Validation accuracy  97.559814453125\n",
      "\t Epoch Loss  1.5366647243499756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  248\n",
      "\t Training accuracy:  99.37188042534723\n",
      "\t Validation accuracy  97.50712076822917\n",
      "\t Epoch Loss  1.5358636379241943\n",
      "Epoch Number :  249\n",
      "\t Training accuracy:  99.51388888888889\n",
      "\t Validation accuracy  97.50386555989583\n",
      "\t Epoch Loss  1.535118579864502\n",
      "Epoch Number :  250\n",
      "\t Training accuracy:  99.54257541232639\n",
      "\t Validation accuracy  97.55228678385417\n",
      "\t Epoch Loss  1.5340161323547363\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  99.55729166666667\n",
      "\t Validation accuracy  97.56022135416667\n",
      "\t Epoch Loss  1.5333691835403442\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  99.59296332465277\n",
      "\t Validation accuracy  97.56978352864583\n",
      "\t Epoch Loss  1.5324745178222656\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  99.57478841145833\n",
      "\t Validation accuracy  97.51871744791667\n",
      "\t Epoch Loss  1.5313079357147217\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  99.56990559895833\n",
      "\t Validation accuracy  97.63163248697917\n",
      "\t Epoch Loss  1.5302767753601074\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  99.573974609375\n",
      "\t Validation accuracy  97.61372884114583\n",
      "\t Epoch Loss  1.5295600891113281\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  99.560546875\n",
      "\t Validation accuracy  97.55533854166667\n",
      "\t Epoch Loss  1.528639316558838\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  99.57377115885417\n",
      "\t Validation accuracy  97.55452473958333\n",
      "\t Epoch Loss  1.5276597738265991\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  99.57051595052083\n",
      "\t Validation accuracy  97.54231770833333\n",
      "\t Epoch Loss  1.5266709327697754\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  99.564208984375\n",
      "\t Validation accuracy  97.56551106770833\n",
      "\t Epoch Loss  1.5257034301757812\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  99.56658257378473\n",
      "\t Validation accuracy  97.54170735677083\n",
      "\t Epoch Loss  1.524730920791626\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  99.56007215711806\n",
      "\t Validation accuracy  97.532958984375\n",
      "\t Epoch Loss  1.5236914157867432\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  99.56902398003473\n",
      "\t Validation accuracy  97.5592041015625\n",
      "\t Epoch Loss  1.5225168466567993\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  99.56732855902777\n",
      "\t Validation accuracy  97.5518798828125\n",
      "\t Epoch Loss  1.5211012363433838\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  99.566650390625\n",
      "\t Validation accuracy  97.54597981770833\n",
      "\t Epoch Loss  1.5195515155792236\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  99.573974609375\n",
      "\t Validation accuracy  97.55533854166667\n",
      "\t Epoch Loss  1.5180145502090454\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  99.57017686631944\n",
      "\t Validation accuracy  97.55330403645833\n",
      "\t Epoch Loss  1.5164005756378174\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  99.57261827256944\n",
      "\t Validation accuracy  97.55716959635417\n",
      "\t Epoch Loss  1.5147511959075928\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  99.57960340711806\n",
      "\t Validation accuracy  97.55940755208333\n",
      "\t Epoch Loss  1.5131739377975464\n",
      "Epoch Number :  269\n",
      "\t Training accuracy:  99.57987467447917\n",
      "\t Validation accuracy  97.559814453125\n",
      "\t Epoch Loss  1.51153564453125\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  99.58645290798611\n",
      "\t Validation accuracy  97.567138671875\n",
      "\t Epoch Loss  1.5099033117294312\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  99.59099663628473\n",
      "\t Validation accuracy  97.5640869140625\n",
      "\t Epoch Loss  1.5083959102630615\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  99.59303114149306\n",
      "\t Validation accuracy  97.55900065104167\n",
      "\t Epoch Loss  1.5070079565048218\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  99.59832085503473\n",
      "\t Validation accuracy  97.56368001302083\n",
      "\t Epoch Loss  1.5055952072143555\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  99.60150824652777\n",
      "\t Validation accuracy  97.55879720052083\n",
      "\t Epoch Loss  1.504153847694397\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  99.60584852430556\n",
      "\t Validation accuracy  97.5567626953125\n",
      "\t Epoch Loss  1.5026885271072388\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  99.61107042100694\n",
      "\t Validation accuracy  97.56368001302083\n",
      "\t Epoch Loss  1.5011825561523438\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  99.61412217881944\n",
      "\t Validation accuracy  97.56266276041667\n",
      "\t Epoch Loss  1.4997310638427734\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  99.62029351128473\n",
      "\t Validation accuracy  97.56388346354167\n",
      "\t Epoch Loss  1.498380422592163\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  99.62422688802083\n",
      "\t Validation accuracy  97.56001790364583\n",
      "\t Epoch Loss  1.4972398281097412\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  99.62917751736111\n",
      "\t Validation accuracy  97.55859375\n",
      "\t Epoch Loss  1.496262788772583\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  99.63616265190973\n",
      "\t Validation accuracy  97.55879720052083\n",
      "\t Epoch Loss  1.4953662157058716\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target).long()  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True).long() # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    Noutputs = 1\n",
    "    \n",
    "Nbatches = int(math.ceil(Ntrain/batch_size)) #batch_size is defined above\n",
    "Nepochs = 1000\n",
    "Nrep = 1\n",
    "        \n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "model = UnetGenerator_3d(in_dim=1, out_dim=Noutputs, num_filter=4)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.90)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "#optimizer = optim.RMSprop(model.parameters())\n",
    "#optimizer = optim.Rprop(model.parameters())\n",
    " \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_ep in range(Nepochs):\n",
    "    for b_start in range(0, Ntrain, batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "        if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "        else:\n",
    "            #if delta model is chosen\n",
    "            #batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output.view(bsize_eff,grid_size,grid_size,grid_size), train_target.narrow(0, b_start, bsize_eff))\n",
    "        ep_loss[i_ep] += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step(ep_loss[i_ep])\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target, batch_size, criterion)\n",
    "    nb_validation_errs = compute_nb_errors(model, validation_input, validation_target, batch_size, criterion)\n",
    "\n",
    "    Ntrain_nb = Ntrain*grid_size**3\n",
    "    Nvalidation_nb = Nvalidation*grid_size**3\n",
    "    print(\"Epoch Number : \", i_ep)\n",
    "    print(\"\\t Training accuracy: \", (100*(Ntrain_nb-nb_train_errs)/Ntrain_nb))\n",
    "    print(\"\\t Validation accuracy \",(100*(Nvalidation_nb-nb_validation_errs)/Nvalidation_nb))\n",
    "\n",
    "    print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "\n",
    "    train_errors[i_ep] = nb_train_errs\n",
    "    validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array(100*(Ntrain_nb-train_errors)/Ntrain_nb)\n",
    "validation_accurcy = np.array(100*(Nvalidation_nb-validation_errors)/Nvalidation_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accurcy)\n",
    "plt.savefig('Conv3D - Polycubes-Grid_size32-CE-Sigmoid-Adamax.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visualisation = output[14,1,:,:,:].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = np.array(test_visualisation.data)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels)\n",
    "fig.savefig('VoxelizedFinal.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
