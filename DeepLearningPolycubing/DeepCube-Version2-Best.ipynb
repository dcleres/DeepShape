{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define from where to load the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 32\n",
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 \n",
    "validation_size=50\n",
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target, validation_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:,0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "image_size = 32\n",
    "\n",
    "train_input = np.array(preprocessed_input_train.view(Ntrain, 1,image_size, image_size, image_size))\n",
    "validation_input = np.array(preprocessed_input_validation.view(Nvalidation, 1,image_size, image_size, image_size))\n",
    "\n",
    "labels_train = np.array(preprocessed_input_train_target.view(Ntrain, 1, image_size, image_size, image_size))\n",
    "labels_validation = np.array(preprocessed_input_validation_target.view(Nvalidation, 1,image_size, image_size, image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the target \n",
    "Find the middle of the cube and the distance to the x, y and z boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input torch.Size([550, 1, 32, 32, 32])\n",
      "labels_train_cube_coords torch.Size([550, 1, 9])\n",
      "validation_input torch.Size([50, 1, 32, 32, 32])\n",
      "labels_validation_cube_coords torch.Size([50, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "labels_train_cube_coords = np.zeros((len(train_input[:,0,0,0,0]), 1, 9))\n",
    "for i in range (len(train_input[:,0,0,0,0])):\n",
    "    #solution 1 - the loss is calculed based on the 9 labels \n",
    "    delta_x_left, delta_x_right, center_x, delta_y_left, delta_y_right, center_y, delta_z_left, delta_z_right, center_z = find_center_and_delta(labels_train[i, 0, :, :, :], grid_size=32)\n",
    "    labels_train_cube_coords[i,0,0] = delta_x_left\n",
    "    labels_train_cube_coords[i,0,1] = delta_x_right\n",
    "    labels_train_cube_coords[i,0,2] = center_x\n",
    "    labels_train_cube_coords[i,0,3] = delta_y_left\n",
    "    labels_train_cube_coords[i,0,4] = delta_y_right\n",
    "    labels_train_cube_coords[i,0,5] = center_y\n",
    "    labels_train_cube_coords[i,0,6] = delta_z_left\n",
    "    labels_train_cube_coords[i,0,7] = delta_z_right\n",
    "    labels_train_cube_coords[i,0,8] = center_z\n",
    "    \n",
    "labels_validation_cube_coords = np.zeros((len(labels_validation[:,0,0,0,0]), 1, 9))\n",
    "for i in range (len((validation_input[:,0,0,0,0]))):\n",
    "    #solution 1 - the loss is calculed based on the 9 labels \n",
    "    delta_x_left, delta_x_right, center_x, delta_y_left, delta_y_right, center_y, delta_z_left, delta_z_right, center_z = find_center_and_delta(labels_train[i, 0, :, :, :], grid_size=32)\n",
    "    labels_validation_cube_coords[i, 0,0] = delta_x_left\n",
    "    labels_validation_cube_coords[i, 0,1] = delta_x_right\n",
    "    labels_validation_cube_coords[i, 0,2] = center_x\n",
    "    labels_validation_cube_coords[i, 0,3] = delta_y_left\n",
    "    labels_validation_cube_coords[i, 0,4] = delta_y_right\n",
    "    labels_validation_cube_coords[i, 0,5] = center_y\n",
    "    labels_validation_cube_coords[i, 0,6] = delta_z_left\n",
    "    labels_validation_cube_coords[i, 0,7] = delta_z_right\n",
    "    labels_validation_cube_coords[i, 0,8] = center_z\n",
    "    \n",
    "    \n",
    "labels_validation_cube_coords = torch.from_numpy(labels_validation_cube_coords)\n",
    "labels_train_cube_coords = torch.from_numpy(labels_train_cube_coords)\n",
    "train_input = torch.from_numpy(train_input)\n",
    "validation_input = torch.from_numpy(validation_input)\n",
    "\n",
    "print('train_input', train_input.shape)\n",
    "print('labels_train_cube_coords', labels_train_cube_coords.shape)\n",
    "\n",
    "print('validation_input', validation_input.shape)\n",
    "print('labels_validation_cube_coords', labels_validation_cube_coords.shape)\n",
    "\n",
    "    \n",
    "    #solution 2 - the loss is calculated from the cube generated thanks to the learned coordinates \n",
    "    #output = build_cube(delta_x_left, delta_x_right, center_x, delta_y_left, delta_y_right, center_y, delta_z_left, delta_z_right, center_z, grid_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  0\n",
      "\t Training accuracy:  98.58585858585859\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  2527.916748046875\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  227.7554168701172\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  159.5004119873047\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  147.3355712890625\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  162.86672973632812\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  98.76767676767676\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  178.31932067871094\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  98.56565656565657\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  186.02066040039062\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  98.56565656565657\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  194.75328063964844\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  98.64646464646465\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  265.11260986328125\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  98.38383838383838\n",
      "\t Validation accuracy  80.44444444444444\n",
      "\t Epoch Loss  389.93255615234375\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  98.26262626262626\n",
      "\t Validation accuracy  81.77777777777777\n",
      "\t Epoch Loss  621.2487182617188\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  98.36363636363636\n",
      "\t Validation accuracy  81.11111111111111\n",
      "\t Epoch Loss  898.6278686523438\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  98.42424242424242\n",
      "\t Validation accuracy  81.11111111111111\n",
      "\t Epoch Loss  1092.4393310546875\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  98.32323232323232\n",
      "\t Validation accuracy  82.0\n",
      "\t Epoch Loss  728.1780395507812\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  98.64646464646465\n",
      "\t Validation accuracy  82.88888888888889\n",
      "\t Epoch Loss  534.1485595703125\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  98.5050505050505\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  313.0417175292969\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  98.66666666666667\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  223.01638793945312\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  98.5050505050505\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  218.08834838867188\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  98.66666666666667\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  241.9783477783203\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  98.46464646464646\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  290.1992492675781\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  98.32323232323232\n",
      "\t Validation accuracy  82.22222222222223\n",
      "\t Epoch Loss  407.6457214355469\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  98.5050505050505\n",
      "\t Validation accuracy  82.88888888888889\n",
      "\t Epoch Loss  481.4173278808594\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  98.22222222222223\n",
      "\t Validation accuracy  80.44444444444444\n",
      "\t Epoch Loss  508.9910888671875\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  98.70707070707071\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  474.7932434082031\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  98.62626262626263\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  210.49400329589844\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  98.68686868686869\n",
      "\t Validation accuracy  82.88888888888889\n",
      "\t Epoch Loss  148.38290405273438\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  98.74747474747475\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  115.95835876464844\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  98.76767676767676\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  107.75177001953125\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  108.22196960449219\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  116.51752471923828\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  98.72727272727273\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  131.7284393310547\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  144.45684814453125\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  148.81007385253906\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  164.93978881835938\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  82.66666666666667\n",
      "\t Epoch Loss  163.32635498046875\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  98.70707070707071\n",
      "\t Validation accuracy  81.77777777777777\n",
      "\t Epoch Loss  132.4206085205078\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  98.66666666666667\n",
      "\t Validation accuracy  82.66666666666667\n",
      "\t Epoch Loss  118.74102783203125\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  130.62686157226562\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  125.3519287109375\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  110.09677124023438\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  98.8080808080808\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  116.36918640136719\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  130.32691955566406\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  98.8080808080808\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  132.0566864013672\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  137.4661865234375\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  98.52525252525253\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  148.68899536132812\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  116.4301528930664\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  84.59083557128906\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  66.80549621582031\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  59.80035400390625\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  54.391971588134766\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  53.518463134765625\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  49.61918258666992\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  43.661563873291016\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  39.7188606262207\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  35.40688705444336\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  32.842227935791016\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  29.78981590270996\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.06791114807129\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  26.54277992248535\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  24.836803436279297\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  24.62912368774414\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  27.941448211669922\n",
      "Epoch Number :  62\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  24.419633865356445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  63\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  30.179521560668945\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  32.2234001159668\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  30.080976486206055\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  31.45897674560547\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  33.778629302978516\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  34.22681427001953\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  35.510528564453125\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  33.08620834350586\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  30.775087356567383\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  40.45595932006836\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  30.174787521362305\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  29.951927185058594\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  36.16175079345703\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  39.77458953857422\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  37.32249069213867\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  98.72727272727273\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  33.74244689941406\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.202213287353516\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  31.14101791381836\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.431751251220703\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  28.187360763549805\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  26.655471801757812\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  25.649337768554688\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  25.79652214050293\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  21.566986083984375\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  22.445642471313477\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  25.932218551635742\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  21.7218017578125\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  22.142684936523438\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  23.134523391723633\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  22.82847023010254\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  26.065555572509766\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  21.22884178161621\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  31.474136352539062\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.596426010131836\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  21.35260772705078\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  25.843141555786133\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  26.275218963623047\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  27.63690948486328\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  17.989187240600586\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  25.613910675048828\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  17.094633102416992\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  23.39579200744629\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  17.91497230529785\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  23.246625900268555\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  31.596384048461914\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  22.09618377685547\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  26.084848403930664\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  27.61357307434082\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  29.259597778320312\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.726844787597656\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  26.289766311645508\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  28.328580856323242\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  28.296716690063477\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  35.27926254272461\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  28.023418426513672\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  26.575624465942383\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  26.281030654907227\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  24.1588134765625\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  27.98431396484375\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  22.042736053466797\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  29.3957576751709\n",
      "Epoch Number :  124\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  29.12175178527832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  125\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  21.87447738647461\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  22.189990997314453\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  20.57637596130371\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  21.26285171508789\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  21.349018096923828\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  15.959776878356934\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  17.102689743041992\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  13.136079788208008\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  15.469438552856445\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  15.7659912109375\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  17.15554428100586\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  24.447120666503906\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  15.135466575622559\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  21.03116226196289\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  21.67159080505371\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  17.64887237548828\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  17.136280059814453\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  16.503536224365234\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  20.305837631225586\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  20.829647064208984\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  16.85997200012207\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.933757781982422\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  16.57103729248047\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  17.563419342041016\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  16.136459350585938\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  18.892505645751953\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  18.087631225585938\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  17.0733585357666\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  17.763874053955078\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  16.366193771362305\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  17.343421936035156\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  23.07899284362793\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  15.3988676071167\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  21.155887603759766\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  22.600618362426758\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  23.107322692871094\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  20.392200469970703\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  24.1265869140625\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  98.74747474747475\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  31.552631378173828\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  28.287578582763672\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  35.43663787841797\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  27.350059509277344\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  24.16710662841797\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  35.33591079711914\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  30.417213439941406\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  33.863826751708984\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  27.89557647705078\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  24.491336822509766\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  25.41852569580078\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  29.673025131225586\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  32.327728271484375\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  26.8139591217041\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  29.767953872680664\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  22.488710403442383\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  23.253774642944336\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  31.96628761291504\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  29.375377655029297\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  24.497440338134766\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  19.561328887939453\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  20.243627548217773\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  16.5633487701416\n",
      "Epoch Number :  186\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  22.149532318115234\n",
      "Epoch Number :  187\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  22.552919387817383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  188\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  16.130935668945312\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  19.67966079711914\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  18.032135009765625\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  18.487520217895508\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  23.160755157470703\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  26.660385131835938\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  14.964457511901855\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  19.303943634033203\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  21.77993392944336\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  19.297122955322266\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  21.98801612854004\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  21.212867736816406\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  22.30820083618164\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  22.754663467407227\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  26.003952026367188\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  27.08466339111328\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  21.63564682006836\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  18.982633590698242\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  23.84247398376465\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  27.95147132873535\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  24.57718276977539\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  29.393537521362305\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  22.527507781982422\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  22.76115608215332\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  23.622716903686523\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  24.651065826416016\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  27.554946899414062\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  28.668516159057617\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  25.50505828857422\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  25.441429138183594\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  27.5893497467041\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  34.37272262573242\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  44.117271423339844\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  29.660812377929688\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  30.089237213134766\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  26.501062393188477\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  23.196393966674805\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  29.310569763183594\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  33.22768020629883\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  34.77376174926758\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  36.57353591918945\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  36.055660247802734\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  26.376981735229492\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  29.13735580444336\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  24.429584503173828\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  23.491378784179688\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  28.42675018310547\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  25.162311553955078\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  24.520042419433594\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  28.446300506591797\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  28.42110252380371\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  31.15127182006836\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  31.711132049560547\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  28.695877075195312\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  28.635780334472656\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  28.93585777282715\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  31.830900192260742\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  24.059627532958984\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  29.767234802246094\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  31.49744415283203\n",
      "Epoch Number :  248\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  27.63345718383789\n",
      "Epoch Number :  249\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  33.636451721191406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  250\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  27.197240829467773\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  98.62626262626263\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  35.50455856323242\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  38.90116882324219\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  25.944936752319336\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  28.16469955444336\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  25.675315856933594\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  24.643434524536133\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  25.748943328857422\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  26.611568450927734\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  26.891008377075195\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  24.125545501708984\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  20.54827308654785\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  23.22733497619629\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  23.24027442932129\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  18.109699249267578\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  15.053871154785156\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  13.78911018371582\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  10.199914932250977\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  9.094910621643066\n",
      "Epoch Number :  269\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.619407653808594\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.078296661376953\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  14.949490547180176\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  16.413143157958984\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.320399284362793\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  16.546743392944336\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  11.104854583740234\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  9.467724800109863\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  8.021291732788086\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  8.376496315002441\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  8.480729103088379\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  15.669750213623047\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  19.586336135864258\n",
      "Epoch Number :  282\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  19.378210067749023\n",
      "Epoch Number :  283\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  16.745779037475586\n",
      "Epoch Number :  284\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  12.783675193786621\n",
      "Epoch Number :  285\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  12.323614120483398\n",
      "Epoch Number :  286\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  11.913581848144531\n",
      "Epoch Number :  287\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  10.646341323852539\n",
      "Epoch Number :  288\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  13.526660919189453\n",
      "Epoch Number :  289\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  14.711860656738281\n",
      "Epoch Number :  290\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  12.758699417114258\n",
      "Epoch Number :  291\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  9.223054885864258\n",
      "Epoch Number :  292\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  8.494752883911133\n",
      "Epoch Number :  293\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.974776268005371\n",
      "Epoch Number :  294\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  11.954277992248535\n",
      "Epoch Number :  295\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.195899963378906\n",
      "Epoch Number :  296\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  12.812387466430664\n",
      "Epoch Number :  297\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  12.471232414245605\n",
      "Epoch Number :  298\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  11.506692886352539\n",
      "Epoch Number :  299\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  11.669081687927246\n",
      "Epoch Number :  300\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  11.634743690490723\n",
      "Epoch Number :  301\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  12.684391975402832\n",
      "Epoch Number :  302\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  13.311572074890137\n",
      "Epoch Number :  303\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  14.558297157287598\n",
      "Epoch Number :  304\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  15.373347282409668\n",
      "Epoch Number :  305\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  15.888855934143066\n",
      "Epoch Number :  306\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  18.25305938720703\n",
      "Epoch Number :  307\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  18.203866958618164\n",
      "Epoch Number :  308\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  19.28909683227539\n",
      "Epoch Number :  309\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  23.16372299194336\n",
      "Epoch Number :  310\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  17.812536239624023\n",
      "Epoch Number :  311\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  15.311753273010254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  312\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  16.490930557250977\n",
      "Epoch Number :  313\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  18.380313873291016\n",
      "Epoch Number :  314\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  23.63107681274414\n",
      "Epoch Number :  315\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  26.087648391723633\n",
      "Epoch Number :  316\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  22.289419174194336\n",
      "Epoch Number :  317\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  30.84143829345703\n",
      "Epoch Number :  318\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  33.756507873535156\n",
      "Epoch Number :  319\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  32.30952453613281\n",
      "Epoch Number :  320\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  38.058467864990234\n",
      "Epoch Number :  321\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  30.52419090270996\n",
      "Epoch Number :  322\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  33.33293914794922\n",
      "Epoch Number :  323\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  29.04801368713379\n",
      "Epoch Number :  324\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  29.284282684326172\n",
      "Epoch Number :  325\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  20.953763961791992\n",
      "Epoch Number :  326\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  10.83242416381836\n",
      "Epoch Number :  327\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  14.637165069580078\n",
      "Epoch Number :  328\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  10.793598175048828\n",
      "Epoch Number :  329\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  11.38102912902832\n",
      "Epoch Number :  330\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  16.893857955932617\n",
      "Epoch Number :  331\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  20.081335067749023\n",
      "Epoch Number :  332\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  14.860114097595215\n",
      "Epoch Number :  333\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  14.24938678741455\n",
      "Epoch Number :  334\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  15.643040657043457\n",
      "Epoch Number :  335\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  15.091073989868164\n",
      "Epoch Number :  336\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  20.048494338989258\n",
      "Epoch Number :  337\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  15.626724243164062\n",
      "Epoch Number :  338\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  14.06496810913086\n",
      "Epoch Number :  339\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  12.186993598937988\n",
      "Epoch Number :  340\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  16.002485275268555\n",
      "Epoch Number :  341\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  13.549288749694824\n",
      "Epoch Number :  342\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  18.461040496826172\n",
      "Epoch Number :  343\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  12.7785062789917\n",
      "Epoch Number :  344\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  14.530879020690918\n",
      "Epoch Number :  345\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  11.99649429321289\n",
      "Epoch Number :  346\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.220274925231934\n",
      "Epoch Number :  347\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  12.009795188903809\n",
      "Epoch Number :  348\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  10.033568382263184\n",
      "Epoch Number :  349\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  10.156160354614258\n",
      "Epoch Number :  350\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  90.22222222222223\n",
      "\t Epoch Loss  11.224427223205566\n",
      "Epoch Number :  351\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  9.496223449707031\n",
      "Epoch Number :  352\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  8.654914855957031\n",
      "Epoch Number :  353\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  9.306342124938965\n",
      "Epoch Number :  354\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  8.794416427612305\n",
      "Epoch Number :  355\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  6.805352687835693\n",
      "Epoch Number :  356\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  8.23799991607666\n",
      "Epoch Number :  357\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  6.680826663970947\n",
      "Epoch Number :  358\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  7.8246941566467285\n",
      "Epoch Number :  359\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  8.048830032348633\n",
      "Epoch Number :  360\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  10.268142700195312\n",
      "Epoch Number :  361\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  9.094243049621582\n",
      "Epoch Number :  362\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  9.713632583618164\n",
      "Epoch Number :  363\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  11.598844528198242\n",
      "Epoch Number :  364\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  11.1570463180542\n",
      "Epoch Number :  365\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  7.873496055603027\n",
      "Epoch Number :  366\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  8.63188362121582\n",
      "Epoch Number :  367\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  7.399597644805908\n",
      "Epoch Number :  368\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  9.7760648727417\n",
      "Epoch Number :  369\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  9.954684257507324\n",
      "Epoch Number :  370\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  10.163580894470215\n",
      "Epoch Number :  371\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  10.568500518798828\n",
      "Epoch Number :  372\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  11.976642608642578\n",
      "Epoch Number :  373\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  13.410611152648926\n",
      "Epoch Number :  374\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  18.978282928466797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  375\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  18.02029037475586\n",
      "Epoch Number :  376\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  15.092598915100098\n",
      "Epoch Number :  377\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  18.351280212402344\n",
      "Epoch Number :  378\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  23.539962768554688\n",
      "Epoch Number :  379\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  90.22222222222223\n",
      "\t Epoch Loss  26.15420150756836\n",
      "Epoch Number :  380\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  16.668188095092773\n",
      "Epoch Number :  381\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  22.000635147094727\n",
      "Epoch Number :  382\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  22.138051986694336\n",
      "Epoch Number :  383\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  23.587574005126953\n",
      "Epoch Number :  384\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.424245834350586\n",
      "Epoch Number :  385\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  17.973800659179688\n",
      "Epoch Number :  386\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  17.48698616027832\n",
      "Epoch Number :  387\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  18.573516845703125\n",
      "Epoch Number :  388\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  21.471036911010742\n",
      "Epoch Number :  389\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  17.1757755279541\n",
      "Epoch Number :  390\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  18.739063262939453\n",
      "Epoch Number :  391\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  14.7036714553833\n",
      "Epoch Number :  392\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  14.037693977355957\n",
      "Epoch Number :  393\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  13.990962028503418\n",
      "Epoch Number :  394\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  19.1020450592041\n",
      "Epoch Number :  395\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  26.410844802856445\n",
      "Epoch Number :  396\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  24.775588989257812\n",
      "Epoch Number :  397\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  21.91425895690918\n",
      "Epoch Number :  398\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  16.558488845825195\n",
      "Epoch Number :  399\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  18.575969696044922\n",
      "Epoch Number :  400\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  17.153499603271484\n",
      "Epoch Number :  401\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  19.191194534301758\n",
      "Epoch Number :  402\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  23.02177619934082\n",
      "Epoch Number :  403\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  24.280170440673828\n",
      "Epoch Number :  404\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  18.160444259643555\n",
      "Epoch Number :  405\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  23.188486099243164\n",
      "Epoch Number :  406\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  22.213796615600586\n",
      "Epoch Number :  407\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  20.652711868286133\n",
      "Epoch Number :  408\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  20.519256591796875\n",
      "Epoch Number :  409\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  16.291318893432617\n",
      "Epoch Number :  410\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  17.898788452148438\n",
      "Epoch Number :  411\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  20.001985549926758\n",
      "Epoch Number :  412\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  21.057527542114258\n",
      "Epoch Number :  413\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  15.53274917602539\n",
      "Epoch Number :  414\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  21.164215087890625\n",
      "Epoch Number :  415\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  15.988934516906738\n",
      "Epoch Number :  416\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  13.970196723937988\n",
      "Epoch Number :  417\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  19.396512985229492\n",
      "Epoch Number :  418\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.28998565673828\n",
      "Epoch Number :  419\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  16.04439926147461\n",
      "Epoch Number :  420\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  19.687602996826172\n",
      "Epoch Number :  421\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  27.485551834106445\n",
      "Epoch Number :  422\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  15.99190902709961\n",
      "Epoch Number :  423\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  89.33333333333333\n",
      "\t Epoch Loss  11.548346519470215\n",
      "Epoch Number :  424\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  14.438895225524902\n",
      "Epoch Number :  425\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  30.16206169128418\n",
      "Epoch Number :  426\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  20.46146011352539\n",
      "Epoch Number :  427\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  13.686646461486816\n",
      "Epoch Number :  428\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  14.072797775268555\n",
      "Epoch Number :  429\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  16.926441192626953\n",
      "Epoch Number :  430\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  24.146852493286133\n",
      "Epoch Number :  431\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  15.480445861816406\n",
      "Epoch Number :  432\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  24.356285095214844\n",
      "Epoch Number :  433\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  11.338346481323242\n",
      "Epoch Number :  434\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  12.163771629333496\n",
      "Epoch Number :  435\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  16.64203453063965\n",
      "Epoch Number :  436\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  14.147716522216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  437\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  11.612226486206055\n",
      "Epoch Number :  438\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  15.963749885559082\n",
      "Epoch Number :  439\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.109597206115723\n",
      "Epoch Number :  440\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  22.534582138061523\n",
      "Epoch Number :  441\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  22.25941276550293\n",
      "Epoch Number :  442\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  20.53879737854004\n",
      "Epoch Number :  443\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  13.674427032470703\n",
      "Epoch Number :  444\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  15.094728469848633\n",
      "Epoch Number :  445\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  21.959453582763672\n",
      "Epoch Number :  446\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  24.12537956237793\n",
      "Epoch Number :  447\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  20.661108016967773\n",
      "Epoch Number :  448\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  26.960559844970703\n",
      "Epoch Number :  449\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  28.136598587036133\n",
      "Epoch Number :  450\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  15.163446426391602\n",
      "Epoch Number :  451\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  12.330979347229004\n",
      "Epoch Number :  452\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  17.279529571533203\n",
      "Epoch Number :  453\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  29.576160430908203\n",
      "Epoch Number :  454\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  26.96851348876953\n",
      "Epoch Number :  455\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  24.769502639770508\n",
      "Epoch Number :  456\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  22.916950225830078\n",
      "Epoch Number :  457\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  22.053138732910156\n",
      "Epoch Number :  458\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  31.71858787536621\n",
      "Epoch Number :  459\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  22.602670669555664\n",
      "Epoch Number :  460\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  26.380428314208984\n",
      "Epoch Number :  461\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  25.9550838470459\n",
      "Epoch Number :  462\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.513181686401367\n",
      "Epoch Number :  463\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  34.07484436035156\n",
      "Epoch Number :  464\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  28.99261474609375\n",
      "Epoch Number :  465\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  26.823156356811523\n",
      "Epoch Number :  466\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  36.939151763916016\n",
      "Epoch Number :  467\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  41.96530532836914\n",
      "Epoch Number :  468\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  24.967300415039062\n",
      "Epoch Number :  469\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  22.923627853393555\n",
      "Epoch Number :  470\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  40.00463104248047\n",
      "Epoch Number :  471\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  44.349178314208984\n",
      "Epoch Number :  472\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  33.50605392456055\n",
      "Epoch Number :  473\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  13.07869815826416\n",
      "Epoch Number :  474\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  53.81058883666992\n",
      "Epoch Number :  475\n",
      "\t Training accuracy:  98.76767676767676\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  50.030765533447266\n",
      "Epoch Number :  476\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  45.39692687988281\n",
      "Epoch Number :  477\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  30.32671546936035\n",
      "Epoch Number :  478\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  57.572139739990234\n",
      "Epoch Number :  479\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  54.80112075805664\n",
      "Epoch Number :  480\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  62.62943649291992\n",
      "Epoch Number :  481\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  82.66666666666667\n",
      "\t Epoch Loss  68.89710235595703\n",
      "Epoch Number :  482\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  73.70047760009766\n",
      "Epoch Number :  483\n",
      "\t Training accuracy:  98.86868686868686\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  56.53834915161133\n",
      "Epoch Number :  484\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  30.695755004882812\n",
      "Epoch Number :  485\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  40.24785232543945\n",
      "Epoch Number :  486\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  43.85400390625\n",
      "Epoch Number :  487\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  30.52777862548828\n",
      "Epoch Number :  488\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  82.22222222222223\n",
      "\t Epoch Loss  92.06324005126953\n",
      "Epoch Number :  489\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  85.90764617919922\n",
      "Epoch Number :  490\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  57.708740234375\n",
      "Epoch Number :  491\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  38.27162170410156\n",
      "Epoch Number :  492\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  81.77777777777777\n",
      "\t Epoch Loss  65.7574691772461\n",
      "Epoch Number :  493\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  45.608619689941406\n",
      "Epoch Number :  494\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  50.7955322265625\n",
      "Epoch Number :  495\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  82.66666666666667\n",
      "\t Epoch Loss  38.370384216308594\n",
      "Epoch Number :  496\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  64.00408172607422\n",
      "Epoch Number :  497\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  56.17877960205078\n",
      "Epoch Number :  498\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  53.95439910888672\n",
      "Epoch Number :  499\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  29.53509521484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  500\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  45.737545013427734\n",
      "Epoch Number :  501\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  40.55906295776367\n",
      "Epoch Number :  502\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  82.88888888888889\n",
      "\t Epoch Loss  91.17011260986328\n",
      "Epoch Number :  503\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  76.3609848022461\n",
      "Epoch Number :  504\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  55.81992721557617\n",
      "Epoch Number :  505\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  36.32073211669922\n",
      "Epoch Number :  506\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  77.04747009277344\n",
      "Epoch Number :  507\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  60.06214141845703\n",
      "Epoch Number :  508\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  69.8178939819336\n",
      "Epoch Number :  509\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  69.90383911132812\n",
      "Epoch Number :  510\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  75.47728729248047\n",
      "Epoch Number :  511\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  83.58808135986328\n",
      "Epoch Number :  512\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  61.487464904785156\n",
      "Epoch Number :  513\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  60.95148468017578\n",
      "Epoch Number :  514\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  25.962230682373047\n",
      "Epoch Number :  515\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  53.654624938964844\n",
      "Epoch Number :  516\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  33.74496841430664\n",
      "Epoch Number :  517\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  66.88175964355469\n",
      "Epoch Number :  518\n",
      "\t Training accuracy:  98.84848484848484\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  54.65631866455078\n",
      "Epoch Number :  519\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  43.031368255615234\n",
      "Epoch Number :  520\n",
      "\t Training accuracy:  98.66666666666667\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  30.29958152770996\n",
      "Epoch Number :  521\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  33.16061782836914\n",
      "Epoch Number :  522\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  22.944765090942383\n",
      "Epoch Number :  523\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  20.43565559387207\n",
      "Epoch Number :  524\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  28.394596099853516\n",
      "Epoch Number :  525\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  16.089494705200195\n",
      "Epoch Number :  526\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  37.05242919921875\n",
      "Epoch Number :  527\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  22.78384017944336\n",
      "Epoch Number :  528\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.507179260253906\n",
      "Epoch Number :  529\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  36.6851806640625\n",
      "Epoch Number :  530\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  18.767742156982422\n",
      "Epoch Number :  531\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  27.941455841064453\n",
      "Epoch Number :  532\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  33.6866455078125\n",
      "Epoch Number :  533\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  19.392715454101562\n",
      "Epoch Number :  534\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  31.36663055419922\n",
      "Epoch Number :  535\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  33.67137908935547\n",
      "Epoch Number :  536\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  20.8696346282959\n",
      "Epoch Number :  537\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  19.90505027770996\n",
      "Epoch Number :  538\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  14.170732498168945\n",
      "Epoch Number :  539\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  16.987585067749023\n",
      "Epoch Number :  540\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  24.568727493286133\n",
      "Epoch Number :  541\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  37.31947326660156\n",
      "Epoch Number :  542\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  24.36972427368164\n",
      "Epoch Number :  543\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  27.984283447265625\n",
      "Epoch Number :  544\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  31.281085968017578\n",
      "Epoch Number :  545\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  16.747928619384766\n",
      "Epoch Number :  546\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  27.246110916137695\n",
      "Epoch Number :  547\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  24.550601959228516\n",
      "Epoch Number :  548\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  15.912738800048828\n",
      "Epoch Number :  549\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  25.736963272094727\n",
      "Epoch Number :  550\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  41.74283981323242\n",
      "Epoch Number :  551\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  13.169647216796875\n",
      "Epoch Number :  552\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  8.723701477050781\n",
      "Epoch Number :  553\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  9.637774467468262\n",
      "Epoch Number :  554\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  9.654012680053711\n",
      "Epoch Number :  555\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  10.734060287475586\n",
      "Epoch Number :  556\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  11.179582595825195\n",
      "Epoch Number :  557\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  11.727375984191895\n",
      "Epoch Number :  558\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  13.530804634094238\n",
      "Epoch Number :  559\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  14.466888427734375\n",
      "Epoch Number :  560\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  17.386396408081055\n",
      "Epoch Number :  561\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  13.931123733520508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  562\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.617511749267578\n",
      "Epoch Number :  563\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  17.51309585571289\n",
      "Epoch Number :  564\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  21.480976104736328\n",
      "Epoch Number :  565\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  13.233640670776367\n",
      "Epoch Number :  566\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  14.147540092468262\n",
      "Epoch Number :  567\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  15.440427780151367\n",
      "Epoch Number :  568\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.857383728027344\n",
      "Epoch Number :  569\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  13.382222175598145\n",
      "Epoch Number :  570\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  11.850433349609375\n",
      "Epoch Number :  571\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  12.947622299194336\n",
      "Epoch Number :  572\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  14.54593276977539\n",
      "Epoch Number :  573\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  10.559816360473633\n",
      "Epoch Number :  574\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.70130729675293\n",
      "Epoch Number :  575\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  15.584904670715332\n",
      "Epoch Number :  576\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  17.598857879638672\n",
      "Epoch Number :  577\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  17.413249969482422\n",
      "Epoch Number :  578\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  17.86678695678711\n",
      "Epoch Number :  579\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.861578941345215\n",
      "Epoch Number :  580\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.951302528381348\n",
      "Epoch Number :  581\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  11.304370880126953\n",
      "Epoch Number :  582\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  12.359105110168457\n",
      "Epoch Number :  583\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  17.788297653198242\n",
      "Epoch Number :  584\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  19.992029190063477\n",
      "Epoch Number :  585\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  13.617536544799805\n",
      "Epoch Number :  586\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  22.363637924194336\n",
      "Epoch Number :  587\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  18.914281845092773\n",
      "Epoch Number :  588\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  17.03851890563965\n",
      "Epoch Number :  589\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  16.393760681152344\n",
      "Epoch Number :  590\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  18.40725326538086\n",
      "Epoch Number :  591\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  20.871049880981445\n",
      "Epoch Number :  592\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  24.799610137939453\n",
      "Epoch Number :  593\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  21.184146881103516\n",
      "Epoch Number :  594\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  21.411602020263672\n",
      "Epoch Number :  595\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  18.036645889282227\n",
      "Epoch Number :  596\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  10.549446105957031\n",
      "Epoch Number :  597\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  12.754076957702637\n",
      "Epoch Number :  598\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  12.497403144836426\n",
      "Epoch Number :  599\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  9.357059478759766\n",
      "Epoch Number :  600\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  10.904075622558594\n",
      "Epoch Number :  601\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  13.46609878540039\n",
      "Epoch Number :  602\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  11.622693061828613\n",
      "Epoch Number :  603\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  14.389689445495605\n",
      "Epoch Number :  604\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  16.66160011291504\n",
      "Epoch Number :  605\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  13.840343475341797\n",
      "Epoch Number :  606\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  15.564905166625977\n",
      "Epoch Number :  607\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  18.176193237304688\n",
      "Epoch Number :  608\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  13.568462371826172\n",
      "Epoch Number :  609\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  12.23532485961914\n",
      "Epoch Number :  610\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  13.373011589050293\n",
      "Epoch Number :  611\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  14.691755294799805\n",
      "Epoch Number :  612\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  12.863420486450195\n",
      "Epoch Number :  613\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  15.911335945129395\n",
      "Epoch Number :  614\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  14.282743453979492\n",
      "Epoch Number :  615\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  15.449331283569336\n",
      "Epoch Number :  616\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  14.410969734191895\n",
      "Epoch Number :  617\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  18.940628051757812\n",
      "Epoch Number :  618\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  16.040992736816406\n",
      "Epoch Number :  619\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  15.993382453918457\n",
      "Epoch Number :  620\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  19.335893630981445\n",
      "Epoch Number :  621\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  18.02678871154785\n",
      "Epoch Number :  622\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  22.12596893310547\n",
      "Epoch Number :  623\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  20.369098663330078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  624\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  20.79340171813965\n",
      "Epoch Number :  625\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  14.94719123840332\n",
      "Epoch Number :  626\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  18.06475830078125\n",
      "Epoch Number :  627\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  21.793895721435547\n",
      "Epoch Number :  628\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  18.452205657958984\n",
      "Epoch Number :  629\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  21.551424026489258\n",
      "Epoch Number :  630\n",
      "\t Training accuracy:  99.39393939393939\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  25.76047706604004\n",
      "Epoch Number :  631\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  81.33333333333333\n",
      "\t Epoch Loss  36.623268127441406\n",
      "Epoch Number :  632\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  36.44172286987305\n",
      "Epoch Number :  633\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  27.843183517456055\n",
      "Epoch Number :  634\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  28.692867279052734\n",
      "Epoch Number :  635\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  23.27129554748535\n",
      "Epoch Number :  636\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  33.26399612426758\n",
      "Epoch Number :  637\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  40.122920989990234\n",
      "Epoch Number :  638\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  44.36928176879883\n",
      "Epoch Number :  639\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  40.24235916137695\n",
      "Epoch Number :  640\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  45.07792663574219\n",
      "Epoch Number :  641\n",
      "\t Training accuracy:  98.86868686868686\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  44.833641052246094\n",
      "Epoch Number :  642\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  35.70159149169922\n",
      "Epoch Number :  643\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  27.59110450744629\n",
      "Epoch Number :  644\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  33.35845947265625\n",
      "Epoch Number :  645\n",
      "\t Training accuracy:  98.82828282828282\n",
      "\t Validation accuracy  82.66666666666667\n",
      "\t Epoch Loss  57.08845901489258\n",
      "Epoch Number :  646\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  30.372095108032227\n",
      "Epoch Number :  647\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  29.418495178222656\n",
      "Epoch Number :  648\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  30.570919036865234\n",
      "Epoch Number :  649\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  37.035152435302734\n",
      "Epoch Number :  650\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  79.62128448486328\n",
      "Epoch Number :  651\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  45.35007095336914\n",
      "Epoch Number :  652\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  61.41672897338867\n",
      "Epoch Number :  653\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  66.26158905029297\n",
      "Epoch Number :  654\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  108.28881072998047\n",
      "Epoch Number :  655\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  74.98445129394531\n",
      "Epoch Number :  656\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  55.39457702636719\n",
      "Epoch Number :  657\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  49.61312484741211\n",
      "Epoch Number :  658\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  62.937522888183594\n",
      "Epoch Number :  659\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  49.12941360473633\n",
      "Epoch Number :  660\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  72.9431381225586\n",
      "Epoch Number :  661\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  90.85872650146484\n",
      "Epoch Number :  662\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  58.52191925048828\n",
      "Epoch Number :  663\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  46.96027374267578\n",
      "Epoch Number :  664\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  60.849021911621094\n",
      "Epoch Number :  665\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  61.674034118652344\n",
      "Epoch Number :  666\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  54.30985641479492\n",
      "Epoch Number :  667\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  57.23500061035156\n",
      "Epoch Number :  668\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  96.93704986572266\n",
      "Epoch Number :  669\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  79.26821899414062\n",
      "Epoch Number :  670\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  81.3130874633789\n",
      "Epoch Number :  671\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  52.78412628173828\n",
      "Epoch Number :  672\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  62.078338623046875\n",
      "Epoch Number :  673\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  77.24565887451172\n",
      "Epoch Number :  674\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  92.3519515991211\n",
      "Epoch Number :  675\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  67.29583740234375\n",
      "Epoch Number :  676\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  71.1678466796875\n",
      "Epoch Number :  677\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  66.41991424560547\n",
      "Epoch Number :  678\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  70.80813598632812\n",
      "Epoch Number :  679\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  87.06722259521484\n",
      "Epoch Number :  680\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  79.8139877319336\n",
      "Epoch Number :  681\n",
      "\t Training accuracy:  98.68686868686869\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  67.67373657226562\n",
      "Epoch Number :  682\n",
      "\t Training accuracy:  98.78787878787878\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  51.12408447265625\n",
      "Epoch Number :  683\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  37.573421478271484\n",
      "Epoch Number :  684\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  24.81366729736328\n",
      "Epoch Number :  685\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  16.647891998291016\n",
      "Epoch Number :  686\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  9.49416446685791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  687\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  10.88304615020752\n",
      "Epoch Number :  688\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  7.901096820831299\n",
      "Epoch Number :  689\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  6.550812244415283\n",
      "Epoch Number :  690\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  5.627173900604248\n",
      "Epoch Number :  691\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  5.406783580780029\n",
      "Epoch Number :  692\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  5.344302654266357\n",
      "Epoch Number :  693\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  5.097585678100586\n",
      "Epoch Number :  694\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  5.337978363037109\n",
      "Epoch Number :  695\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  4.831048488616943\n",
      "Epoch Number :  696\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  5.425536632537842\n",
      "Epoch Number :  697\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  4.595261096954346\n",
      "Epoch Number :  698\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  5.499731063842773\n",
      "Epoch Number :  699\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  89.33333333333333\n",
      "\t Epoch Loss  4.080506324768066\n",
      "Epoch Number :  700\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  5.9714765548706055\n",
      "Epoch Number :  701\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  3.948840618133545\n",
      "Epoch Number :  702\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  8.220111846923828\n",
      "Epoch Number :  703\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  5.376552581787109\n",
      "Epoch Number :  704\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  16.27805519104004\n",
      "Epoch Number :  705\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  15.906941413879395\n",
      "Epoch Number :  706\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  33.905155181884766\n",
      "Epoch Number :  707\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  46.872779846191406\n",
      "Epoch Number :  708\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  45.28886413574219\n",
      "Epoch Number :  709\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  33.991764068603516\n",
      "Epoch Number :  710\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  35.05197525024414\n",
      "Epoch Number :  711\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  45.83767318725586\n",
      "Epoch Number :  712\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  25.97606658935547\n",
      "Epoch Number :  713\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  33.30464553833008\n",
      "Epoch Number :  714\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  35.66564178466797\n",
      "Epoch Number :  715\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  27.35193634033203\n",
      "Epoch Number :  716\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  29.85833168029785\n",
      "Epoch Number :  717\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  31.105472564697266\n",
      "Epoch Number :  718\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  30.910799026489258\n",
      "Epoch Number :  719\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  34.023075103759766\n",
      "Epoch Number :  720\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  23.472959518432617\n",
      "Epoch Number :  721\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  31.630802154541016\n",
      "Epoch Number :  722\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  40.45756912231445\n",
      "Epoch Number :  723\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  22.98379135131836\n",
      "Epoch Number :  724\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  23.200096130371094\n",
      "Epoch Number :  725\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  30.986591339111328\n",
      "Epoch Number :  726\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  21.7840633392334\n",
      "Epoch Number :  727\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  20.766511917114258\n",
      "Epoch Number :  728\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  21.126585006713867\n",
      "Epoch Number :  729\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  27.71634292602539\n",
      "Epoch Number :  730\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  20.192054748535156\n",
      "Epoch Number :  731\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  19.988773345947266\n",
      "Epoch Number :  732\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  25.52172088623047\n",
      "Epoch Number :  733\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  21.012718200683594\n",
      "Epoch Number :  734\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  24.65569305419922\n",
      "Epoch Number :  735\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  29.634883880615234\n",
      "Epoch Number :  736\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  20.92742347717285\n",
      "Epoch Number :  737\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  20.277177810668945\n",
      "Epoch Number :  738\n",
      "\t Training accuracy:  98.84848484848484\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  29.619007110595703\n",
      "Epoch Number :  739\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  16.22245216369629\n",
      "Epoch Number :  740\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  19.06676483154297\n",
      "Epoch Number :  741\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  21.572330474853516\n",
      "Epoch Number :  742\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  19.81492042541504\n",
      "Epoch Number :  743\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  16.14134979248047\n",
      "Epoch Number :  744\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  22.004884719848633\n",
      "Epoch Number :  745\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  21.678476333618164\n",
      "Epoch Number :  746\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.997392654418945\n",
      "Epoch Number :  747\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  22.36631202697754\n",
      "Epoch Number :  748\n",
      "\t Training accuracy:  99.07070707070707\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  18.7529296875\n",
      "Epoch Number :  749\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  14.086016654968262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  750\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  17.24879264831543\n",
      "Epoch Number :  751\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  18.748092651367188\n",
      "Epoch Number :  752\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  14.232183456420898\n",
      "Epoch Number :  753\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  17.46814727783203\n",
      "Epoch Number :  754\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  17.169677734375\n",
      "Epoch Number :  755\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  14.237252235412598\n",
      "Epoch Number :  756\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  15.630884170532227\n",
      "Epoch Number :  757\n",
      "\t Training accuracy:  98.88888888888889\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  14.700925827026367\n",
      "Epoch Number :  758\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  15.474408149719238\n",
      "Epoch Number :  759\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  9.276716232299805\n",
      "Epoch Number :  760\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  90.44444444444444\n",
      "\t Epoch Loss  5.47860860824585\n",
      "Epoch Number :  761\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  89.55555555555556\n",
      "\t Epoch Loss  5.115049839019775\n",
      "Epoch Number :  762\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  4.427631378173828\n",
      "Epoch Number :  763\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  89.77777777777777\n",
      "\t Epoch Loss  3.351606607437134\n",
      "Epoch Number :  764\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  90.22222222222223\n",
      "\t Epoch Loss  2.913408041000366\n",
      "Epoch Number :  765\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  90.22222222222223\n",
      "\t Epoch Loss  3.113219738006592\n",
      "Epoch Number :  766\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  4.204617500305176\n",
      "Epoch Number :  767\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  4.631911754608154\n",
      "Epoch Number :  768\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  89.33333333333333\n",
      "\t Epoch Loss  6.004298686981201\n",
      "Epoch Number :  769\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  7.709689140319824\n",
      "Epoch Number :  770\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  6.612563133239746\n",
      "Epoch Number :  771\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  8.245280265808105\n",
      "Epoch Number :  772\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  6.495004653930664\n",
      "Epoch Number :  773\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  5.178640842437744\n",
      "Epoch Number :  774\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  5.090822219848633\n",
      "Epoch Number :  775\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  5.164090633392334\n",
      "Epoch Number :  776\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  7.881245136260986\n",
      "Epoch Number :  777\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  5.098698616027832\n",
      "Epoch Number :  778\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  5.202645778656006\n",
      "Epoch Number :  779\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  3.9108188152313232\n",
      "Epoch Number :  780\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  4.099289417266846\n",
      "Epoch Number :  781\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  3.6493289470672607\n",
      "Epoch Number :  782\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  4.144123554229736\n",
      "Epoch Number :  783\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  4.2846574783325195\n",
      "Epoch Number :  784\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  5.58896017074585\n",
      "Epoch Number :  785\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  3.5330328941345215\n",
      "Epoch Number :  786\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  89.55555555555556\n",
      "\t Epoch Loss  3.0846405029296875\n",
      "Epoch Number :  787\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  4.447282314300537\n",
      "Epoch Number :  788\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  3.74406099319458\n",
      "Epoch Number :  789\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  3.2461981773376465\n",
      "Epoch Number :  790\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  89.55555555555556\n",
      "\t Epoch Loss  3.163787364959717\n",
      "Epoch Number :  791\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  3.5444836616516113\n",
      "Epoch Number :  792\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  5.677794933319092\n",
      "Epoch Number :  793\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  4.404952526092529\n",
      "Epoch Number :  794\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  5.026656150817871\n",
      "Epoch Number :  795\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  6.925373077392578\n",
      "Epoch Number :  796\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  9.2002534866333\n",
      "Epoch Number :  797\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  12.442824363708496\n",
      "Epoch Number :  798\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  15.21999454498291\n",
      "Epoch Number :  799\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  23.09563636779785\n",
      "Epoch Number :  800\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  23.20574951171875\n",
      "Epoch Number :  801\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  27.598854064941406\n",
      "Epoch Number :  802\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  33.844425201416016\n",
      "Epoch Number :  803\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  19.72632598876953\n",
      "Epoch Number :  804\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  10.023921012878418\n",
      "Epoch Number :  805\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  11.050972938537598\n",
      "Epoch Number :  806\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  13.867632865905762\n",
      "Epoch Number :  807\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  13.33587646484375\n",
      "Epoch Number :  808\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  13.751749038696289\n",
      "Epoch Number :  809\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  13.285001754760742\n",
      "Epoch Number :  810\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  14.103131294250488\n",
      "Epoch Number :  811\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  14.250798225402832\n",
      "Epoch Number :  812\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.705536842346191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  813\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  12.637377738952637\n",
      "Epoch Number :  814\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  12.028165817260742\n",
      "Epoch Number :  815\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  12.487632751464844\n",
      "Epoch Number :  816\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  11.982217788696289\n",
      "Epoch Number :  817\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  13.162150382995605\n",
      "Epoch Number :  818\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  6.061595916748047\n",
      "Epoch Number :  819\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  4.906916618347168\n",
      "Epoch Number :  820\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  4.982569694519043\n",
      "Epoch Number :  821\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  4.179450035095215\n",
      "Epoch Number :  822\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  4.587010383605957\n",
      "Epoch Number :  823\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  5.742101669311523\n",
      "Epoch Number :  824\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  4.420261859893799\n",
      "Epoch Number :  825\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  4.218415260314941\n",
      "Epoch Number :  826\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  3.8363943099975586\n",
      "Epoch Number :  827\n",
      "\t Training accuracy:  99.97979797979798\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  4.457708358764648\n",
      "Epoch Number :  828\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  4.570146560668945\n",
      "Epoch Number :  829\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  5.330050945281982\n",
      "Epoch Number :  830\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  6.0427727699279785\n",
      "Epoch Number :  831\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  8.39091968536377\n",
      "Epoch Number :  832\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  9.720012664794922\n",
      "Epoch Number :  833\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  11.156280517578125\n",
      "Epoch Number :  834\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  10.748956680297852\n",
      "Epoch Number :  835\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  15.680793762207031\n",
      "Epoch Number :  836\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  15.890911102294922\n",
      "Epoch Number :  837\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  19.13542938232422\n",
      "Epoch Number :  838\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  22.928037643432617\n",
      "Epoch Number :  839\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  24.2197208404541\n",
      "Epoch Number :  840\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  18.612443923950195\n",
      "Epoch Number :  841\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  10.133519172668457\n",
      "Epoch Number :  842\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  8.867321014404297\n",
      "Epoch Number :  843\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  89.55555555555556\n",
      "\t Epoch Loss  9.5149564743042\n",
      "Epoch Number :  844\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  8.485506057739258\n",
      "Epoch Number :  845\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  8.587172508239746\n",
      "Epoch Number :  846\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.457298278808594\n",
      "Epoch Number :  847\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  10.515929222106934\n",
      "Epoch Number :  848\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  10.069001197814941\n",
      "Epoch Number :  849\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  11.535734176635742\n",
      "Epoch Number :  850\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  13.575533866882324\n",
      "Epoch Number :  851\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  11.56652545928955\n",
      "Epoch Number :  852\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  12.226369857788086\n",
      "Epoch Number :  853\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  12.696374893188477\n",
      "Epoch Number :  854\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  14.843032836914062\n",
      "Epoch Number :  855\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  15.26492691040039\n",
      "Epoch Number :  856\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  14.751219749450684\n",
      "Epoch Number :  857\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  14.354559898376465\n",
      "Epoch Number :  858\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  12.940244674682617\n",
      "Epoch Number :  859\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  11.805123329162598\n",
      "Epoch Number :  860\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  12.160248756408691\n",
      "Epoch Number :  861\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  9.068133354187012\n",
      "Epoch Number :  862\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  7.35833740234375\n",
      "Epoch Number :  863\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  8.199163436889648\n",
      "Epoch Number :  864\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  9.64346694946289\n",
      "Epoch Number :  865\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  8.441595077514648\n",
      "Epoch Number :  866\n",
      "\t Training accuracy:  99.81818181818181\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  9.254081726074219\n",
      "Epoch Number :  867\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  10.298486709594727\n",
      "Epoch Number :  868\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  11.269807815551758\n",
      "Epoch Number :  869\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  90.0\n",
      "\t Epoch Loss  9.419317245483398\n",
      "Epoch Number :  870\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  6.665369510650635\n",
      "Epoch Number :  871\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.88888888888889\n",
      "\t Epoch Loss  7.117232322692871\n",
      "Epoch Number :  872\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  7.202114105224609\n",
      "Epoch Number :  873\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  8.176093101501465\n",
      "Epoch Number :  874\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  8.91021728515625\n",
      "Epoch Number :  875\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  10.986289024353027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  876\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  12.020727157592773\n",
      "Epoch Number :  877\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  16.292827606201172\n",
      "Epoch Number :  878\n",
      "\t Training accuracy:  99.23232323232324\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  17.65713119506836\n",
      "Epoch Number :  879\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  24.178627014160156\n",
      "Epoch Number :  880\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  22.873300552368164\n",
      "Epoch Number :  881\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  18.138023376464844\n",
      "Epoch Number :  882\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  23.81692886352539\n",
      "Epoch Number :  883\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  32.227474212646484\n",
      "Epoch Number :  884\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  41.167015075683594\n",
      "Epoch Number :  885\n",
      "\t Training accuracy:  99.73737373737374\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  22.54249382019043\n",
      "Epoch Number :  886\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  14.927361488342285\n",
      "Epoch Number :  887\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.3361234664917\n",
      "Epoch Number :  888\n",
      "\t Training accuracy:  100.0\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  10.239644050598145\n",
      "Epoch Number :  889\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  13.919039726257324\n",
      "Epoch Number :  890\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  18.241188049316406\n",
      "Epoch Number :  891\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  23.550931930541992\n",
      "Epoch Number :  892\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  22.604978561401367\n",
      "Epoch Number :  893\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  22.209253311157227\n",
      "Epoch Number :  894\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  14.9758939743042\n",
      "Epoch Number :  895\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  15.772207260131836\n",
      "Epoch Number :  896\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  21.945802688598633\n",
      "Epoch Number :  897\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  21.747634887695312\n",
      "Epoch Number :  898\n",
      "\t Training accuracy:  99.67676767676768\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  16.961904525756836\n",
      "Epoch Number :  899\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  11.51606559753418\n",
      "Epoch Number :  900\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  19.433635711669922\n",
      "Epoch Number :  901\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  24.32004737854004\n",
      "Epoch Number :  902\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  17.468591690063477\n",
      "Epoch Number :  903\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  11.390521049499512\n",
      "Epoch Number :  904\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  22.332040786743164\n",
      "Epoch Number :  905\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  24.732282638549805\n",
      "Epoch Number :  906\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  15.355693817138672\n",
      "Epoch Number :  907\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  22.688661575317383\n",
      "Epoch Number :  908\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  34.304420471191406\n",
      "Epoch Number :  909\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  32.712032318115234\n",
      "Epoch Number :  910\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  18.43421745300293\n",
      "Epoch Number :  911\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  39.010009765625\n",
      "Epoch Number :  912\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  50.1361083984375\n",
      "Epoch Number :  913\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  20.959369659423828\n",
      "Epoch Number :  914\n",
      "\t Training accuracy:  98.54545454545455\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  37.36286926269531\n",
      "Epoch Number :  915\n",
      "\t Training accuracy:  98.68686868686869\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  42.89963150024414\n",
      "Epoch Number :  916\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  44.76502227783203\n",
      "Epoch Number :  917\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  48.7559700012207\n",
      "Epoch Number :  918\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  34.972198486328125\n",
      "Epoch Number :  919\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  23.471973419189453\n",
      "Epoch Number :  920\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  31.741973876953125\n",
      "Epoch Number :  921\n",
      "\t Training accuracy:  98.96969696969697\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  29.81010627746582\n",
      "Epoch Number :  922\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  24.394298553466797\n",
      "Epoch Number :  923\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  36.530006408691406\n",
      "Epoch Number :  924\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  81.55555555555556\n",
      "\t Epoch Loss  34.372920989990234\n",
      "Epoch Number :  925\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  39.98402404785156\n",
      "Epoch Number :  926\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  26.87197494506836\n",
      "Epoch Number :  927\n",
      "\t Training accuracy:  99.25252525252525\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  38.66487121582031\n",
      "Epoch Number :  928\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  42.673789978027344\n",
      "Epoch Number :  929\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  31.717124938964844\n",
      "Epoch Number :  930\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  39.6442985534668\n",
      "Epoch Number :  931\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  38.41739273071289\n",
      "Epoch Number :  932\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  85.33333333333333\n",
      "\t Epoch Loss  49.570526123046875\n",
      "Epoch Number :  933\n",
      "\t Training accuracy:  99.27272727272727\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  51.47810363769531\n",
      "Epoch Number :  934\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  85.55555555555556\n",
      "\t Epoch Loss  15.551558494567871\n",
      "Epoch Number :  935\n",
      "\t Training accuracy:  99.63636363636364\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  20.95760726928711\n",
      "Epoch Number :  936\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  21.614604949951172\n",
      "Epoch Number :  937\n",
      "\t Training accuracy:  99.13131313131314\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  56.25935745239258\n",
      "Epoch Number :  938\n",
      "\t Training accuracy:  99.17171717171718\n",
      "\t Validation accuracy  84.66666666666667\n",
      "\t Epoch Loss  43.82822799682617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  939\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  39.10798645019531\n",
      "Epoch Number :  940\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  20.474830627441406\n",
      "Epoch Number :  941\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  37.49427032470703\n",
      "Epoch Number :  942\n",
      "\t Training accuracy:  99.35353535353535\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  39.95133972167969\n",
      "Epoch Number :  943\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  72.51661682128906\n",
      "Epoch Number :  944\n",
      "\t Training accuracy:  98.74747474747475\n",
      "\t Validation accuracy  84.22222222222223\n",
      "\t Epoch Loss  71.23975372314453\n",
      "Epoch Number :  945\n",
      "\t Training accuracy:  99.11111111111111\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  60.51457977294922\n",
      "Epoch Number :  946\n",
      "\t Training accuracy:  98.86868686868686\n",
      "\t Validation accuracy  84.88888888888889\n",
      "\t Epoch Loss  73.94102478027344\n",
      "Epoch Number :  947\n",
      "\t Training accuracy:  99.01010101010101\n",
      "\t Validation accuracy  83.55555555555556\n",
      "\t Epoch Loss  84.27361297607422\n",
      "Epoch Number :  948\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  83.77777777777777\n",
      "\t Epoch Loss  59.51361846923828\n",
      "Epoch Number :  949\n",
      "\t Training accuracy:  98.94949494949495\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  39.27276611328125\n",
      "Epoch Number :  950\n",
      "\t Training accuracy:  98.72727272727273\n",
      "\t Validation accuracy  83.11111111111111\n",
      "\t Epoch Loss  53.1568717956543\n",
      "Epoch Number :  951\n",
      "\t Training accuracy:  98.9090909090909\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  33.094482421875\n",
      "Epoch Number :  952\n",
      "\t Training accuracy:  99.03030303030303\n",
      "\t Validation accuracy  84.0\n",
      "\t Epoch Loss  55.67180252075195\n",
      "Epoch Number :  953\n",
      "\t Training accuracy:  99.05050505050505\n",
      "\t Validation accuracy  85.11111111111111\n",
      "\t Epoch Loss  47.738529205322266\n",
      "Epoch Number :  954\n",
      "\t Training accuracy:  98.86868686868686\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  79.0090560913086\n",
      "Epoch Number :  955\n",
      "\t Training accuracy:  98.98989898989899\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  70.6386947631836\n",
      "Epoch Number :  956\n",
      "\t Training accuracy:  98.8080808080808\n",
      "\t Validation accuracy  84.44444444444444\n",
      "\t Epoch Loss  55.13981628417969\n",
      "Epoch Number :  957\n",
      "\t Training accuracy:  98.70707070707071\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  91.32215881347656\n",
      "Epoch Number :  958\n",
      "\t Training accuracy:  99.1919191919192\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  55.98466873168945\n",
      "Epoch Number :  959\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  59.12432098388672\n",
      "Epoch Number :  960\n",
      "\t Training accuracy:  99.15151515151516\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Epoch Loss  51.18266677856445\n",
      "Epoch Number :  961\n",
      "\t Training accuracy:  99.47474747474747\n",
      "\t Validation accuracy  89.11111111111111\n",
      "\t Epoch Loss  27.89145278930664\n",
      "Epoch Number :  962\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  27.495237350463867\n",
      "Epoch Number :  963\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  27.99660301208496\n",
      "Epoch Number :  964\n",
      "\t Training accuracy:  98.92929292929293\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  26.54855728149414\n",
      "Epoch Number :  965\n",
      "\t Training accuracy:  99.41414141414141\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  29.36608123779297\n",
      "Epoch Number :  966\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  35.492374420166016\n",
      "Epoch Number :  967\n",
      "\t Training accuracy:  99.57575757575758\n",
      "\t Validation accuracy  88.44444444444444\n",
      "\t Epoch Loss  26.016075134277344\n",
      "Epoch Number :  968\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  41.94718933105469\n",
      "Epoch Number :  969\n",
      "\t Training accuracy:  99.43434343434343\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  29.923511505126953\n",
      "Epoch Number :  970\n",
      "\t Training accuracy:  99.21212121212122\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  36.66065216064453\n",
      "Epoch Number :  971\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  22.67991065979004\n",
      "Epoch Number :  972\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  33.10181427001953\n",
      "Epoch Number :  973\n",
      "\t Training accuracy:  99.33333333333333\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  20.337902069091797\n",
      "Epoch Number :  974\n",
      "\t Training accuracy:  99.5959595959596\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  26.793663024902344\n",
      "Epoch Number :  975\n",
      "\t Training accuracy:  99.0909090909091\n",
      "\t Validation accuracy  86.44444444444444\n",
      "\t Epoch Loss  26.976564407348633\n",
      "Epoch Number :  976\n",
      "\t Training accuracy:  99.87878787878788\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  13.524005889892578\n",
      "Epoch Number :  977\n",
      "\t Training accuracy:  99.51515151515152\n",
      "\t Validation accuracy  86.0\n",
      "\t Epoch Loss  18.164928436279297\n",
      "Epoch Number :  978\n",
      "\t Training accuracy:  99.29292929292929\n",
      "\t Validation accuracy  85.77777777777777\n",
      "\t Epoch Loss  15.41158390045166\n",
      "Epoch Number :  979\n",
      "\t Training accuracy:  99.85858585858585\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  14.626952171325684\n",
      "Epoch Number :  980\n",
      "\t Training accuracy:  99.53535353535354\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  29.935096740722656\n",
      "Epoch Number :  981\n",
      "\t Training accuracy:  99.71717171717172\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  10.840657234191895\n",
      "Epoch Number :  982\n",
      "\t Training accuracy:  99.91919191919192\n",
      "\t Validation accuracy  88.0\n",
      "\t Epoch Loss  10.692948341369629\n",
      "Epoch Number :  983\n",
      "\t Training accuracy:  99.31313131313131\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  22.468284606933594\n",
      "Epoch Number :  984\n",
      "\t Training accuracy:  99.4949494949495\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  10.66443920135498\n",
      "Epoch Number :  985\n",
      "\t Training accuracy:  99.77777777777777\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  16.664936065673828\n",
      "Epoch Number :  986\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  88.22222222222223\n",
      "\t Epoch Loss  20.812278747558594\n",
      "Epoch Number :  987\n",
      "\t Training accuracy:  99.45454545454545\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.965876579284668\n",
      "Epoch Number :  988\n",
      "\t Training accuracy:  99.95959595959596\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  12.192827224731445\n",
      "Epoch Number :  989\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  88.66666666666667\n",
      "\t Epoch Loss  19.739017486572266\n",
      "Epoch Number :  990\n",
      "\t Training accuracy:  99.37373737373737\n",
      "\t Validation accuracy  86.22222222222223\n",
      "\t Epoch Loss  13.476229667663574\n",
      "Epoch Number :  991\n",
      "\t Training accuracy:  99.83838383838383\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  12.377996444702148\n",
      "Epoch Number :  992\n",
      "\t Training accuracy:  99.8989898989899\n",
      "\t Validation accuracy  86.88888888888889\n",
      "\t Epoch Loss  18.042131423950195\n",
      "Epoch Number :  993\n",
      "\t Training accuracy:  99.79797979797979\n",
      "\t Validation accuracy  89.33333333333333\n",
      "\t Epoch Loss  17.872995376586914\n",
      "Epoch Number :  994\n",
      "\t Training accuracy:  99.61616161616162\n",
      "\t Validation accuracy  87.55555555555556\n",
      "\t Epoch Loss  6.31281852722168\n",
      "Epoch Number :  995\n",
      "\t Training accuracy:  99.93939393939394\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  13.031048774719238\n",
      "Epoch Number :  996\n",
      "\t Training accuracy:  99.75757575757575\n",
      "\t Validation accuracy  87.33333333333333\n",
      "\t Epoch Loss  11.894366264343262\n",
      "Epoch Number :  997\n",
      "\t Training accuracy:  99.55555555555556\n",
      "\t Validation accuracy  87.77777777777777\n",
      "\t Epoch Loss  16.88009262084961\n",
      "Epoch Number :  998\n",
      "\t Training accuracy:  99.65656565656566\n",
      "\t Validation accuracy  86.66666666666667\n",
      "\t Epoch Loss  9.898149490356445\n",
      "Epoch Number :  999\n",
      "\t Training accuracy:  99.6969696969697\n",
      "\t Validation accuracy  87.11111111111111\n",
      "\t Epoch Loss  11.891351699829102\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_input = Variable(train_input).float()\n",
    "validation_input = Variable(validation_input).float()\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(labels_train_cube_coords)  # keep long tensors\n",
    "    validation_target = Variable(labels_validation_cube_coords, \n",
    "    uires_grad=False) # convert to float\n",
    "    Noutputs = 18\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(labels_train_cube_coords)  # keep long tensors\n",
    "    validation_target = Variable(labels_validation_cube_coords, requires_grad=False) # convert to float\n",
    "    Noutputs = 18\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(labels_train_cube_coords, requires_grad=False).float() # convert to float\n",
    "    validation_target = Variable(labels_validation_cube_coords, requires_grad=False).float() # convert to float\n",
    "    Noutputs = 9\n",
    "\n",
    "Nbatches = int(math.ceil(Ntrain/batch_size))\n",
    "Nepochs = 1000\n",
    "#seeds = list(range(15)) #Test 15 different seeds but always the seeds from 0 to 15 so that the weights are always initialized in a reproducible way\n",
    "#Nrep = len(seeds)\n",
    "Nrep = 1\n",
    "\n",
    "train_errors = torch.Tensor(Nrep, Nepochs).zero_()\n",
    "test_errors = torch.Tensor(Nrep, Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nrep, Nepochs).zero_()\n",
    "ep_loss = torch.Tensor(Nrep, Nepochs).zero_()\n",
    "\n",
    "for i_rep in range(Nrep):    \n",
    "    #print('Repetition', seeds[i_rep])\n",
    "    #torch.manual_seed(seeds[i_rep])\n",
    "    \n",
    "    model = conv2DNet_1(Noutputs) #from litterature EEG-Net coorected\n",
    "    #model = conv2DNet_2(Noutputs)  #from Temporal - Spatial; 4 Filters Model - Best performing model with accuracy 0.83 in average on the validation set\n",
    "    #model = conv2DNet_3(Noutputs) #from Temporal - Spatial; 64 Filters Model\n",
    "    #model = conv2DNet_4(Noutputs) #from Temporal - Spatial; 128 Filters Model\n",
    "    \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.50)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    #optimizer = optim.Adagrad(model.parameters())\n",
    "    #optimizer = optim.Adamax(model.parameters())\n",
    "    #optimizer = optim.ASGD(model.parameters())\n",
    "    #optimizer = optim.RMSprop(model.parameters())\n",
    "    #optimizer = optim.Rprop(model.parameters())\n",
    "    \n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "    for i_ep in range(Nepochs):\n",
    "        for b_start in range(0, Ntrain, batch_size):\n",
    "            bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "            if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "                batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "            else:\n",
    "                batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            ep_loss[i_rep, i_ep] += batch_loss.data[0]\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        #scheduler.step(ep_loss[i_rep, i_ep])\n",
    "        \n",
    "        nb_train_errs = compute_nb_errors_delta(model, train_input, train_target, batch_size, criterion)\n",
    "        nb_validation_errs = compute_nb_errors_delta(model, validation_input, validation_target, batch_size, criterion)\n",
    "        \n",
    "        print(\"Epoch Number : \", i_ep)\n",
    "        print(\"\\t Training accuracy: \", (100*(Ntrain*Noutputs-nb_train_errs)/(Ntrain*Noutputs)))\n",
    "        print(\"\\t Validation accuracy \",(100*(Nvalidation*Noutputs-nb_validation_errs)/(Nvalidation*Noutputs)))\n",
    "        \n",
    "        print(\"\\t Epoch Loss \", ep_loss[i_rep, i_ep])\n",
    "        \n",
    "        train_errors[i_rep, i_ep] = nb_train_errs\n",
    "        validation_errors[i_rep, i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK SUMMARY & RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 99.7%+-0.0\n",
      "Validation accuracy 87.1%+-0.0\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = 100*(Ntrain*Noutputs-np.array(train_errors))/(Ntrain*Noutputs)\n",
    "val_accuracy = 100*(Nvalidation*Noutputs-np.array(validation_errors))/(Nvalidation*Noutputs)\n",
    "\n",
    "stddev_train_errors = np.std(train_accuracy, axis=0)\n",
    "stddev_val_errors = np.std(val_accuracy, axis=0)\n",
    "\n",
    "mean_train_errors = np.mean(train_accuracy, axis=0)\n",
    "mean_val_errors = np.mean(val_accuracy, axis=0)\n",
    "\n",
    "epoch = list(range(1000))\n",
    "plt.plot(epoch, mean_train_errors)\n",
    "plt.plot(epoch, mean_val_errors)\n",
    "plt.fill_between(epoch, mean_train_errors+stddev_train_errors, mean_train_errors-stddev_train_errors, alpha=0.5)\n",
    "plt.fill_between(epoch, mean_val_errors+stddev_val_errors, mean_val_errors-stddev_val_errors, alpha=0.5)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy in %')\n",
    "plt.legend(['train', 'validation', 'test'])\n",
    "\n",
    "print(\"Training accuracy {:4.3g}%+-{}\".format(mean_train_errors[-1], stddev_train_errors[-1]))\n",
    "print(\"Validation accuracy {:4.3g}%+-{}\".format(mean_val_errors[-1], stddev_val_errors[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
