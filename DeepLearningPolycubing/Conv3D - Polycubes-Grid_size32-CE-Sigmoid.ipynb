{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=32\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensor to a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "torch.Size([60, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([45, 1, 32, 32, 32])\n",
      "validation torch.Size([15, 1, 32, 32, 32])\n",
      "train_target torch.Size([45, 32, 32, 32])\n",
      "validation_target torch.Size([15, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target,batch_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:, 0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, 1, grid_size, grid_size, grid_size).float())\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, 1, grid_size, grid_size, grid_size).float())\n",
    "\n",
    "labels_train = preprocessed_input_train_target.float()\n",
    "labels_validation = preprocessed_input_validation_target.float()\n",
    "\n",
    "print('train', train_input.shape)\n",
    "print('validation', validation_input.shape)\n",
    "print('train_target', labels_train.shape)\n",
    "print('validation_target', labels_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n",
      "Epoch Number :  0\n",
      "\t Training accuracy:  45.57691786024306\n",
      "\t Validation accuracy  45.007731119791664\n",
      "\t Epoch Loss  2.1012232303619385\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  87.76075575086806\n",
      "\t Validation accuracy  87.63936360677083\n",
      "\t Epoch Loss  2.0755698680877686\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  90.39421929253473\n",
      "\t Validation accuracy  90.0347900390625\n",
      "\t Epoch Loss  2.060469388961792\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  92.5799560546875\n",
      "\t Validation accuracy  92.45463053385417\n",
      "\t Epoch Loss  2.0567660331726074\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  94.52663845486111\n",
      "\t Validation accuracy  94.5068359375\n",
      "\t Epoch Loss  2.054701805114746\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  93.34615071614583\n",
      "\t Validation accuracy  93.32417805989583\n",
      "\t Epoch Loss  2.0538744926452637\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  91.427001953125\n",
      "\t Validation accuracy  91.14990234375\n",
      "\t Epoch Loss  2.0530824661254883\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  90.63503689236111\n",
      "\t Validation accuracy  90.303955078125\n",
      "\t Epoch Loss  2.052891254425049\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  91.12820095486111\n",
      "\t Validation accuracy  90.92020670572917\n",
      "\t Epoch Loss  2.0518970489501953\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  92.60667588975694\n",
      "\t Validation accuracy  92.486572265625\n",
      "\t Epoch Loss  2.049814224243164\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  93.15599229600694\n",
      "\t Validation accuracy  93.07759602864583\n",
      "\t Epoch Loss  2.0486440658569336\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  92.41889105902777\n",
      "\t Validation accuracy  92.21435546875\n",
      "\t Epoch Loss  2.0479564666748047\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  91.73773871527777\n",
      "\t Validation accuracy  91.4508056640625\n",
      "\t Epoch Loss  2.047206163406372\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  91.87120225694444\n",
      "\t Validation accuracy  91.51875813802083\n",
      "\t Epoch Loss  2.046344518661499\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  92.19923231336806\n",
      "\t Validation accuracy  91.77571614583333\n",
      "\t Epoch Loss  2.0434212684631348\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  91.90388997395833\n",
      "\t Validation accuracy  91.619873046875\n",
      "\t Epoch Loss  2.0384082794189453\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  91.34772406684027\n",
      "\t Validation accuracy  91.01175944010417\n",
      "\t Epoch Loss  2.036020040512085\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  91.29482693142361\n",
      "\t Validation accuracy  90.88338216145833\n",
      "\t Epoch Loss  2.0350852012634277\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  93.95989312065973\n",
      "\t Validation accuracy  93.95222981770833\n",
      "\t Epoch Loss  2.033296585083008\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  96.09937879774306\n",
      "\t Validation accuracy  96.01277669270833\n",
      "\t Epoch Loss  2.031787395477295\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  92.0062255859375\n",
      "\t Validation accuracy  91.58101399739583\n",
      "\t Epoch Loss  2.030212640762329\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  91.34765625\n",
      "\t Validation accuracy  90.80322265625\n",
      "\t Epoch Loss  2.0283875465393066\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  91.72627766927083\n",
      "\t Validation accuracy  91.07808430989583\n",
      "\t Epoch Loss  2.027343273162842\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  92.41278754340277\n",
      "\t Validation accuracy  91.88802083333333\n",
      "\t Epoch Loss  2.026148796081543\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  92.15603298611111\n",
      "\t Validation accuracy  91.48193359375\n",
      "\t Epoch Loss  2.0247693061828613\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  91.95102267795139\n",
      "\t Validation accuracy  91.129150390625\n",
      "\t Epoch Loss  2.0234689712524414\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  92.60579427083333\n",
      "\t Validation accuracy  92.08455403645833\n",
      "\t Epoch Loss  2.0192642211914062\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  93.11659071180556\n",
      "\t Validation accuracy  92.39013671875\n",
      "\t Epoch Loss  2.0146431922912598\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  92.32245551215277\n",
      "\t Validation accuracy  91.38875325520833\n",
      "\t Epoch Loss  2.012012004852295\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  92.77492947048611\n",
      "\t Validation accuracy  91.9256591796875\n",
      "\t Epoch Loss  2.0104002952575684\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  93.2025146484375\n",
      "\t Validation accuracy  92.67415364583333\n",
      "\t Epoch Loss  2.0091142654418945\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  92.67985026041667\n",
      "\t Validation accuracy  91.87581380208333\n",
      "\t Epoch Loss  2.0075087547302246\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  95.36580403645833\n",
      "\t Validation accuracy  95.08260091145833\n",
      "\t Epoch Loss  2.0061721801757812\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  94.49388292100694\n",
      "\t Validation accuracy  94.17582194010417\n",
      "\t Epoch Loss  2.0039427280426025\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  92.69185384114583\n",
      "\t Validation accuracy  91.84956868489583\n",
      "\t Epoch Loss  2.00199818611145\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  92.76353624131944\n",
      "\t Validation accuracy  91.92769368489583\n",
      "\t Epoch Loss  2.0010898113250732\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  96.19222005208333\n",
      "\t Validation accuracy  95.58247884114583\n",
      "\t Epoch Loss  1.9987095594406128\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  93.951416015625\n",
      "\t Validation accuracy  93.26253255208333\n",
      "\t Epoch Loss  1.9975903034210205\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  93.19817437065973\n",
      "\t Validation accuracy  92.20743815104167\n",
      "\t Epoch Loss  1.9956812858581543\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  94.55220540364583\n",
      "\t Validation accuracy  94.05293782552083\n",
      "\t Epoch Loss  1.993922233581543\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  94.24262152777777\n",
      "\t Validation accuracy  93.5552978515625\n",
      "\t Epoch Loss  1.9907881021499634\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  93.91635470920139\n",
      "\t Validation accuracy  93.41532389322917\n",
      "\t Epoch Loss  1.986907720565796\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  94.82374403211806\n",
      "\t Validation accuracy  94.29443359375\n",
      "\t Epoch Loss  1.9839341640472412\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  94.51137966579861\n",
      "\t Validation accuracy  94.16951497395833\n",
      "\t Epoch Loss  1.98212730884552\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  93.39979383680556\n",
      "\t Validation accuracy  92.90852864583333\n",
      "\t Epoch Loss  1.980924367904663\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  95.16472710503473\n",
      "\t Validation accuracy  94.5013427734375\n",
      "\t Epoch Loss  1.9788718223571777\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  95.17910427517361\n",
      "\t Validation accuracy  94.48160807291667\n",
      "\t Epoch Loss  1.9771709442138672\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  94.13486056857639\n",
      "\t Validation accuracy  93.41512044270833\n",
      "\t Epoch Loss  1.9758548736572266\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  95.78525119357639\n",
      "\t Validation accuracy  94.976806640625\n",
      "\t Epoch Loss  1.9744715690612793\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  94.62544759114583\n",
      "\t Validation accuracy  93.863525390625\n",
      "\t Epoch Loss  1.9742679595947266\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  94.18307834201389\n",
      "\t Validation accuracy  93.29549153645833\n",
      "\t Epoch Loss  1.972430944442749\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  94.94472927517361\n",
      "\t Validation accuracy  94.38374837239583\n",
      "\t Epoch Loss  1.97123384475708\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  95.70821126302083\n",
      "\t Validation accuracy  95.00020345052083\n",
      "\t Epoch Loss  1.9726518392562866\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  96.56243218315973\n",
      "\t Validation accuracy  95.8905029296875\n",
      "\t Epoch Loss  1.9709528684616089\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  94.73253038194444\n",
      "\t Validation accuracy  94.0924072265625\n",
      "\t Epoch Loss  1.9701322317123413\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  93.63362630208333\n",
      "\t Validation accuracy  92.65869140625\n",
      "\t Epoch Loss  1.9696667194366455\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  93.76858181423611\n",
      "\t Validation accuracy  93.19091796875\n",
      "\t Epoch Loss  1.9683927297592163\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  94.98250325520833\n",
      "\t Validation accuracy  94.066162109375\n",
      "\t Epoch Loss  1.967305302619934\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  95.06320529513889\n",
      "\t Validation accuracy  94.43603515625\n",
      "\t Epoch Loss  1.9661376476287842\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  93.86569552951389\n",
      "\t Validation accuracy  93.1646728515625\n",
      "\t Epoch Loss  1.965345859527588\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  94.27591959635417\n",
      "\t Validation accuracy  93.46964518229167\n",
      "\t Epoch Loss  1.9641132354736328\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  94.60123697916667\n",
      "\t Validation accuracy  93.81245930989583\n",
      "\t Epoch Loss  1.9625693559646606\n",
      "Epoch Number :  62\n",
      "\t Training accuracy:  94.79722764756944\n",
      "\t Validation accuracy  94.07246907552083\n",
      "\t Epoch Loss  1.961390495300293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  63\n",
      "\t Training accuracy:  94.48933919270833\n",
      "\t Validation accuracy  93.41634114583333\n",
      "\t Epoch Loss  1.9600108861923218\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  94.98942057291667\n",
      "\t Validation accuracy  94.02079264322917\n",
      "\t Epoch Loss  1.9588955640792847\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  94.635009765625\n",
      "\t Validation accuracy  93.85579427083333\n",
      "\t Epoch Loss  1.957463026046753\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  94.89854600694444\n",
      "\t Validation accuracy  93.78377278645833\n",
      "\t Epoch Loss  1.9576878547668457\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  95.27553982204861\n",
      "\t Validation accuracy  94.57661946614583\n",
      "\t Epoch Loss  1.954479455947876\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  94.85460069444444\n",
      "\t Validation accuracy  93.81429036458333\n",
      "\t Epoch Loss  1.9535503387451172\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  94.32990180121527\n",
      "\t Validation accuracy  93.44095865885417\n",
      "\t Epoch Loss  1.9498695135116577\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  95.17774793836806\n",
      "\t Validation accuracy  94.36482747395833\n",
      "\t Epoch Loss  1.9473657608032227\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  94.87711588541667\n",
      "\t Validation accuracy  93.934326171875\n",
      "\t Epoch Loss  1.9446499347686768\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  94.85819498697917\n",
      "\t Validation accuracy  93.84134928385417\n",
      "\t Epoch Loss  1.9426379203796387\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  94.48777940538194\n",
      "\t Validation accuracy  93.538818359375\n",
      "\t Epoch Loss  1.9407627582550049\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  94.98935275607639\n",
      "\t Validation accuracy  94.03889973958333\n",
      "\t Epoch Loss  1.9396178722381592\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  95.26740180121527\n",
      "\t Validation accuracy  94.4281005859375\n",
      "\t Epoch Loss  1.937633991241455\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  95.15157063802083\n",
      "\t Validation accuracy  94.33268229166667\n",
      "\t Epoch Loss  1.9360053539276123\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  94.84666612413194\n",
      "\t Validation accuracy  93.8568115234375\n",
      "\t Epoch Loss  1.934621810913086\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  94.67176649305556\n",
      "\t Validation accuracy  93.702392578125\n",
      "\t Epoch Loss  1.933459758758545\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  94.92045084635417\n",
      "\t Validation accuracy  93.99881998697917\n",
      "\t Epoch Loss  1.9320051670074463\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  95.17415364583333\n",
      "\t Validation accuracy  94.34427897135417\n",
      "\t Epoch Loss  1.9307541847229004\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  95.7598876953125\n",
      "\t Validation accuracy  94.500732421875\n",
      "\t Epoch Loss  1.9291439056396484\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  94.75104437934027\n",
      "\t Validation accuracy  93.82832845052083\n",
      "\t Epoch Loss  1.9269614219665527\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  94.93177625868056\n",
      "\t Validation accuracy  94.149169921875\n",
      "\t Epoch Loss  1.9249764680862427\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  95.49065483940973\n",
      "\t Validation accuracy  94.2694091796875\n",
      "\t Epoch Loss  1.9224199056625366\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  95.63442654079861\n",
      "\t Validation accuracy  94.632568359375\n",
      "\t Epoch Loss  1.9207282066345215\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  95.09921603732639\n",
      "\t Validation accuracy  94.29768880208333\n",
      "\t Epoch Loss  1.9186768531799316\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  95.98076714409723\n",
      "\t Validation accuracy  94.92106119791667\n",
      "\t Epoch Loss  1.9168628454208374\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  95.59956868489583\n",
      "\t Validation accuracy  94.80631510416667\n",
      "\t Epoch Loss  1.9152944087982178\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  95.17198350694444\n",
      "\t Validation accuracy  94.193115234375\n",
      "\t Epoch Loss  1.9138545989990234\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  96.18387858072917\n",
      "\t Validation accuracy  95.13936360677083\n",
      "\t Epoch Loss  1.9124876260757446\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  94.93001302083333\n",
      "\t Validation accuracy  94.1827392578125\n",
      "\t Epoch Loss  1.9112905263900757\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  96.86265733506944\n",
      "\t Validation accuracy  95.62601725260417\n",
      "\t Epoch Loss  1.910219430923462\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  95.29541015625\n",
      "\t Validation accuracy  94.32169596354167\n",
      "\t Epoch Loss  1.9087891578674316\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  95.74544270833333\n",
      "\t Validation accuracy  94.99593098958333\n",
      "\t Epoch Loss  1.9076731204986572\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  95.65104166666667\n",
      "\t Validation accuracy  94.77294921875\n",
      "\t Epoch Loss  1.9064364433288574\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  97.29092068142361\n",
      "\t Validation accuracy  96.02274576822917\n",
      "\t Epoch Loss  1.9044008255004883\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  94.5697021484375\n",
      "\t Validation accuracy  93.87552897135417\n",
      "\t Epoch Loss  1.9027693271636963\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  97.05112033420139\n",
      "\t Validation accuracy  96.23819986979167\n",
      "\t Epoch Loss  1.9003088474273682\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  95.65694173177083\n",
      "\t Validation accuracy  94.5257568359375\n",
      "\t Epoch Loss  1.8987679481506348\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  96.49692111545139\n",
      "\t Validation accuracy  95.731201171875\n",
      "\t Epoch Loss  1.8962911367416382\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  96.728515625\n",
      "\t Validation accuracy  95.5633544921875\n",
      "\t Epoch Loss  1.8945345878601074\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  95.57685004340277\n",
      "\t Validation accuracy  94.873046875\n",
      "\t Epoch Loss  1.8922851085662842\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  97.21293131510417\n",
      "\t Validation accuracy  96.148681640625\n",
      "\t Epoch Loss  1.8910090923309326\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  95.76761881510417\n",
      "\t Validation accuracy  95.01871744791667\n",
      "\t Epoch Loss  1.889510154724121\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  97.13779025607639\n",
      "\t Validation accuracy  96.1285400390625\n",
      "\t Epoch Loss  1.888338327407837\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  95.53310818142361\n",
      "\t Validation accuracy  94.88566080729167\n",
      "\t Epoch Loss  1.8869435787200928\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  98.07094997829861\n",
      "\t Validation accuracy  96.71223958333333\n",
      "\t Epoch Loss  1.8859540224075317\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  95.44752332899306\n",
      "\t Validation accuracy  94.42423502604167\n",
      "\t Epoch Loss  1.8852813243865967\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  96.22199164496527\n",
      "\t Validation accuracy  95.64615885416667\n",
      "\t Epoch Loss  1.8837811946868896\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  96.81728786892361\n",
      "\t Validation accuracy  95.64046223958333\n",
      "\t Epoch Loss  1.8832569122314453\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  96.9415283203125\n",
      "\t Validation accuracy  96.1773681640625\n",
      "\t Epoch Loss  1.8823707103729248\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  97.34117296006944\n",
      "\t Validation accuracy  96.3543701171875\n",
      "\t Epoch Loss  1.8818719387054443\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  96.52364095052083\n",
      "\t Validation accuracy  95.56803385416667\n",
      "\t Epoch Loss  1.8808473348617554\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  97.56117078993056\n",
      "\t Validation accuracy  96.59322102864583\n",
      "\t Epoch Loss  1.8803168535232544\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  95.84309895833333\n",
      "\t Validation accuracy  94.85270182291667\n",
      "\t Epoch Loss  1.8798658847808838\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  97.78252495659723\n",
      "\t Validation accuracy  96.611328125\n",
      "\t Epoch Loss  1.8794162273406982\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  95.96598307291667\n",
      "\t Validation accuracy  95.16276041666667\n",
      "\t Epoch Loss  1.8781380653381348\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  97.51627604166667\n",
      "\t Validation accuracy  96.65730794270833\n",
      "\t Epoch Loss  1.8778759241104126\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  96.61777072482639\n",
      "\t Validation accuracy  95.328369140625\n",
      "\t Epoch Loss  1.8768012523651123\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  97.56008572048611\n",
      "\t Validation accuracy  96.70186360677083\n",
      "\t Epoch Loss  1.8764841556549072\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  96.98940700954861\n",
      "\t Validation accuracy  95.80851236979167\n",
      "\t Epoch Loss  1.8753082752227783\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  97.13704427083333\n",
      "\t Validation accuracy  96.16455078125\n",
      "\t Epoch Loss  1.8743712902069092\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  97.89679633246527\n",
      "\t Validation accuracy  96.83329264322917\n",
      "\t Epoch Loss  1.873752236366272\n",
      "Epoch Number :  124\n",
      "\t Training accuracy:  96.63092719184027\n",
      "\t Validation accuracy  95.78389485677083\n",
      "\t Epoch Loss  1.8720066547393799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  125\n",
      "\t Training accuracy:  97.47097439236111\n",
      "\t Validation accuracy  96.64896647135417\n",
      "\t Epoch Loss  1.870856761932373\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  97.01605902777777\n",
      "\t Validation accuracy  96.07625325520833\n",
      "\t Epoch Loss  1.8685818910598755\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  97.72793240017361\n",
      "\t Validation accuracy  96.942138671875\n",
      "\t Epoch Loss  1.8669607639312744\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  96.96031358506944\n",
      "\t Validation accuracy  95.7891845703125\n",
      "\t Epoch Loss  1.8653641939163208\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  98.11733669704861\n",
      "\t Validation accuracy  97.11710611979167\n",
      "\t Epoch Loss  1.8635495901107788\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  97.11581759982639\n",
      "\t Validation accuracy  95.8770751953125\n",
      "\t Epoch Loss  1.8613219261169434\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  97.16396755642361\n",
      "\t Validation accuracy  96.71366373697917\n",
      "\t Epoch Loss  1.8594027757644653\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  97.83949110243056\n",
      "\t Validation accuracy  96.4312744140625\n",
      "\t Epoch Loss  1.855832576751709\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  96.90212673611111\n",
      "\t Validation accuracy  96.03535970052083\n",
      "\t Epoch Loss  1.8554925918579102\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  98.45113118489583\n",
      "\t Validation accuracy  97.08536783854167\n",
      "\t Epoch Loss  1.8527259826660156\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  96.94085015190973\n",
      "\t Validation accuracy  95.7958984375\n",
      "\t Epoch Loss  1.8513736724853516\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  98.16257052951389\n",
      "\t Validation accuracy  97.198486328125\n",
      "\t Epoch Loss  1.850035548210144\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  97.36599392361111\n",
      "\t Validation accuracy  96.46586100260417\n",
      "\t Epoch Loss  1.8487077951431274\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  98.15633138020833\n",
      "\t Validation accuracy  97.01639811197917\n",
      "\t Epoch Loss  1.8475291728973389\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  97.74712456597223\n",
      "\t Validation accuracy  96.8133544921875\n",
      "\t Epoch Loss  1.8463938236236572\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  97.73735894097223\n",
      "\t Validation accuracy  96.6864013671875\n",
      "\t Epoch Loss  1.8452496528625488\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  98.20570203993056\n",
      "\t Validation accuracy  97.14009602864583\n",
      "\t Epoch Loss  1.8441373109817505\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  98.1134033203125\n",
      "\t Validation accuracy  97.00642903645833\n",
      "\t Epoch Loss  1.8428031206130981\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  97.7703857421875\n",
      "\t Validation accuracy  96.8463134765625\n",
      "\t Epoch Loss  1.8415520191192627\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  98.38514539930556\n",
      "\t Validation accuracy  97.23856608072917\n",
      "\t Epoch Loss  1.8403279781341553\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  98.14500596788194\n",
      "\t Validation accuracy  96.84000651041667\n",
      "\t Epoch Loss  1.8390302658081055\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  97.94650607638889\n",
      "\t Validation accuracy  96.97367350260417\n",
      "\t Epoch Loss  1.8376128673553467\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  98.27907986111111\n",
      "\t Validation accuracy  97.2589111328125\n",
      "\t Epoch Loss  1.835974931716919\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  98.28403049045139\n",
      "\t Validation accuracy  96.9189453125\n",
      "\t Epoch Loss  1.8346374034881592\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  98.40969509548611\n",
      "\t Validation accuracy  97.23551432291667\n",
      "\t Epoch Loss  1.8330785036087036\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  98.2574462890625\n",
      "\t Validation accuracy  97.1044921875\n",
      "\t Epoch Loss  1.831664800643921\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  98.33611382378473\n",
      "\t Validation accuracy  97.12890625\n",
      "\t Epoch Loss  1.830549955368042\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  98.51603190104167\n",
      "\t Validation accuracy  97.3193359375\n",
      "\t Epoch Loss  1.829262137413025\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  98.18861219618056\n",
      "\t Validation accuracy  96.88822428385417\n",
      "\t Epoch Loss  1.8282744884490967\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  98.56187608506944\n",
      "\t Validation accuracy  97.24568684895833\n",
      "\t Epoch Loss  1.8273152112960815\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  98.50070529513889\n",
      "\t Validation accuracy  97.3321533203125\n",
      "\t Epoch Loss  1.826348900794983\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  98.4381103515625\n",
      "\t Validation accuracy  97.08536783854167\n",
      "\t Epoch Loss  1.8252460956573486\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  98.76858181423611\n",
      "\t Validation accuracy  97.42533365885417\n",
      "\t Epoch Loss  1.8239898681640625\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  98.30098470052083\n",
      "\t Validation accuracy  97.03715006510417\n",
      "\t Epoch Loss  1.8227505683898926\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  98.80683051215277\n",
      "\t Validation accuracy  97.4169921875\n",
      "\t Epoch Loss  1.8214378356933594\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  98.59524197048611\n",
      "\t Validation accuracy  97.24507649739583\n",
      "\t Epoch Loss  1.8195525407791138\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  98.6444091796875\n",
      "\t Validation accuracy  97.30387369791667\n",
      "\t Epoch Loss  1.8183906078338623\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  98.81679958767361\n",
      "\t Validation accuracy  97.4237060546875\n",
      "\t Epoch Loss  1.8165075778961182\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  98.52878146701389\n",
      "\t Validation accuracy  97.28006998697917\n",
      "\t Epoch Loss  1.8150231838226318\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  98.92706976996527\n",
      "\t Validation accuracy  97.489013671875\n",
      "\t Epoch Loss  1.8124198913574219\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  98.64549424913194\n",
      "\t Validation accuracy  97.30855305989583\n",
      "\t Epoch Loss  1.8111317157745361\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  98.88156467013889\n",
      "\t Validation accuracy  97.47639973958333\n",
      "\t Epoch Loss  1.8085861206054688\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  98.78065321180556\n",
      "\t Validation accuracy  97.43082682291667\n",
      "\t Epoch Loss  1.806828260421753\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  98.91608344184027\n",
      "\t Validation accuracy  97.45625813802083\n",
      "\t Epoch Loss  1.8053548336029053\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  98.89743381076389\n",
      "\t Validation accuracy  97.489013671875\n",
      "\t Epoch Loss  1.804039478302002\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  98.9215087890625\n",
      "\t Validation accuracy  97.48881022135417\n",
      "\t Epoch Loss  1.802938461303711\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  98.98484971788194\n",
      "\t Validation accuracy  97.5\n",
      "\t Epoch Loss  1.8019285202026367\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  98.88760036892361\n",
      "\t Validation accuracy  97.50590006510417\n",
      "\t Epoch Loss  1.8009989261627197\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  99.24750434027777\n",
      "\t Validation accuracy  97.57080078125\n",
      "\t Epoch Loss  1.800199031829834\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  98.55400933159723\n",
      "\t Validation accuracy  97.386474609375\n",
      "\t Epoch Loss  1.7992770671844482\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  99.4134521484375\n",
      "\t Validation accuracy  97.728271484375\n",
      "\t Epoch Loss  1.7985326051712036\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  98.28525119357639\n",
      "\t Validation accuracy  97.15006510416667\n",
      "\t Epoch Loss  1.7977159023284912\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  99.24248589409723\n",
      "\t Validation accuracy  97.65177408854167\n",
      "\t Epoch Loss  1.7970829010009766\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  99.05266655815973\n",
      "\t Validation accuracy  97.4462890625\n",
      "\t Epoch Loss  1.7964624166488647\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  98.92856174045139\n",
      "\t Validation accuracy  97.6123046875\n",
      "\t Epoch Loss  1.7956783771514893\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  99.48689778645833\n",
      "\t Validation accuracy  97.79073079427083\n",
      "\t Epoch Loss  1.7956130504608154\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  98.74525282118056\n",
      "\t Validation accuracy  97.42899576822917\n",
      "\t Epoch Loss  1.7943878173828125\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  99.23923068576389\n",
      "\t Validation accuracy  97.5775146484375\n",
      "\t Epoch Loss  1.7946279048919678\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  98.94904242621527\n",
      "\t Validation accuracy  97.3712158203125\n",
      "\t Epoch Loss  1.7936229705810547\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  99.4183349609375\n",
      "\t Validation accuracy  97.77587890625\n",
      "\t Epoch Loss  1.7937004566192627\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  98.61992730034723\n",
      "\t Validation accuracy  97.3382568359375\n",
      "\t Epoch Loss  1.7932813167572021\n",
      "Epoch Number :  186\n",
      "\t Training accuracy:  99.26222059461806\n",
      "\t Validation accuracy  97.53804524739583\n",
      "\t Epoch Loss  1.7935636043548584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  187\n",
      "\t Training accuracy:  99.73944769965277\n",
      "\t Validation accuracy  97.901611328125\n",
      "\t Epoch Loss  1.7930423021316528\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  96.43385145399306\n",
      "\t Validation accuracy  96.036376953125\n",
      "\t Epoch Loss  1.7911791801452637\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  99.76291232638889\n",
      "\t Validation accuracy  97.87556966145833\n",
      "\t Epoch Loss  1.7924761772155762\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  99.05232747395833\n",
      "\t Validation accuracy  97.398681640625\n",
      "\t Epoch Loss  1.7905749082565308\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  99.10203721788194\n",
      "\t Validation accuracy  97.68208821614583\n",
      "\t Epoch Loss  1.7904571294784546\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  98.81401909722223\n",
      "\t Validation accuracy  97.39176432291667\n",
      "\t Epoch Loss  1.7897062301635742\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  99.19325086805556\n",
      "\t Validation accuracy  97.80375162760417\n",
      "\t Epoch Loss  1.7884539365768433\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  98.9923095703125\n",
      "\t Validation accuracy  97.61617024739583\n",
      "\t Epoch Loss  1.7875444889068604\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  99.57478841145833\n",
      "\t Validation accuracy  97.52197265625\n",
      "\t Epoch Loss  1.7862299680709839\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  98.80622016059027\n",
      "\t Validation accuracy  97.3651123046875\n",
      "\t Epoch Loss  1.7838941812515259\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  99.40334743923611\n",
      "\t Validation accuracy  97.55961100260417\n",
      "\t Epoch Loss  1.7830328941345215\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  99.17385525173611\n",
      "\t Validation accuracy  97.52644856770833\n",
      "\t Epoch Loss  1.780961275100708\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  99.53043619791667\n",
      "\t Validation accuracy  97.550048828125\n",
      "\t Epoch Loss  1.7790567874908447\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  99.28778754340277\n",
      "\t Validation accuracy  97.52115885416667\n",
      "\t Epoch Loss  1.777584195137024\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  99.63602701822917\n",
      "\t Validation accuracy  97.57954915364583\n",
      "\t Epoch Loss  1.7748750448226929\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  99.4110107421875\n",
      "\t Validation accuracy  97.5537109375\n",
      "\t Epoch Loss  1.7738797664642334\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  99.51558430989583\n",
      "\t Validation accuracy  97.52339680989583\n",
      "\t Epoch Loss  1.7704684734344482\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  99.43793402777777\n",
      "\t Validation accuracy  97.44771321614583\n",
      "\t Epoch Loss  1.7693815231323242\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  99.45414225260417\n",
      "\t Validation accuracy  97.38444010416667\n",
      "\t Epoch Loss  1.7672479152679443\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  99.45332845052083\n",
      "\t Validation accuracy  97.43387858072917\n",
      "\t Epoch Loss  1.7662620544433594\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  99.52840169270833\n",
      "\t Validation accuracy  97.51078287760417\n",
      "\t Epoch Loss  1.7647114992141724\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  99.515380859375\n",
      "\t Validation accuracy  97.515869140625\n",
      "\t Epoch Loss  1.7635164260864258\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  99.3524169921875\n",
      "\t Validation accuracy  97.4530029296875\n",
      "\t Epoch Loss  1.7624051570892334\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  99.32210286458333\n",
      "\t Validation accuracy  97.41678873697917\n",
      "\t Epoch Loss  1.7612757682800293\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  99.2803955078125\n",
      "\t Validation accuracy  97.44384765625\n",
      "\t Epoch Loss  1.7602267265319824\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  99.30548773871527\n",
      "\t Validation accuracy  97.4224853515625\n",
      "\t Epoch Loss  1.7591514587402344\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  99.30765787760417\n",
      "\t Validation accuracy  97.48881022135417\n",
      "\t Epoch Loss  1.7580854892730713\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  99.24262152777777\n",
      "\t Validation accuracy  97.47517903645833\n",
      "\t Epoch Loss  1.7569973468780518\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  99.24641927083333\n",
      "\t Validation accuracy  97.51627604166667\n",
      "\t Epoch Loss  1.7559350728988647\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  99.29450141059027\n",
      "\t Validation accuracy  97.55940755208333\n",
      "\t Epoch Loss  1.7548134326934814\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  99.31484646267361\n",
      "\t Validation accuracy  97.5799560546875\n",
      "\t Epoch Loss  1.7537012100219727\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  99.2120361328125\n",
      "\t Validation accuracy  97.53702799479167\n",
      "\t Epoch Loss  1.7525908946990967\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  99.0679931640625\n",
      "\t Validation accuracy  97.48311360677083\n",
      "\t Epoch Loss  1.751479148864746\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  99.04676649305556\n",
      "\t Validation accuracy  97.4542236328125\n",
      "\t Epoch Loss  1.7503645420074463\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  98.93310546875\n",
      "\t Validation accuracy  97.3663330078125\n",
      "\t Epoch Loss  1.749240756034851\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  98.97915310329861\n",
      "\t Validation accuracy  97.38179524739583\n",
      "\t Epoch Loss  1.7481663227081299\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  98.97135416666667\n",
      "\t Validation accuracy  97.38321940104167\n",
      "\t Epoch Loss  1.7470769882202148\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  99.02309841579861\n",
      "\t Validation accuracy  97.45869954427083\n",
      "\t Epoch Loss  1.7460944652557373\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  99.07090928819444\n",
      "\t Validation accuracy  97.50630696614583\n",
      "\t Epoch Loss  1.7450894117355347\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  99.0765380859375\n",
      "\t Validation accuracy  97.5579833984375\n",
      "\t Epoch Loss  1.74398934841156\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  98.97257486979167\n",
      "\t Validation accuracy  97.50590006510417\n",
      "\t Epoch Loss  1.742882490158081\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  98.87498643663194\n",
      "\t Validation accuracy  97.39176432291667\n",
      "\t Epoch Loss  1.7418211698532104\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  99.06643337673611\n",
      "\t Validation accuracy  97.46561686197917\n",
      "\t Epoch Loss  1.740879774093628\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  98.7957763671875\n",
      "\t Validation accuracy  97.31913248697917\n",
      "\t Epoch Loss  1.739804983139038\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  99.10678439670139\n",
      "\t Validation accuracy  97.52339680989583\n",
      "\t Epoch Loss  1.7387971878051758\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  98.76234266493056\n",
      "\t Validation accuracy  97.34232584635417\n",
      "\t Epoch Loss  1.7377686500549316\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  98.99427625868056\n",
      "\t Validation accuracy  97.4371337890625\n",
      "\t Epoch Loss  1.7366985082626343\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  98.93059624565973\n",
      "\t Validation accuracy  97.42574055989583\n",
      "\t Epoch Loss  1.735663890838623\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  98.98017035590277\n",
      "\t Validation accuracy  97.42757161458333\n",
      "\t Epoch Loss  1.7346340417861938\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  99.18314615885417\n",
      "\t Validation accuracy  97.56022135416667\n",
      "\t Epoch Loss  1.733468770980835\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  98.89180501302083\n",
      "\t Validation accuracy  97.37548828125\n",
      "\t Epoch Loss  1.732311725616455\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  99.039306640625\n",
      "\t Validation accuracy  97.50752766927083\n",
      "\t Epoch Loss  1.7310917377471924\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  98.80147298177083\n",
      "\t Validation accuracy  97.33561197916667\n",
      "\t Epoch Loss  1.7298424243927002\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  98.65152994791667\n",
      "\t Validation accuracy  97.22981770833333\n",
      "\t Epoch Loss  1.728594422340393\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  98.99868435329861\n",
      "\t Validation accuracy  97.406005859375\n",
      "\t Epoch Loss  1.7274320125579834\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  98.83680555555556\n",
      "\t Validation accuracy  97.34659830729167\n",
      "\t Epoch Loss  1.7263820171356201\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  98.86678059895833\n",
      "\t Validation accuracy  97.418212890625\n",
      "\t Epoch Loss  1.7251425981521606\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  99.49313693576389\n",
      "\t Validation accuracy  97.70263671875\n",
      "\t Epoch Loss  1.7241194248199463\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  99.64803059895833\n",
      "\t Validation accuracy  97.7862548828125\n",
      "\t Epoch Loss  1.7238436937332153\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  98.90326605902777\n",
      "\t Validation accuracy  96.99544270833333\n",
      "\t Epoch Loss  1.7239038944244385\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  99.10854763454861\n",
      "\t Validation accuracy  97.745361328125\n",
      "\t Epoch Loss  1.7238500118255615\n",
      "Epoch Number :  248\n",
      "\t Training accuracy:  99.46329752604167\n",
      "\t Validation accuracy  97.53153483072917\n",
      "\t Epoch Loss  1.7221627235412598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  249\n",
      "\t Training accuracy:  99.287109375\n",
      "\t Validation accuracy  97.36958821614583\n",
      "\t Epoch Loss  1.7207725048065186\n",
      "Epoch Number :  250\n",
      "\t Training accuracy:  99.26317003038194\n",
      "\t Validation accuracy  97.545166015625\n",
      "\t Epoch Loss  1.7192260026931763\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  99.28738064236111\n",
      "\t Validation accuracy  97.27254231770833\n",
      "\t Epoch Loss  1.7180780172348022\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  99.27313910590277\n",
      "\t Validation accuracy  97.3858642578125\n",
      "\t Epoch Loss  1.7167909145355225\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  99.25265842013889\n",
      "\t Validation accuracy  97.24690755208333\n",
      "\t Epoch Loss  1.7151215076446533\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  99.33810763888889\n",
      "\t Validation accuracy  97.43082682291667\n",
      "\t Epoch Loss  1.7150096893310547\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  99.57865397135417\n",
      "\t Validation accuracy  97.39888509114583\n",
      "\t Epoch Loss  1.713099479675293\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  99.12929958767361\n",
      "\t Validation accuracy  97.34232584635417\n",
      "\t Epoch Loss  1.7120401859283447\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  99.37466091579861\n",
      "\t Validation accuracy  97.74129231770833\n",
      "\t Epoch Loss  1.7108864784240723\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  99.29280598958333\n",
      "\t Validation accuracy  97.52197265625\n",
      "\t Epoch Loss  1.7097508907318115\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  99.44593641493056\n",
      "\t Validation accuracy  97.51993815104167\n",
      "\t Epoch Loss  1.7086093425750732\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  99.22159830729167\n",
      "\t Validation accuracy  97.56184895833333\n",
      "\t Epoch Loss  1.7073171138763428\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  99.52629937065973\n",
      "\t Validation accuracy  97.60945638020833\n",
      "\t Epoch Loss  1.7061145305633545\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  99.42043728298611\n",
      "\t Validation accuracy  97.60762532552083\n",
      "\t Epoch Loss  1.7046890258789062\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  99.2633056640625\n",
      "\t Validation accuracy  97.568359375\n",
      "\t Epoch Loss  1.703060507774353\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  99.40877278645833\n",
      "\t Validation accuracy  97.63142903645833\n",
      "\t Epoch Loss  1.7017297744750977\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  99.33241102430556\n",
      "\t Validation accuracy  97.55574544270833\n",
      "\t Epoch Loss  1.7002192735671997\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  99.40823025173611\n",
      "\t Validation accuracy  97.5531005859375\n",
      "\t Epoch Loss  1.6987359523773193\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  99.30426703559027\n",
      "\t Validation accuracy  97.57792154947917\n",
      "\t Epoch Loss  1.6972596645355225\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  99.30555555555556\n",
      "\t Validation accuracy  97.59236653645833\n",
      "\t Epoch Loss  1.6954221725463867\n",
      "Epoch Number :  269\n",
      "\t Training accuracy:  99.2340087890625\n",
      "\t Validation accuracy  97.58992513020833\n",
      "\t Epoch Loss  1.693573236465454\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  99.39493815104167\n",
      "\t Validation accuracy  97.61250813802083\n",
      "\t Epoch Loss  1.6918599605560303\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  99.36252170138889\n",
      "\t Validation accuracy  97.59724934895833\n",
      "\t Epoch Loss  1.690305233001709\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  99.24533420138889\n",
      "\t Validation accuracy  97.56245930989583\n",
      "\t Epoch Loss  1.6885815858840942\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  99.3658447265625\n",
      "\t Validation accuracy  97.59053548177083\n",
      "\t Epoch Loss  1.6870193481445312\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  99.37310112847223\n",
      "\t Validation accuracy  97.60721842447917\n",
      "\t Epoch Loss  1.6859015226364136\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  99.34963650173611\n",
      "\t Validation accuracy  97.596435546875\n",
      "\t Epoch Loss  1.6847803592681885\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  99.32746039496527\n",
      "\t Validation accuracy  97.59033203125\n",
      "\t Epoch Loss  1.683868646621704\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  99.37655978732639\n",
      "\t Validation accuracy  97.58707682291667\n",
      "\t Epoch Loss  1.6830923557281494\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  99.38090006510417\n",
      "\t Validation accuracy  97.58748372395833\n",
      "\t Epoch Loss  1.6823539733886719\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  99.39012315538194\n",
      "\t Validation accuracy  97.5933837890625\n",
      "\t Epoch Loss  1.6816718578338623\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  99.38944498697917\n",
      "\t Validation accuracy  97.59908040364583\n",
      "\t Epoch Loss  1.680989146232605\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  99.38849555121527\n",
      "\t Validation accuracy  97.59602864583333\n",
      "\t Epoch Loss  1.6802995204925537\n",
      "Epoch Number :  282\n",
      "\t Training accuracy:  99.40843370225694\n",
      "\t Validation accuracy  97.59602864583333\n",
      "\t Epoch Loss  1.6796746253967285\n",
      "Epoch Number :  283\n",
      "\t Training accuracy:  99.40897623697917\n",
      "\t Validation accuracy  97.59724934895833\n",
      "\t Epoch Loss  1.6790425777435303\n",
      "Epoch Number :  284\n",
      "\t Training accuracy:  99.40504286024306\n",
      "\t Validation accuracy  97.59440104166667\n",
      "\t Epoch Loss  1.6785157918930054\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target).long()  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True).long() # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    Noutputs = 1\n",
    "    \n",
    "Nbatches = int(math.ceil(Ntrain/batch_size)) #batch_size is defined above\n",
    "Nepochs = 1000\n",
    "Nrep = 1\n",
    "        \n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "model = UnetGenerator_3d(in_dim=1, out_dim=Noutputs, num_filter=4)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.90)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "#optimizer = optim.RMSprop(model.parameters())\n",
    "#optimizer = optim.Rprop(model.parameters())\n",
    " \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_ep in range(Nepochs):\n",
    "    for b_start in range(0, Ntrain, batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "        if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "        else:\n",
    "            #if delta model is chosen\n",
    "            #batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output.view(bsize_eff,grid_size,grid_size,grid_size), train_target.narrow(0, b_start, bsize_eff))\n",
    "        ep_loss[i_ep] += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step(ep_loss[i_ep])\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target, batch_size, criterion)\n",
    "    nb_validation_errs = compute_nb_errors(model, validation_input, validation_target, batch_size, criterion)\n",
    "\n",
    "    Ntrain_nb = Ntrain*grid_size**3\n",
    "    Nvalidation_nb = Nvalidation*grid_size**3\n",
    "    print(\"Epoch Number : \", i_ep)\n",
    "    print(\"\\t Training accuracy: \", (100*(Ntrain_nb-nb_train_errs)/Ntrain_nb))\n",
    "    print(\"\\t Validation accuracy \",(100*(Nvalidation_nb-nb_validation_errs)/Nvalidation_nb))\n",
    "\n",
    "    print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "\n",
    "    train_errors[i_ep] = nb_train_errs\n",
    "    validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target[44,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[14,1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array(100*(Ntrain_nb-train_errors)/Ntrain_nb)\n",
    "validation_accurcy = np.array(100*(Nvalidation_nb-validation_errors)/Nvalidation_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accurcy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visualisation = output[14,1,:,:,:].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = np.array(test_visualisation.data)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels)\n",
    "fig.savefig('VoxelizedFinal.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def summary(input_size, model):\n",
    "        def register_hook(module):\n",
    "            def hook(module, input, output):\n",
    "                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "                module_idx = len(summary)\n",
    "\n",
    "                m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "                summary[m_key] = OrderedDict()\n",
    "                summary[m_key]['input_shape'] = list(input[0].size())\n",
    "                summary[m_key]['input_shape'][0] = -1\n",
    "                summary[m_key]['output_shape'] = list(output.size())\n",
    "                summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "                params = 0\n",
    "                if hasattr(module, 'weight'):\n",
    "                    params += th.prod(th.LongTensor(list(module.weight.size())))\n",
    "                    if module.weight.requires_grad:\n",
    "                        summary[m_key]['trainable'] = True\n",
    "                    else:\n",
    "                        summary[m_key]['trainable'] = False\n",
    "                if hasattr(module, 'bias'):\n",
    "                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n",
    "                summary[m_key]['nb_params'] = params\n",
    "                \n",
    "            if not isinstance(module, nn.Sequential) and \\\n",
    "               not isinstance(module, nn.ModuleList) and \\\n",
    "               not (module == model):\n",
    "                hooks.append(module.register_forward_hook(hook))\n",
    "                \n",
    "        dtype = th.cuda.FloatTensor\n",
    "        \n",
    "        # check if there are multiple inputs to the network\n",
    "        if isinstance(input_size[0], (list, tuple)):\n",
    "            x = [Variable(th.rand(1,*in_size)).type(dtype) for in_size in input_size]\n",
    "        else:\n",
    "            x = Variable(th.rand(1,*input_size)).type(dtype)\n",
    "            \n",
    "        print(x.shape)\n",
    "        print(type(x[0]))\n",
    "        # create properties\n",
    "        summary = OrderedDict()\n",
    "        hooks = []\n",
    "        # register hook\n",
    "        model.apply(register_hook)\n",
    "        # make a forward pass\n",
    "        model(x)\n",
    "        # remove these hooks\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        print('----------------------------------------------------------------')\n",
    "        line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shpae', 'Param #')\n",
    "        print(line_new)\n",
    "        print('================================================================')\n",
    "        total_params = 0\n",
    "        trainable_params = 0\n",
    "        for layer in summary:\n",
    "            ## input_shape, output_shape, trainable, nb_params\n",
    "            line_new = '{:>20}  {:>25} {:>15}'.format(layer, summary[layer]['output_shape'], summary[layer]['nb_params'])\n",
    "            total_params += summary[layer]['nb_params']\n",
    "            if 'trainable' in summary[layer]:\n",
    "                if summary[layer]['trainable'] == True:\n",
    "                    trainable_params += summary[layer]['nb_params']\n",
    "            print(line_new)\n",
    "        print('================================================================')\n",
    "        print('Total params: ' + str(total_params))\n",
    "        print('Trainable params: ' + str(trainable_params))\n",
    "        print('Non-trainable params: ' + str(total_params - trainable_params))\n",
    "        print('----------------------------------------------------------------')\n",
    "        return summary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
