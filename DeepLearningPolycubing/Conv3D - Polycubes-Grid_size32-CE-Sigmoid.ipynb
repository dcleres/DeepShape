{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=32\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensor to a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "torch.Size([60, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([45, 1, 32, 32, 32])\n",
      "validation torch.Size([15, 1, 32, 32, 32])\n",
      "train_target torch.Size([45, 32, 32, 32])\n",
      "validation_target torch.Size([15, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target,batch_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:, 0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, 1, grid_size, grid_size, grid_size).float())\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, 1, grid_size, grid_size, grid_size).float())\n",
    "\n",
    "labels_train = preprocessed_input_train_target.float()\n",
    "labels_validation = preprocessed_input_validation_target.float()\n",
    "\n",
    "print('train', train_input.shape)\n",
    "print('validation', validation_input.shape)\n",
    "print('train_target', labels_train.shape)\n",
    "print('validation_target', labels_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n",
      "Epoch Number :  0\n",
      "\t Training accuracy:  41.99883355034722\n",
      "\t Validation accuracy  41.694742838541664\n",
      "\t Epoch Loss  2.123506546020508\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  42.23985460069444\n",
      "\t Validation accuracy  41.882527669270836\n",
      "\t Epoch Loss  2.0980615615844727\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  56.718410915798614\n",
      "\t Validation accuracy  56.4117431640625\n",
      "\t Epoch Loss  2.0866212844848633\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  54.758029513888886\n",
      "\t Validation accuracy  54.385986328125\n",
      "\t Epoch Loss  2.079710006713867\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  43.108791775173614\n",
      "\t Validation accuracy  42.102254231770836\n",
      "\t Epoch Loss  2.0749034881591797\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  39.026217990451386\n",
      "\t Validation accuracy  37.827962239583336\n",
      "\t Epoch Loss  2.0715861320495605\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  40.49079047309028\n",
      "\t Validation accuracy  39.708658854166664\n",
      "\t Epoch Loss  2.069072723388672\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  41.55029296875\n",
      "\t Validation accuracy  40.950113932291664\n",
      "\t Epoch Loss  2.0667738914489746\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  42.476399739583336\n",
      "\t Validation accuracy  42.000935872395836\n",
      "\t Epoch Loss  2.0646920204162598\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  43.277859157986114\n",
      "\t Validation accuracy  42.8692626953125\n",
      "\t Epoch Loss  2.062448740005493\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  45.64887152777778\n",
      "\t Validation accuracy  45.187581380208336\n",
      "\t Epoch Loss  2.060502529144287\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  46.90911187065972\n",
      "\t Validation accuracy  46.742960611979164\n",
      "\t Epoch Loss  2.0588479042053223\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  48.08770073784722\n",
      "\t Validation accuracy  47.703450520833336\n",
      "\t Epoch Loss  2.057255506515503\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  49.152628580729164\n",
      "\t Validation accuracy  48.7158203125\n",
      "\t Epoch Loss  2.0556437969207764\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  50.05242241753472\n",
      "\t Validation accuracy  50.11474609375\n",
      "\t Epoch Loss  2.054124355316162\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  51.72607421875\n",
      "\t Validation accuracy  51.678059895833336\n",
      "\t Epoch Loss  2.052842140197754\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  53.29352484809028\n",
      "\t Validation accuracy  53.5382080078125\n",
      "\t Epoch Loss  2.051567316055298\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  54.623684353298614\n",
      "\t Validation accuracy  54.5159912109375\n",
      "\t Epoch Loss  2.050283908843994\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  69.37154134114583\n",
      "\t Validation accuracy  68.26131184895833\n",
      "\t Epoch Loss  2.0489583015441895\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  80.01471625434027\n",
      "\t Validation accuracy  75.53446451822917\n",
      "\t Epoch Loss  2.0476315021514893\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  96.41194661458333\n",
      "\t Validation accuracy  96.6754150390625\n",
      "\t Epoch Loss  2.0454089641571045\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  94.91041395399306\n",
      "\t Validation accuracy  95.13142903645833\n",
      "\t Epoch Loss  2.0430495738983154\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  96.93868001302083\n",
      "\t Validation accuracy  96.88863118489583\n",
      "\t Epoch Loss  2.0341928005218506\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  97.49362521701389\n",
      "\t Validation accuracy  97.44384765625\n",
      "\t Epoch Loss  2.0234861373901367\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  97.44391547309027\n",
      "\t Validation accuracy  97.37508138020833\n",
      "\t Epoch Loss  2.019325017929077\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  97.16600206163194\n",
      "\t Validation accuracy  96.9989013671875\n",
      "\t Epoch Loss  2.01729154586792\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  97.24270290798611\n",
      "\t Validation accuracy  97.10408528645833\n",
      "\t Epoch Loss  2.0153398513793945\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  97.21584743923611\n",
      "\t Validation accuracy  96.998291015625\n",
      "\t Epoch Loss  2.0135154724121094\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  97.28352864583333\n",
      "\t Validation accuracy  97.08109537760417\n",
      "\t Epoch Loss  2.009031295776367\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  97.34307183159723\n",
      "\t Validation accuracy  97.16796875\n",
      "\t Epoch Loss  2.003035545349121\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  97.32523600260417\n",
      "\t Validation accuracy  97.0977783203125\n",
      "\t Epoch Loss  2.0007896423339844\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  97.37996419270833\n",
      "\t Validation accuracy  97.1270751953125\n",
      "\t Epoch Loss  1.9984921216964722\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  97.46914333767361\n",
      "\t Validation accuracy  97.20255533854167\n",
      "\t Epoch Loss  1.9968578815460205\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  97.5390625\n",
      "\t Validation accuracy  97.26094563802083\n",
      "\t Epoch Loss  1.995387315750122\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  97.53512912326389\n",
      "\t Validation accuracy  97.215576171875\n",
      "\t Epoch Loss  1.9937608242034912\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  97.56449381510417\n",
      "\t Validation accuracy  97.22269694010417\n",
      "\t Epoch Loss  1.9919252395629883\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  97.50413682725694\n",
      "\t Validation accuracy  97.07173665364583\n",
      "\t Epoch Loss  1.9908254146575928\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  97.67144097222223\n",
      "\t Validation accuracy  97.28963216145833\n",
      "\t Epoch Loss  1.9898979663848877\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  97.46595594618056\n",
      "\t Validation accuracy  96.88883463541667\n",
      "\t Epoch Loss  1.9884717464447021\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  97.74563259548611\n",
      "\t Validation accuracy  97.3040771484375\n",
      "\t Epoch Loss  1.9860475063323975\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  97.50522189670139\n",
      "\t Validation accuracy  96.94173177083333\n",
      "\t Epoch Loss  1.9812602996826172\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  97.49559190538194\n",
      "\t Validation accuracy  96.87703450520833\n",
      "\t Epoch Loss  1.9750086069107056\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  97.83169216579861\n",
      "\t Validation accuracy  97.3675537109375\n",
      "\t Epoch Loss  1.972548484802246\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  97.46710883246527\n",
      "\t Validation accuracy  96.81355794270833\n",
      "\t Epoch Loss  1.9713730812072754\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  97.82212999131944\n",
      "\t Validation accuracy  97.28963216145833\n",
      "\t Epoch Loss  1.9698195457458496\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  97.57900661892361\n",
      "\t Validation accuracy  96.95027669270833\n",
      "\t Epoch Loss  1.9686336517333984\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  97.61508517795139\n",
      "\t Validation accuracy  97.12117513020833\n",
      "\t Epoch Loss  1.9668464660644531\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  98.16033257378473\n",
      "\t Validation accuracy  97.57486979166667\n",
      "\t Epoch Loss  1.9659647941589355\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  97.58409288194444\n",
      "\t Validation accuracy  96.64937337239583\n",
      "\t Epoch Loss  1.9641894102096558\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  97.87638346354167\n",
      "\t Validation accuracy  97.31587727864583\n",
      "\t Epoch Loss  1.9638278484344482\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  97.56374782986111\n",
      "\t Validation accuracy  96.70186360677083\n",
      "\t Epoch Loss  1.9626448154449463\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  97.84098307291667\n",
      "\t Validation accuracy  97.15576171875\n",
      "\t Epoch Loss  1.9621813297271729\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  97.61942545572917\n",
      "\t Validation accuracy  96.74947102864583\n",
      "\t Epoch Loss  1.961120843887329\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  98.1964111328125\n",
      "\t Validation accuracy  97.31770833333333\n",
      "\t Epoch Loss  1.9626760482788086\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  97.58795844184027\n",
      "\t Validation accuracy  97.10530598958333\n",
      "\t Epoch Loss  1.9599814414978027\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  97.62369791666667\n",
      "\t Validation accuracy  97.01395670572917\n",
      "\t Epoch Loss  1.9620347023010254\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  98.0084228515625\n",
      "\t Validation accuracy  97.1435546875\n",
      "\t Epoch Loss  1.95945143699646\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  97.72481282552083\n",
      "\t Validation accuracy  96.74519856770833\n",
      "\t Epoch Loss  1.9579839706420898\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  98.18732367621527\n",
      "\t Validation accuracy  96.98954264322917\n",
      "\t Epoch Loss  1.9568994045257568\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  97.90228949652777\n",
      "\t Validation accuracy  96.78690592447917\n",
      "\t Epoch Loss  1.9554245471954346\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  98.27799479166667\n",
      "\t Validation accuracy  96.9195556640625\n",
      "\t Epoch Loss  1.9539070129394531\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  97.91252983940973\n",
      "\t Validation accuracy  96.619873046875\n",
      "\t Epoch Loss  1.9518694877624512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  62\n",
      "\t Training accuracy:  98.44584147135417\n",
      "\t Validation accuracy  96.89168294270833\n",
      "\t Epoch Loss  1.9506983757019043\n",
      "Epoch Number :  63\n",
      "\t Training accuracy:  97.3291015625\n",
      "\t Validation accuracy  96.16312662760417\n",
      "\t Epoch Loss  1.9487462043762207\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  98.4478759765625\n",
      "\t Validation accuracy  97.19828287760417\n",
      "\t Epoch Loss  1.9473358392715454\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  97.97234429253473\n",
      "\t Validation accuracy  96.74702962239583\n",
      "\t Epoch Loss  1.947324514389038\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  97.69761827256944\n",
      "\t Validation accuracy  96.65852864583333\n",
      "\t Epoch Loss  1.9427998065948486\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  98.00048828125\n",
      "\t Validation accuracy  96.65873209635417\n",
      "\t Epoch Loss  1.939400315284729\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  98.07325575086806\n",
      "\t Validation accuracy  96.57999674479167\n",
      "\t Epoch Loss  1.9371016025543213\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  98.01751030815973\n",
      "\t Validation accuracy  96.86604817708333\n",
      "\t Epoch Loss  1.9355862140655518\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  98.24259440104167\n",
      "\t Validation accuracy  96.8975830078125\n",
      "\t Epoch Loss  1.9334444999694824\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  97.99140082465277\n",
      "\t Validation accuracy  96.47115071614583\n",
      "\t Epoch Loss  1.931110143661499\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  98.08627658420139\n",
      "\t Validation accuracy  96.36250813802083\n",
      "\t Epoch Loss  1.9291033744812012\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  97.94521755642361\n",
      "\t Validation accuracy  96.287841796875\n",
      "\t Epoch Loss  1.9273273944854736\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  97.94440375434027\n",
      "\t Validation accuracy  96.38509114583333\n",
      "\t Epoch Loss  1.925845742225647\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  98.56099446614583\n",
      "\t Validation accuracy  96.46240234375\n",
      "\t Epoch Loss  1.9248409271240234\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  97.72101508246527\n",
      "\t Validation accuracy  96.34501139322917\n",
      "\t Epoch Loss  1.9236009120941162\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  98.23594835069444\n",
      "\t Validation accuracy  96.92830403645833\n",
      "\t Epoch Loss  1.9225022792816162\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  98.21851942274306\n",
      "\t Validation accuracy  96.572265625\n",
      "\t Epoch Loss  1.9195528030395508\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  97.96407063802083\n",
      "\t Validation accuracy  96.11287434895833\n",
      "\t Epoch Loss  1.9170039892196655\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  98.56499565972223\n",
      "\t Validation accuracy  96.42903645833333\n",
      "\t Epoch Loss  1.9152987003326416\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  97.68263075086806\n",
      "\t Validation accuracy  96.30269368489583\n",
      "\t Epoch Loss  1.9129910469055176\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  98.64759657118056\n",
      "\t Validation accuracy  96.49820963541667\n",
      "\t Epoch Loss  1.911271572113037\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  97.84552680121527\n",
      "\t Validation accuracy  96.00382486979167\n",
      "\t Epoch Loss  1.9099421501159668\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  98.433837890625\n",
      "\t Validation accuracy  96.3470458984375\n",
      "\t Epoch Loss  1.9080957174301147\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  98.01527235243056\n",
      "\t Validation accuracy  96.37654622395833\n",
      "\t Epoch Loss  1.9061741828918457\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  98.404541015625\n",
      "\t Validation accuracy  96.446533203125\n",
      "\t Epoch Loss  1.9040265083312988\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  98.12608506944444\n",
      "\t Validation accuracy  96.32486979166667\n",
      "\t Epoch Loss  1.902334451675415\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  98.49955240885417\n",
      "\t Validation accuracy  96.34318033854167\n",
      "\t Epoch Loss  1.9008245468139648\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  98.20170084635417\n",
      "\t Validation accuracy  96.26546223958333\n",
      "\t Epoch Loss  1.898965835571289\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  98.25093587239583\n",
      "\t Validation accuracy  96.33138020833333\n",
      "\t Epoch Loss  1.8975874185562134\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  98.50572374131944\n",
      "\t Validation accuracy  96.1602783203125\n",
      "\t Epoch Loss  1.895853877067566\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  98.16575792100694\n",
      "\t Validation accuracy  96.38346354166667\n",
      "\t Epoch Loss  1.8941030502319336\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  98.71968587239583\n",
      "\t Validation accuracy  96.46484375\n",
      "\t Epoch Loss  1.8921152353286743\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  98.14324273003473\n",
      "\t Validation accuracy  96.31368001302083\n",
      "\t Epoch Loss  1.8903734683990479\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  98.6785888671875\n",
      "\t Validation accuracy  96.1663818359375\n",
      "\t Epoch Loss  1.887693166732788\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  98.14371744791667\n",
      "\t Validation accuracy  96.28662109375\n",
      "\t Epoch Loss  1.8865611553192139\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  98.62711588541667\n",
      "\t Validation accuracy  96.46443684895833\n",
      "\t Epoch Loss  1.8844332695007324\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  98.26422797309027\n",
      "\t Validation accuracy  96.298828125\n",
      "\t Epoch Loss  1.882408618927002\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  98.47073025173611\n",
      "\t Validation accuracy  96.50431315104167\n",
      "\t Epoch Loss  1.8802440166473389\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  98.56635199652777\n",
      "\t Validation accuracy  96.14664713541667\n",
      "\t Epoch Loss  1.8783676624298096\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  98.03955078125\n",
      "\t Validation accuracy  96.34928385416667\n",
      "\t Epoch Loss  1.8773601055145264\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  98.66977267795139\n",
      "\t Validation accuracy  96.48295084635417\n",
      "\t Epoch Loss  1.876541018486023\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  98.28036838107639\n",
      "\t Validation accuracy  96.24593098958333\n",
      "\t Epoch Loss  1.874053716659546\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  98.59090169270833\n",
      "\t Validation accuracy  96.46952311197917\n",
      "\t Epoch Loss  1.872896671295166\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  98.22977701822917\n",
      "\t Validation accuracy  96.0357666015625\n",
      "\t Epoch Loss  1.8718725442886353\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  98.50538465711806\n",
      "\t Validation accuracy  96.60054524739583\n",
      "\t Epoch Loss  1.8707796335220337\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  98.40352376302083\n",
      "\t Validation accuracy  96.33443196614583\n",
      "\t Epoch Loss  1.869846224784851\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  98.40169270833333\n",
      "\t Validation accuracy  96.37491861979167\n",
      "\t Epoch Loss  1.868239164352417\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  98.31787109375\n",
      "\t Validation accuracy  96.48111979166667\n",
      "\t Epoch Loss  1.8673570156097412\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  98.52084689670139\n",
      "\t Validation accuracy  96.19527180989583\n",
      "\t Epoch Loss  1.8669872283935547\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  98.28884548611111\n",
      "\t Validation accuracy  96.46016438802083\n",
      "\t Epoch Loss  1.8659547567367554\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  98.98335774739583\n",
      "\t Validation accuracy  96.3330078125\n",
      "\t Epoch Loss  1.8660361766815186\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  98.23092990451389\n",
      "\t Validation accuracy  96.00728352864583\n",
      "\t Epoch Loss  1.86519455909729\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  98.72422960069444\n",
      "\t Validation accuracy  96.63411458333333\n",
      "\t Epoch Loss  1.8648383617401123\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  98.37714301215277\n",
      "\t Validation accuracy  96.32649739583333\n",
      "\t Epoch Loss  1.8645493984222412\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  98.44407823350694\n",
      "\t Validation accuracy  96.31368001302083\n",
      "\t Epoch Loss  1.8626432418823242\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  98.47805447048611\n",
      "\t Validation accuracy  96.33524576822917\n",
      "\t Epoch Loss  1.8626655340194702\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  98.31488715277777\n",
      "\t Validation accuracy  96.3873291015625\n",
      "\t Epoch Loss  1.860746145248413\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  98.55305989583333\n",
      "\t Validation accuracy  96.2542724609375\n",
      "\t Epoch Loss  1.8599506616592407\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  98.3349609375\n",
      "\t Validation accuracy  96.38773600260417\n",
      "\t Epoch Loss  1.8588593006134033\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  98.46808539496527\n",
      "\t Validation accuracy  96.59708658854167\n",
      "\t Epoch Loss  1.8578447103500366\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  98.61470540364583\n",
      "\t Validation accuracy  96.22355143229167\n",
      "\t Epoch Loss  1.856379508972168\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  98.35740831163194\n",
      "\t Validation accuracy  96.50614420572917\n",
      "\t Epoch Loss  1.8553348779678345\n",
      "Epoch Number :  124\n",
      "\t Training accuracy:  98.97040473090277\n",
      "\t Validation accuracy  96.46199544270833\n",
      "\t Epoch Loss  1.8548309803009033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  125\n",
      "\t Training accuracy:  98.29739040798611\n",
      "\t Validation accuracy  96.2933349609375\n",
      "\t Epoch Loss  1.8521549701690674\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  98.74484592013889\n",
      "\t Validation accuracy  96.5924072265625\n",
      "\t Epoch Loss  1.8507193326950073\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  98.34058973524306\n",
      "\t Validation accuracy  96.256103515625\n",
      "\t Epoch Loss  1.848457932472229\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  98.43024359809027\n",
      "\t Validation accuracy  96.407470703125\n",
      "\t Epoch Loss  1.8459522724151611\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  98.59110514322917\n",
      "\t Validation accuracy  96.44999186197917\n",
      "\t Epoch Loss  1.8436369895935059\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  98.36568196614583\n",
      "\t Validation accuracy  96.35965983072917\n",
      "\t Epoch Loss  1.8423165082931519\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  98.807373046875\n",
      "\t Validation accuracy  96.54703776041667\n",
      "\t Epoch Loss  1.8403970003128052\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  98.45967610677083\n",
      "\t Validation accuracy  96.34480794270833\n",
      "\t Epoch Loss  1.838278889656067\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  98.51901584201389\n",
      "\t Validation accuracy  96.45589192708333\n",
      "\t Epoch Loss  1.8370801210403442\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  98.78851996527777\n",
      "\t Validation accuracy  96.3983154296875\n",
      "\t Epoch Loss  1.8349850177764893\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  98.42888726128473\n",
      "\t Validation accuracy  96.53971354166667\n",
      "\t Epoch Loss  1.8336877822875977\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  98.64827473958333\n",
      "\t Validation accuracy  96.5985107421875\n",
      "\t Epoch Loss  1.832109808921814\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  98.73067220052083\n",
      "\t Validation accuracy  96.56392415364583\n",
      "\t Epoch Loss  1.831251859664917\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  98.33604600694444\n",
      "\t Validation accuracy  96.38997395833333\n",
      "\t Epoch Loss  1.8296997547149658\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  99.04317220052083\n",
      "\t Validation accuracy  96.64693196614583\n",
      "\t Epoch Loss  1.8288226127624512\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  98.21729871961806\n",
      "\t Validation accuracy  96.4056396484375\n",
      "\t Epoch Loss  1.826897144317627\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  99.17853461371527\n",
      "\t Validation accuracy  96.644287109375\n",
      "\t Epoch Loss  1.8268702030181885\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  98.46035427517361\n",
      "\t Validation accuracy  96.2725830078125\n",
      "\t Epoch Loss  1.824887990951538\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  98.53000217013889\n",
      "\t Validation accuracy  96.53422037760417\n",
      "\t Epoch Loss  1.823307991027832\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  98.59151204427083\n",
      "\t Validation accuracy  96.56026204427083\n",
      "\t Epoch Loss  1.8219404220581055\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  98.65376790364583\n",
      "\t Validation accuracy  96.10107421875\n",
      "\t Epoch Loss  1.820174217224121\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  98.56675889756944\n",
      "\t Validation accuracy  96.46402994791667\n",
      "\t Epoch Loss  1.8192124366760254\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  98.92422146267361\n",
      "\t Validation accuracy  96.24226888020833\n",
      "\t Epoch Loss  1.8173418045043945\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  98.44028049045139\n",
      "\t Validation accuracy  96.42069498697917\n",
      "\t Epoch Loss  1.8171989917755127\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  99.13370768229167\n",
      "\t Validation accuracy  96.60380045572917\n",
      "\t Epoch Loss  1.815862774848938\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  98.53156195746527\n",
      "\t Validation accuracy  96.35111490885417\n",
      "\t Epoch Loss  1.8146610260009766\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  98.94612630208333\n",
      "\t Validation accuracy  96.54947916666667\n",
      "\t Epoch Loss  1.8124122619628906\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  98.58676486545139\n",
      "\t Validation accuracy  96.47013346354167\n",
      "\t Epoch Loss  1.8109376430511475\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  98.87797037760417\n",
      "\t Validation accuracy  96.55314127604167\n",
      "\t Epoch Loss  1.8100847005844116\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  98.46605088975694\n",
      "\t Validation accuracy  96.45792643229167\n",
      "\t Epoch Loss  1.8093109130859375\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  99.31613498263889\n",
      "\t Validation accuracy  96.80643717447917\n",
      "\t Epoch Loss  1.808221697807312\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  98.62297905815973\n",
      "\t Validation accuracy  96.55110677083333\n",
      "\t Epoch Loss  1.8065052032470703\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  99.17914496527777\n",
      "\t Validation accuracy  96.72444661458333\n",
      "\t Epoch Loss  1.8048982620239258\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  98.55238172743056\n",
      "\t Validation accuracy  96.50594075520833\n",
      "\t Epoch Loss  1.802849531173706\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  99.21671549479167\n",
      "\t Validation accuracy  96.67460123697917\n",
      "\t Epoch Loss  1.801867961883545\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  98.68320041232639\n",
      "\t Validation accuracy  96.57145182291667\n",
      "\t Epoch Loss  1.79972505569458\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  98.94605848524306\n",
      "\t Validation accuracy  96.77836100260417\n",
      "\t Epoch Loss  1.798213243484497\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  98.95100911458333\n",
      "\t Validation accuracy  96.58772786458333\n",
      "\t Epoch Loss  1.79624342918396\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  98.97630479600694\n",
      "\t Validation accuracy  96.60115559895833\n",
      "\t Epoch Loss  1.7943644523620605\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  98.85525173611111\n",
      "\t Validation accuracy  96.5985107421875\n",
      "\t Epoch Loss  1.7927377223968506\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  98.97488064236111\n",
      "\t Validation accuracy  96.6058349609375\n",
      "\t Epoch Loss  1.7906081676483154\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  98.96084255642361\n",
      "\t Validation accuracy  96.52608235677083\n",
      "\t Epoch Loss  1.7890375852584839\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  98.973388671875\n",
      "\t Validation accuracy  96.60664876302083\n",
      "\t Epoch Loss  1.7871142625808716\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  98.95657009548611\n",
      "\t Validation accuracy  96.63899739583333\n",
      "\t Epoch Loss  1.7847574949264526\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  98.87335883246527\n",
      "\t Validation accuracy  96.6082763671875\n",
      "\t Epoch Loss  1.7834306955337524\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  99.20823838975694\n",
      "\t Validation accuracy  96.60420735677083\n",
      "\t Epoch Loss  1.7820990085601807\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  98.79041883680556\n",
      "\t Validation accuracy  96.55517578125\n",
      "\t Epoch Loss  1.781376838684082\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  99.10413953993056\n",
      "\t Validation accuracy  96.65995279947917\n",
      "\t Epoch Loss  1.7799118757247925\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  99.11485460069444\n",
      "\t Validation accuracy  96.5826416015625\n",
      "\t Epoch Loss  1.778764009475708\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  98.82914225260417\n",
      "\t Validation accuracy  96.62089029947917\n",
      "\t Epoch Loss  1.7781541347503662\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  99.29646809895833\n",
      "\t Validation accuracy  96.8084716796875\n",
      "\t Epoch Loss  1.7770798206329346\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  98.853759765625\n",
      "\t Validation accuracy  96.56107584635417\n",
      "\t Epoch Loss  1.7764675617218018\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  99.12502712673611\n",
      "\t Validation accuracy  96.6650390625\n",
      "\t Epoch Loss  1.7753393650054932\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  99.21271430121527\n",
      "\t Validation accuracy  96.66483561197917\n",
      "\t Epoch Loss  1.7747867107391357\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  98.78811306423611\n",
      "\t Validation accuracy  96.639404296875\n",
      "\t Epoch Loss  1.7743027210235596\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  99.39948187934027\n",
      "\t Validation accuracy  96.75008138020833\n",
      "\t Epoch Loss  1.7742760181427002\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  98.90692816840277\n",
      "\t Validation accuracy  96.5435791015625\n",
      "\t Epoch Loss  1.7731074094772339\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  99.21440972222223\n",
      "\t Validation accuracy  96.79728190104167\n",
      "\t Epoch Loss  1.7722399234771729\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  99.14021809895833\n",
      "\t Validation accuracy  96.6510009765625\n",
      "\t Epoch Loss  1.7719522714614868\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  98.93202039930556\n",
      "\t Validation accuracy  96.70613606770833\n",
      "\t Epoch Loss  1.7715367078781128\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  99.17683919270833\n",
      "\t Validation accuracy  96.719970703125\n",
      "\t Epoch Loss  1.7707750797271729\n",
      "Epoch Number :  186\n",
      "\t Training accuracy:  99.04629177517361\n",
      "\t Validation accuracy  96.641845703125\n",
      "\t Epoch Loss  1.7700622081756592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  187\n",
      "\t Training accuracy:  99.09322102864583\n",
      "\t Validation accuracy  96.68904622395833\n",
      "\t Epoch Loss  1.7694711685180664\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  99.09220377604167\n",
      "\t Validation accuracy  96.7010498046875\n",
      "\t Epoch Loss  1.7686221599578857\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  99.11600748697917\n",
      "\t Validation accuracy  96.724853515625\n",
      "\t Epoch Loss  1.7681186199188232\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  99.17955186631944\n",
      "\t Validation accuracy  96.73482259114583\n",
      "\t Epoch Loss  1.7674415111541748\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  99.03822157118056\n",
      "\t Validation accuracy  96.69514973958333\n",
      "\t Epoch Loss  1.7663731575012207\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  99.28331163194444\n",
      "\t Validation accuracy  96.7822265625\n",
      "\t Epoch Loss  1.7659249305725098\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  98.89010959201389\n",
      "\t Validation accuracy  96.67765299479167\n",
      "\t Epoch Loss  1.7647724151611328\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  99.21834309895833\n",
      "\t Validation accuracy  96.90348307291667\n",
      "\t Epoch Loss  1.7638349533081055\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  99.18816460503473\n",
      "\t Validation accuracy  96.683349609375\n",
      "\t Epoch Loss  1.7621901035308838\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  98.86867947048611\n",
      "\t Validation accuracy  96.64835611979167\n",
      "\t Epoch Loss  1.7610421180725098\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  99.31966145833333\n",
      "\t Validation accuracy  96.81111653645833\n",
      "\t Epoch Loss  1.7597211599349976\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  98.90177408854167\n",
      "\t Validation accuracy  96.6754150390625\n",
      "\t Epoch Loss  1.7576911449432373\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  99.51368543836806\n",
      "\t Validation accuracy  96.80318196614583\n",
      "\t Epoch Loss  1.7567203044891357\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  98.85911729600694\n",
      "\t Validation accuracy  96.57063802083333\n",
      "\t Epoch Loss  1.7549405097961426\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  99.30508083767361\n",
      "\t Validation accuracy  96.92545572916667\n",
      "\t Epoch Loss  1.75331711769104\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  99.16205512152777\n",
      "\t Validation accuracy  96.7840576171875\n",
      "\t Epoch Loss  1.7515451908111572\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  98.85240342881944\n",
      "\t Validation accuracy  96.70491536458333\n",
      "\t Epoch Loss  1.749650001525879\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  99.37859429253473\n",
      "\t Validation accuracy  96.87255859375\n",
      "\t Epoch Loss  1.7472994327545166\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  98.84853786892361\n",
      "\t Validation accuracy  96.6485595703125\n",
      "\t Epoch Loss  1.7463871240615845\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  99.41399468315973\n",
      "\t Validation accuracy  96.81294759114583\n",
      "\t Epoch Loss  1.7434897422790527\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  98.99264865451389\n",
      "\t Validation accuracy  96.71854654947917\n",
      "\t Epoch Loss  1.743088722229004\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  99.33268229166667\n",
      "\t Validation accuracy  96.871337890625\n",
      "\t Epoch Loss  1.740896463394165\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  99.01482476128473\n",
      "\t Validation accuracy  96.78568522135417\n",
      "\t Epoch Loss  1.740006685256958\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  99.24757215711806\n",
      "\t Validation accuracy  96.69962565104167\n",
      "\t Epoch Loss  1.7386314868927002\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  99.37940809461806\n",
      "\t Validation accuracy  96.90144856770833\n",
      "\t Epoch Loss  1.7374190092086792\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  99.19114854600694\n",
      "\t Validation accuracy  96.78385416666667\n",
      "\t Epoch Loss  1.7363240718841553\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  99.19379340277777\n",
      "\t Validation accuracy  96.83207194010417\n",
      "\t Epoch Loss  1.735216736793518\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  99.40897623697917\n",
      "\t Validation accuracy  96.800537109375\n",
      "\t Epoch Loss  1.7341786623001099\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  99.06385633680556\n",
      "\t Validation accuracy  96.70430501302083\n",
      "\t Epoch Loss  1.7331637144088745\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  99.44715711805556\n",
      "\t Validation accuracy  96.80643717447917\n",
      "\t Epoch Loss  1.7320830821990967\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  99.08494737413194\n",
      "\t Validation accuracy  96.74906412760417\n",
      "\t Epoch Loss  1.7310361862182617\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  99.18585883246527\n",
      "\t Validation accuracy  96.88232421875\n",
      "\t Epoch Loss  1.730294942855835\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  99.51165093315973\n",
      "\t Validation accuracy  96.83939615885417\n",
      "\t Epoch Loss  1.7293611764907837\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  99.13899739583333\n",
      "\t Validation accuracy  96.85811360677083\n",
      "\t Epoch Loss  1.7286183834075928\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  99.21040852864583\n",
      "\t Validation accuracy  96.85201009114583\n",
      "\t Epoch Loss  1.7277812957763672\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  99.40409342447917\n",
      "\t Validation accuracy  96.73990885416667\n",
      "\t Epoch Loss  1.7270245552062988\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  99.22654893663194\n",
      "\t Validation accuracy  96.89717610677083\n",
      "\t Epoch Loss  1.7262626886367798\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  99.28243001302083\n",
      "\t Validation accuracy  96.82963053385417\n",
      "\t Epoch Loss  1.7253882884979248\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  99.49150933159723\n",
      "\t Validation accuracy  96.83817545572917\n",
      "\t Epoch Loss  1.7247235774993896\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  98.94212510850694\n",
      "\t Validation accuracy  96.8157958984375\n",
      "\t Epoch Loss  1.7236835956573486\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  99.44600423177083\n",
      "\t Validation accuracy  96.69108072916667\n",
      "\t Epoch Loss  1.7227392196655273\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  99.66193305121527\n",
      "\t Validation accuracy  97.01192220052083\n",
      "\t Epoch Loss  1.7227455377578735\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  98.8531494140625\n",
      "\t Validation accuracy  96.59525553385417\n",
      "\t Epoch Loss  1.7224068641662598\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  99.28093804253473\n",
      "\t Validation accuracy  96.79545084635417\n",
      "\t Epoch Loss  1.7229063510894775\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  99.32542588975694\n",
      "\t Validation accuracy  96.88944498697917\n",
      "\t Epoch Loss  1.7225754261016846\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  98.63471137152777\n",
      "\t Validation accuracy  96.783447265625\n",
      "\t Epoch Loss  1.721121072769165\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target).long()  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True).long() # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    Noutputs = 1\n",
    "    \n",
    "Nbatches = int(math.ceil(Ntrain/batch_size)) #batch_size is defined above\n",
    "Nepochs = 250\n",
    "Nrep = 1\n",
    "        \n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "model = UnetGenerator_3d(in_dim=1, out_dim=Noutputs, num_filter=4)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.90)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "#optimizer = optim.RMSprop(model.parameters())\n",
    "#optimizer = optim.Rprop(model.parameters())\n",
    " \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_ep in range(Nepochs):\n",
    "    for b_start in range(0, Ntrain, batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "        if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "        else:\n",
    "            #if delta model is chosen\n",
    "            #batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output.view(bsize_eff,grid_size,grid_size,grid_size), train_target.narrow(0, b_start, bsize_eff))\n",
    "        ep_loss[i_ep] += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step(ep_loss[i_ep])\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target, batch_size, criterion)\n",
    "    nb_validation_errs = compute_nb_errors(model, validation_input, validation_target, batch_size, criterion)\n",
    "\n",
    "    Ntrain_nb = Ntrain*grid_size**3\n",
    "    Nvalidation_nb = Nvalidation*grid_size**3\n",
    "    print(\"Epoch Number : \", i_ep)\n",
    "    print(\"\\t Training accuracy: \", (100*(Ntrain_nb-nb_train_errs)/Ntrain_nb))\n",
    "    print(\"\\t Validation accuracy \",(100*(Nvalidation_nb-nb_validation_errs)/Nvalidation_nb))\n",
    "\n",
    "    print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "\n",
    "    train_errors[i_ep] = nb_train_errs\n",
    "    validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target[44,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[14,1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array(100*(Ntrain_nb-train_errors)/Ntrain_nb)\n",
    "validation_accurcy = np.array(100*(Nvalidation_nb-validation_errors)/Nvalidation_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accurcy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''voxels = np.array(output[4,:,:,:])\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels)\n",
    "fig.savefig('VoxelizedFinal.png')\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def summary(input_size, model):\n",
    "        def register_hook(module):\n",
    "            def hook(module, input, output):\n",
    "                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "                module_idx = len(summary)\n",
    "\n",
    "                m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "                summary[m_key] = OrderedDict()\n",
    "                summary[m_key]['input_shape'] = list(input[0].size())\n",
    "                summary[m_key]['input_shape'][0] = -1\n",
    "                summary[m_key]['output_shape'] = list(output.size())\n",
    "                summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "                params = 0\n",
    "                if hasattr(module, 'weight'):\n",
    "                    params += th.prod(th.LongTensor(list(module.weight.size())))\n",
    "                    if module.weight.requires_grad:\n",
    "                        summary[m_key]['trainable'] = True\n",
    "                    else:\n",
    "                        summary[m_key]['trainable'] = False\n",
    "                if hasattr(module, 'bias'):\n",
    "                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n",
    "                summary[m_key]['nb_params'] = params\n",
    "                \n",
    "            if not isinstance(module, nn.Sequential) and \\\n",
    "               not isinstance(module, nn.ModuleList) and \\\n",
    "               not (module == model):\n",
    "                hooks.append(module.register_forward_hook(hook))\n",
    "                \n",
    "        dtype = th.cuda.FloatTensor\n",
    "        \n",
    "        # check if there are multiple inputs to the network\n",
    "        if isinstance(input_size[0], (list, tuple)):\n",
    "            x = [Variable(th.rand(1,*in_size)).type(dtype) for in_size in input_size]\n",
    "        else:\n",
    "            x = Variable(th.rand(1,*input_size)).type(dtype)\n",
    "            \n",
    "        print(x.shape)\n",
    "        print(type(x[0]))\n",
    "        # create properties\n",
    "        summary = OrderedDict()\n",
    "        hooks = []\n",
    "        # register hook\n",
    "        model.apply(register_hook)\n",
    "        # make a forward pass\n",
    "        model(x)\n",
    "        # remove these hooks\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        print('----------------------------------------------------------------')\n",
    "        line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shpae', 'Param #')\n",
    "        print(line_new)\n",
    "        print('================================================================')\n",
    "        total_params = 0\n",
    "        trainable_params = 0\n",
    "        for layer in summary:\n",
    "            ## input_shape, output_shape, trainable, nb_params\n",
    "            line_new = '{:>20}  {:>25} {:>15}'.format(layer, summary[layer]['output_shape'], summary[layer]['nb_params'])\n",
    "            total_params += summary[layer]['nb_params']\n",
    "            if 'trainable' in summary[layer]:\n",
    "                if summary[layer]['trainable'] == True:\n",
    "                    trainable_params += summary[layer]['nb_params']\n",
    "            print(line_new)\n",
    "        print('================================================================')\n",
    "        print('Total params: ' + str(total_params))\n",
    "        print('Trainable params: ' + str(trainable_params))\n",
    "        print('Non-trainable params: ' + str(total_params - trainable_params))\n",
    "        print('----------------------------------------------------------------')\n",
    "        return summary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
