{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utility import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "polycube_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/Generated-Cars/\"\n",
    "polycube_files = [f for f in listdir(polycube_path) if isfile(join(polycube_path, f))]\n",
    "\n",
    "voxelized_mesh_path = \"/Users/davidcleres/DeepShape/Polycubing-Automated/voxelizedMeshes/\"\n",
    "voxelized_mesh_files = [f for f in listdir(voxelized_mesh_path) if isfile(join(voxelized_mesh_path, f))]\n",
    "\n",
    "voxelizedFiles = []\n",
    "polycubedFiles = []\n",
    "\n",
    "for f in voxelized_mesh_files: \n",
    "    if f[-13:] == \"voxelized.txt\":\n",
    "        voxelizedFiles = np.hstack((voxelizedFiles, f))\n",
    "    \n",
    "for f in polycube_files:\n",
    "    if f[-14:] == \"finalCubes.txt\":\n",
    "        polycubedFiles = np.hstack((polycubedFiles, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=32\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensor to a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "<class 'torch.IntTensor'> torch.Size([32, 32, 32])\n",
      "torch.Size([60, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "voxelized_train_input, polycube_target=loadData(grid_size, polycube_path, voxelized_mesh_path, voxelizedFiles, polycubedFiles, loadFromScratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([45, 1, 32, 32, 32])\n",
      "validation torch.Size([15, 1, 32, 32, 32])\n",
      "train_target torch.Size([45, 32, 32, 32])\n",
      "validation_target torch.Size([15, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(voxelized_train_input, polycube_target,batch_size, False, False)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train)\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation)\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:, 0,0,0,0]) \n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0,0,0])\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, 1, grid_size, grid_size, grid_size).float())\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, 1, grid_size, grid_size, grid_size).float())\n",
    "\n",
    "labels_train = preprocessed_input_train_target.float()\n",
    "labels_validation = preprocessed_input_validation_target.float()\n",
    "\n",
    "print('train', train_input.shape)\n",
    "print('validation', validation_input.shape)\n",
    "print('train_target', labels_train.shape)\n",
    "print('validation_target', labels_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n",
      "Epoch Number :  0\n",
      "\t Training accuracy:  80.7977294921875\n",
      "\t Validation accuracy  80.31778971354167\n",
      "\t Epoch Loss  1.9901957511901855\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  81.395263671875\n",
      "\t Validation accuracy  80.91634114583333\n",
      "\t Epoch Loss  1.9006342887878418\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  85.98971896701389\n",
      "\t Validation accuracy  85.61055501302083\n",
      "\t Epoch Loss  1.8481688499450684\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  83.41959635416667\n",
      "\t Validation accuracy  83.12459309895833\n",
      "\t Epoch Loss  1.8189024925231934\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  89.18613009982639\n",
      "\t Validation accuracy  89.41752115885417\n",
      "\t Epoch Loss  1.7748970985412598\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  89.63460286458333\n",
      "\t Validation accuracy  89.0911865234375\n",
      "\t Epoch Loss  1.741786003112793\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  94.46268717447917\n",
      "\t Validation accuracy  94.06880696614583\n",
      "\t Epoch Loss  1.712183952331543\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  95.53093804253473\n",
      "\t Validation accuracy  95.2685546875\n",
      "\t Epoch Loss  1.6856319904327393\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  90.13597276475694\n",
      "\t Validation accuracy  89.76888020833333\n",
      "\t Epoch Loss  1.6660983562469482\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  94.61459689670139\n",
      "\t Validation accuracy  94.36808268229167\n",
      "\t Epoch Loss  1.6506578922271729\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  95.53310818142361\n",
      "\t Validation accuracy  95.23783365885417\n",
      "\t Epoch Loss  1.6459708213806152\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  93.66495768229167\n",
      "\t Validation accuracy  93.33577473958333\n",
      "\t Epoch Loss  1.62369966506958\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  95.05642361111111\n",
      "\t Validation accuracy  94.79410807291667\n",
      "\t Epoch Loss  1.6096152067184448\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  95.47336154513889\n",
      "\t Validation accuracy  95.24943033854167\n",
      "\t Epoch Loss  1.5924034118652344\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  95.55901421440973\n",
      "\t Validation accuracy  95.38533528645833\n",
      "\t Epoch Loss  1.5825772285461426\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  95.69044325086806\n",
      "\t Validation accuracy  95.51554361979167\n",
      "\t Epoch Loss  1.5739355087280273\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  95.93763563368056\n",
      "\t Validation accuracy  95.74015299479167\n",
      "\t Epoch Loss  1.5631712675094604\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  96.55741373697917\n",
      "\t Validation accuracy  96.2890625\n",
      "\t Epoch Loss  1.550441026687622\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  96.85872395833333\n",
      "\t Validation accuracy  96.591796875\n",
      "\t Epoch Loss  1.53931725025177\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  96.81694878472223\n",
      "\t Validation accuracy  96.54459635416667\n",
      "\t Epoch Loss  1.5325400829315186\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  96.92715115017361\n",
      "\t Validation accuracy  96.67928059895833\n",
      "\t Epoch Loss  1.5281579494476318\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  96.98689778645833\n",
      "\t Validation accuracy  96.7364501953125\n",
      "\t Epoch Loss  1.522230863571167\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  97.21598307291667\n",
      "\t Validation accuracy  96.93949381510417\n",
      "\t Epoch Loss  1.5137068033218384\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  96.76886664496527\n",
      "\t Validation accuracy  96.50309244791667\n",
      "\t Epoch Loss  1.5041799545288086\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  97.64838324652777\n",
      "\t Validation accuracy  97.3828125\n",
      "\t Epoch Loss  1.50020170211792\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  96.90131293402777\n",
      "\t Validation accuracy  96.5716552734375\n",
      "\t Epoch Loss  1.487911343574524\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  97.44411892361111\n",
      "\t Validation accuracy  97.1026611328125\n",
      "\t Epoch Loss  1.484140157699585\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  97.451171875\n",
      "\t Validation accuracy  97.115478515625\n",
      "\t Epoch Loss  1.4798076152801514\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  97.58558485243056\n",
      "\t Validation accuracy  97.21028645833333\n",
      "\t Epoch Loss  1.4769153594970703\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  97.44913736979167\n",
      "\t Validation accuracy  97.10795084635417\n",
      "\t Epoch Loss  1.4724922180175781\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  97.63563368055556\n",
      "\t Validation accuracy  97.2418212890625\n",
      "\t Epoch Loss  1.4677798748016357\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  97.46419270833333\n",
      "\t Validation accuracy  97.1295166015625\n",
      "\t Epoch Loss  1.46084725856781\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  97.75037977430556\n",
      "\t Validation accuracy  97.36490885416667\n",
      "\t Epoch Loss  1.452560305595398\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  96.76418728298611\n",
      "\t Validation accuracy  96.4892578125\n",
      "\t Epoch Loss  1.447521686553955\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  97.60708279079861\n",
      "\t Validation accuracy  97.2613525390625\n",
      "\t Epoch Loss  1.4438397884368896\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  97.54781087239583\n",
      "\t Validation accuracy  97.14436848958333\n",
      "\t Epoch Loss  1.4379905462265015\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  97.55032009548611\n",
      "\t Validation accuracy  97.19197591145833\n",
      "\t Epoch Loss  1.4345225095748901\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  97.57392035590277\n",
      "\t Validation accuracy  97.21781412760417\n",
      "\t Epoch Loss  1.4323995113372803\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  97.32143825954861\n",
      "\t Validation accuracy  96.9390869140625\n",
      "\t Epoch Loss  1.432796835899353\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  97.66635470920139\n",
      "\t Validation accuracy  97.23897298177083\n",
      "\t Epoch Loss  1.4293138980865479\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  97.61522081163194\n",
      "\t Validation accuracy  97.22574869791667\n",
      "\t Epoch Loss  1.4243659973144531\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  97.69497341579861\n",
      "\t Validation accuracy  97.3272705078125\n",
      "\t Epoch Loss  1.4200870990753174\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  97.66187879774306\n",
      "\t Validation accuracy  97.298583984375\n",
      "\t Epoch Loss  1.4151291847229004\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  97.74068196614583\n",
      "\t Validation accuracy  97.39990234375\n",
      "\t Epoch Loss  1.409674882888794\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  97.85054524739583\n",
      "\t Validation accuracy  97.43733723958333\n",
      "\t Epoch Loss  1.40355384349823\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  97.72508409288194\n",
      "\t Validation accuracy  97.364501953125\n",
      "\t Epoch Loss  1.398056149482727\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  97.61854383680556\n",
      "\t Validation accuracy  97.25382486979167\n",
      "\t Epoch Loss  1.3955597877502441\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  97.877197265625\n",
      "\t Validation accuracy  97.41719563802083\n",
      "\t Epoch Loss  1.391144037246704\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  97.82857259114583\n",
      "\t Validation accuracy  97.33479817708333\n",
      "\t Epoch Loss  1.3872096538543701\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  97.84077962239583\n",
      "\t Validation accuracy  97.43631998697917\n",
      "\t Epoch Loss  1.3894134759902954\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  93.57550726996527\n",
      "\t Validation accuracy  92.90934244791667\n",
      "\t Epoch Loss  1.4178283214569092\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  97.88302951388889\n",
      "\t Validation accuracy  97.4822998046875\n",
      "\t Epoch Loss  1.4133632183074951\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  97.88784450954861\n",
      "\t Validation accuracy  97.49247233072917\n",
      "\t Epoch Loss  1.3841608762741089\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  97.92670355902777\n",
      "\t Validation accuracy  97.52543131510417\n",
      "\t Epoch Loss  1.3814210891723633\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  97.97383626302083\n",
      "\t Validation accuracy  97.568359375\n",
      "\t Epoch Loss  1.3784830570220947\n",
      "Epoch Number :  55\n",
      "\t Training accuracy:  98.01764594184027\n",
      "\t Validation accuracy  97.62837727864583\n",
      "\t Epoch Loss  1.3757567405700684\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  98.09658474392361\n",
      "\t Validation accuracy  97.71402994791667\n",
      "\t Epoch Loss  1.37192964553833\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  98.14737955729167\n",
      "\t Validation accuracy  97.7947998046875\n",
      "\t Epoch Loss  1.367161512374878\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  98.18766276041667\n",
      "\t Validation accuracy  97.82389322916667\n",
      "\t Epoch Loss  1.361863613128662\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  98.21980794270833\n",
      "\t Validation accuracy  97.7777099609375\n",
      "\t Epoch Loss  1.357249140739441\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  98.251953125\n",
      "\t Validation accuracy  97.78462727864583\n",
      "\t Epoch Loss  1.3532377481460571\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  98.14622667100694\n",
      "\t Validation accuracy  97.6287841796875\n",
      "\t Epoch Loss  1.3494055271148682\n",
      "Epoch Number :  62\n",
      "\t Training accuracy:  98.28375922309027\n",
      "\t Validation accuracy  97.8826904296875\n",
      "\t Epoch Loss  1.3468996286392212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  63\n",
      "\t Training accuracy:  98.27548556857639\n",
      "\t Validation accuracy  97.81534830729167\n",
      "\t Epoch Loss  1.3445155620574951\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  98.17355685763889\n",
      "\t Validation accuracy  97.78177897135417\n",
      "\t Epoch Loss  1.3411431312561035\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  98.20631239149306\n",
      "\t Validation accuracy  97.68208821614583\n",
      "\t Epoch Loss  1.3399049043655396\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  97.95016818576389\n",
      "\t Validation accuracy  97.50203450520833\n",
      "\t Epoch Loss  1.3378103971481323\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  98.38175455729167\n",
      "\t Validation accuracy  97.80924479166667\n",
      "\t Epoch Loss  1.3380146026611328\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  98.32071940104167\n",
      "\t Validation accuracy  97.77669270833333\n",
      "\t Epoch Loss  1.3358142375946045\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  98.06491427951389\n",
      "\t Validation accuracy  97.60945638020833\n",
      "\t Epoch Loss  1.3327170610427856\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  98.37246365017361\n",
      "\t Validation accuracy  97.86844889322917\n",
      "\t Epoch Loss  1.3304181098937988\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  97.81182183159723\n",
      "\t Validation accuracy  97.30550130208333\n",
      "\t Epoch Loss  1.3292787075042725\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  98.24747721354167\n",
      "\t Validation accuracy  97.6751708984375\n",
      "\t Epoch Loss  1.3274083137512207\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  98.07176378038194\n",
      "\t Validation accuracy  97.65238444010417\n",
      "\t Epoch Loss  1.3265721797943115\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  98.20977105034723\n",
      "\t Validation accuracy  97.574462890625\n",
      "\t Epoch Loss  1.323323130607605\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  98.382568359375\n",
      "\t Validation accuracy  97.6220703125\n",
      "\t Epoch Loss  1.3187828063964844\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  98.55150010850694\n",
      "\t Validation accuracy  97.78279622395833\n",
      "\t Epoch Loss  1.3156176805496216\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  98.34499782986111\n",
      "\t Validation accuracy  97.82023111979167\n",
      "\t Epoch Loss  1.3114739656448364\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  98.23581271701389\n",
      "\t Validation accuracy  97.66866048177083\n",
      "\t Epoch Loss  1.3075590133666992\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  98.34486219618056\n",
      "\t Validation accuracy  97.55574544270833\n",
      "\t Epoch Loss  1.3042709827423096\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  98.37687174479167\n",
      "\t Validation accuracy  97.71199544270833\n",
      "\t Epoch Loss  1.30336332321167\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  98.4521484375\n",
      "\t Validation accuracy  97.80293782552083\n",
      "\t Epoch Loss  1.2976622581481934\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  98.17640516493056\n",
      "\t Validation accuracy  97.537841796875\n",
      "\t Epoch Loss  1.2980642318725586\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  98.36880154079861\n",
      "\t Validation accuracy  97.76448567708333\n",
      "\t Epoch Loss  1.2961716651916504\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  98.02890353732639\n",
      "\t Validation accuracy  97.44140625\n",
      "\t Epoch Loss  1.2941287755966187\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  98.45133463541667\n",
      "\t Validation accuracy  97.76896158854167\n",
      "\t Epoch Loss  1.2897406816482544\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  98.45526801215277\n",
      "\t Validation accuracy  97.7459716796875\n",
      "\t Epoch Loss  1.2908940315246582\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  98.37599012586806\n",
      "\t Validation accuracy  97.52421061197917\n",
      "\t Epoch Loss  1.28888738155365\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  98.51637098524306\n",
      "\t Validation accuracy  97.80863444010417\n",
      "\t Epoch Loss  1.2895839214324951\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  98.55082194010417\n",
      "\t Validation accuracy  97.87516276041667\n",
      "\t Epoch Loss  1.2872190475463867\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  98.72463650173611\n",
      "\t Validation accuracy  97.90690104166667\n",
      "\t Epoch Loss  1.286041498184204\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  98.66644965277777\n",
      "\t Validation accuracy  97.85115559895833\n",
      "\t Epoch Loss  1.2857178449630737\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  98.88895670572917\n",
      "\t Validation accuracy  97.850341796875\n",
      "\t Epoch Loss  1.2809345722198486\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  98.68509928385417\n",
      "\t Validation accuracy  97.7667236328125\n",
      "\t Epoch Loss  1.2826895713806152\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  98.80601671006944\n",
      "\t Validation accuracy  97.96244303385417\n",
      "\t Epoch Loss  1.2761012315750122\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  98.25880262586806\n",
      "\t Validation accuracy  97.652587890625\n",
      "\t Epoch Loss  1.2812018394470215\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  98.72300889756944\n",
      "\t Validation accuracy  98.00496419270833\n",
      "\t Epoch Loss  1.2776533365249634\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  98.5491943359375\n",
      "\t Validation accuracy  97.84281412760417\n",
      "\t Epoch Loss  1.2745962142944336\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  98.75678168402777\n",
      "\t Validation accuracy  98.062744140625\n",
      "\t Epoch Loss  1.2678968906402588\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  98.64773220486111\n",
      "\t Validation accuracy  97.84566243489583\n",
      "\t Epoch Loss  1.2714829444885254\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  98.79679361979167\n",
      "\t Validation accuracy  98.05806477864583\n",
      "\t Epoch Loss  1.262669563293457\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  98.65580240885417\n",
      "\t Validation accuracy  97.8179931640625\n",
      "\t Epoch Loss  1.260913610458374\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  98.59931098090277\n",
      "\t Validation accuracy  97.7569580078125\n",
      "\t Epoch Loss  1.2554457187652588\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  98.89872233072917\n",
      "\t Validation accuracy  98.074951171875\n",
      "\t Epoch Loss  1.2540102005004883\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  98.75969780815973\n",
      "\t Validation accuracy  97.8997802734375\n",
      "\t Epoch Loss  1.2585530281066895\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  98.79496256510417\n",
      "\t Validation accuracy  98.0303955078125\n",
      "\t Epoch Loss  1.2475879192352295\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  98.61219618055556\n",
      "\t Validation accuracy  97.86865234375\n",
      "\t Epoch Loss  1.2534732818603516\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  98.97528754340277\n",
      "\t Validation accuracy  98.01839192708333\n",
      "\t Epoch Loss  1.2444169521331787\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  98.85247124565973\n",
      "\t Validation accuracy  97.7581787109375\n",
      "\t Epoch Loss  1.2443324327468872\n",
      "Epoch Number :  109\n",
      "\t Training accuracy:  98.68252224392361\n",
      "\t Validation accuracy  98.0621337890625\n",
      "\t Epoch Loss  1.2475372552871704\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  98.91615125868056\n",
      "\t Validation accuracy  98.20760091145833\n",
      "\t Epoch Loss  1.24124014377594\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  98.51209852430556\n",
      "\t Validation accuracy  97.76957194010417\n",
      "\t Epoch Loss  1.242728590965271\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  98.8214111328125\n",
      "\t Validation accuracy  97.96854654947917\n",
      "\t Epoch Loss  1.240260362625122\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  98.9984130859375\n",
      "\t Validation accuracy  97.96651204427083\n",
      "\t Epoch Loss  1.2380380630493164\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  98.82839626736111\n",
      "\t Validation accuracy  97.88289388020833\n",
      "\t Epoch Loss  1.2397387027740479\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  98.85904947916667\n",
      "\t Validation accuracy  97.90568033854167\n",
      "\t Epoch Loss  1.2349112033843994\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  98.68740505642361\n",
      "\t Validation accuracy  97.952880859375\n",
      "\t Epoch Loss  1.237064003944397\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  98.96959092881944\n",
      "\t Validation accuracy  98.06986490885417\n",
      "\t Epoch Loss  1.2340675592422485\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  98.84379069010417\n",
      "\t Validation accuracy  97.89286295572917\n",
      "\t Epoch Loss  1.2368652820587158\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  99.06419542100694\n",
      "\t Validation accuracy  98.01350911458333\n",
      "\t Epoch Loss  1.230334997177124\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  98.95433213975694\n",
      "\t Validation accuracy  97.99479166666667\n",
      "\t Epoch Loss  1.2340463399887085\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  98.80574544270833\n",
      "\t Validation accuracy  97.89510091145833\n",
      "\t Epoch Loss  1.229345679283142\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  98.86739095052083\n",
      "\t Validation accuracy  97.93599446614583\n",
      "\t Epoch Loss  1.2306625843048096\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  98.88807508680556\n",
      "\t Validation accuracy  98.0645751953125\n",
      "\t Epoch Loss  1.2268016338348389\n",
      "Epoch Number :  124\n",
      "\t Training accuracy:  98.88651529947917\n",
      "\t Validation accuracy  98.15348307291667\n",
      "\t Epoch Loss  1.2236672639846802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  125\n",
      "\t Training accuracy:  98.60493977864583\n",
      "\t Validation accuracy  97.5714111328125\n",
      "\t Epoch Loss  1.2266778945922852\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  99.00187174479167\n",
      "\t Validation accuracy  98.14066569010417\n",
      "\t Epoch Loss  1.2222908735275269\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  99.04805501302083\n",
      "\t Validation accuracy  97.99906412760417\n",
      "\t Epoch Loss  1.2199712991714478\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  98.90557183159723\n",
      "\t Validation accuracy  97.79296875\n",
      "\t Epoch Loss  1.2170556783676147\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  98.62467447916667\n",
      "\t Validation accuracy  97.89164225260417\n",
      "\t Epoch Loss  1.2174785137176514\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  99.07307942708333\n",
      "\t Validation accuracy  98.07169596354167\n",
      "\t Epoch Loss  1.2098807096481323\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  98.9227294921875\n",
      "\t Validation accuracy  97.9241943359375\n",
      "\t Epoch Loss  1.207887053489685\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  98.78431532118056\n",
      "\t Validation accuracy  97.93355305989583\n",
      "\t Epoch Loss  1.205681324005127\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  99.03245713975694\n",
      "\t Validation accuracy  98.14046223958333\n",
      "\t Epoch Loss  1.2061595916748047\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  98.99454752604167\n",
      "\t Validation accuracy  97.972412109375\n",
      "\t Epoch Loss  1.205129861831665\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  98.89166937934027\n",
      "\t Validation accuracy  98.045654296875\n",
      "\t Epoch Loss  1.1997475624084473\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  98.63979763454861\n",
      "\t Validation accuracy  97.691650390625\n",
      "\t Epoch Loss  1.2023152112960815\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  99.05287000868056\n",
      "\t Validation accuracy  97.96915690104167\n",
      "\t Epoch Loss  1.1963822841644287\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  99.00051540798611\n",
      "\t Validation accuracy  98.15327962239583\n",
      "\t Epoch Loss  1.198311448097229\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  99.08942328559027\n",
      "\t Validation accuracy  98.0462646484375\n",
      "\t Epoch Loss  1.19498610496521\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  98.94565158420139\n",
      "\t Validation accuracy  97.97871907552083\n",
      "\t Epoch Loss  1.1913172006607056\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  99.034423828125\n",
      "\t Validation accuracy  98.17891438802083\n",
      "\t Epoch Loss  1.2005733251571655\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  99.07145182291667\n",
      "\t Validation accuracy  98.01513671875\n",
      "\t Epoch Loss  1.190481185913086\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  99.07769097222223\n",
      "\t Validation accuracy  97.98380533854167\n",
      "\t Epoch Loss  1.1895887851715088\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  99.00410970052083\n",
      "\t Validation accuracy  97.92378743489583\n",
      "\t Epoch Loss  1.187294363975525\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  98.78913031684027\n",
      "\t Validation accuracy  97.71586100260417\n",
      "\t Epoch Loss  1.191603183746338\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  98.99359809027777\n",
      "\t Validation accuracy  97.93701171875\n",
      "\t Epoch Loss  1.1932283639907837\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  99.24235026041667\n",
      "\t Validation accuracy  98.08980305989583\n",
      "\t Epoch Loss  1.187882661819458\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  98.90007866753473\n",
      "\t Validation accuracy  97.945556640625\n",
      "\t Epoch Loss  1.1871283054351807\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  98.38460286458333\n",
      "\t Validation accuracy  97.9168701171875\n",
      "\t Epoch Loss  1.1854093074798584\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  99.0863037109375\n",
      "\t Validation accuracy  98.17138671875\n",
      "\t Epoch Loss  1.188897967338562\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  98.77129448784723\n",
      "\t Validation accuracy  97.79866536458333\n",
      "\t Epoch Loss  1.1894266605377197\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  99.08711751302083\n",
      "\t Validation accuracy  98.09285481770833\n",
      "\t Epoch Loss  1.1845269203186035\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  98.99943033854167\n",
      "\t Validation accuracy  98.08756510416667\n",
      "\t Epoch Loss  1.181511402130127\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  99.16592068142361\n",
      "\t Validation accuracy  98.0340576171875\n",
      "\t Epoch Loss  1.184511661529541\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  99.16673448350694\n",
      "\t Validation accuracy  98.12174479166667\n",
      "\t Epoch Loss  1.1791977882385254\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  99.03781467013889\n",
      "\t Validation accuracy  97.94637044270833\n",
      "\t Epoch Loss  1.1822214126586914\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  99.02235243055556\n",
      "\t Validation accuracy  98.03955078125\n",
      "\t Epoch Loss  1.1760694980621338\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  99.08677842881944\n",
      "\t Validation accuracy  98.09183756510417\n",
      "\t Epoch Loss  1.1747334003448486\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  99.14415147569444\n",
      "\t Validation accuracy  98.07027180989583\n",
      "\t Epoch Loss  1.1761298179626465\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  98.50253634982639\n",
      "\t Validation accuracy  97.53580729166667\n",
      "\t Epoch Loss  1.1721292734146118\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  98.94795735677083\n",
      "\t Validation accuracy  98.01717122395833\n",
      "\t Epoch Loss  1.1765937805175781\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  99.09674750434027\n",
      "\t Validation accuracy  98.03243001302083\n",
      "\t Epoch Loss  1.1737008094787598\n",
      "Epoch Number :  163\n",
      "\t Training accuracy:  99.20294867621527\n",
      "\t Validation accuracy  98.10384114583333\n",
      "\t Epoch Loss  1.1661555767059326\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  99.15005154079861\n",
      "\t Validation accuracy  98.04239908854167\n",
      "\t Epoch Loss  1.1637216806411743\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  99.11946614583333\n",
      "\t Validation accuracy  98.10160319010417\n",
      "\t Epoch Loss  1.1630741357803345\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  98.75590006510417\n",
      "\t Validation accuracy  98.104248046875\n",
      "\t Epoch Loss  1.1644989252090454\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  99.03964572482639\n",
      "\t Validation accuracy  98.0975341796875\n",
      "\t Epoch Loss  1.1639039516448975\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  99.24797905815973\n",
      "\t Validation accuracy  98.19315592447917\n",
      "\t Epoch Loss  1.156198501586914\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  99.03618706597223\n",
      "\t Validation accuracy  98.15266927083333\n",
      "\t Epoch Loss  1.156341314315796\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  99.00967068142361\n",
      "\t Validation accuracy  97.96407063802083\n",
      "\t Epoch Loss  1.1551885604858398\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  99.18450249565973\n",
      "\t Validation accuracy  98.01839192708333\n",
      "\t Epoch Loss  1.151784062385559\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  98.97752549913194\n",
      "\t Validation accuracy  97.86051432291667\n",
      "\t Epoch Loss  1.1571022272109985\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  99.14842393663194\n",
      "\t Validation accuracy  97.960205078125\n",
      "\t Epoch Loss  1.1502565145492554\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  99.18741861979167\n",
      "\t Validation accuracy  98.02978515625\n",
      "\t Epoch Loss  1.1494032144546509\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  99.20694986979167\n",
      "\t Validation accuracy  98.1134033203125\n",
      "\t Epoch Loss  1.1456799507141113\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  99.14835611979167\n",
      "\t Validation accuracy  98.12235514322917\n",
      "\t Epoch Loss  1.1473251581192017\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  98.93500434027777\n",
      "\t Validation accuracy  97.98197428385417\n",
      "\t Epoch Loss  1.1478383541107178\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  98.87702094184027\n",
      "\t Validation accuracy  98.1121826171875\n",
      "\t Epoch Loss  1.1448125839233398\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  99.19887966579861\n",
      "\t Validation accuracy  98.101806640625\n",
      "\t Epoch Loss  1.1504387855529785\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  99.19542100694444\n",
      "\t Validation accuracy  98.09224446614583\n",
      "\t Epoch Loss  1.1412721872329712\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  99.14381239149306\n",
      "\t Validation accuracy  98.28145345052083\n",
      "\t Epoch Loss  1.1468985080718994\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  98.96796332465277\n",
      "\t Validation accuracy  97.87068684895833\n",
      "\t Epoch Loss  1.1417992115020752\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  98.80567762586806\n",
      "\t Validation accuracy  97.82002766927083\n",
      "\t Epoch Loss  1.143864631652832\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  98.92381456163194\n",
      "\t Validation accuracy  98.00313313802083\n",
      "\t Epoch Loss  1.148142695426941\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  99.25157335069444\n",
      "\t Validation accuracy  97.98543294270833\n",
      "\t Epoch Loss  1.143094778060913\n",
      "Epoch Number :  186\n",
      "\t Training accuracy:  98.87064615885417\n",
      "\t Validation accuracy  98.20902506510417\n",
      "\t Epoch Loss  1.1386256217956543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  187\n",
      "\t Training accuracy:  99.28378634982639\n",
      "\t Validation accuracy  98.14168294270833\n",
      "\t Epoch Loss  1.14180588722229\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  99.19562445746527\n",
      "\t Validation accuracy  97.93172200520833\n",
      "\t Epoch Loss  1.1401599645614624\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  99.29884168836806\n",
      "\t Validation accuracy  98.24564615885417\n",
      "\t Epoch Loss  1.1362595558166504\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  99.36360677083333\n",
      "\t Validation accuracy  98.0853271484375\n",
      "\t Epoch Loss  1.1367409229278564\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  99.25564236111111\n",
      "\t Validation accuracy  97.96630859375\n",
      "\t Epoch Loss  1.135643482208252\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  99.16802300347223\n",
      "\t Validation accuracy  98.20841471354167\n",
      "\t Epoch Loss  1.135392427444458\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  99.15947808159723\n",
      "\t Validation accuracy  98.14453125\n",
      "\t Epoch Loss  1.1358880996704102\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  98.92232259114583\n",
      "\t Validation accuracy  98.148193359375\n",
      "\t Epoch Loss  1.1365317106246948\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  99.2572021484375\n",
      "\t Validation accuracy  98.10078938802083\n",
      "\t Epoch Loss  1.138197422027588\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  99.25726996527777\n",
      "\t Validation accuracy  97.95552571614583\n",
      "\t Epoch Loss  1.1318824291229248\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  99.44681803385417\n",
      "\t Validation accuracy  98.18603515625\n",
      "\t Epoch Loss  1.1272748708724976\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  99.4329833984375\n",
      "\t Validation accuracy  98.01188151041667\n",
      "\t Epoch Loss  1.126402735710144\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  99.24323187934027\n",
      "\t Validation accuracy  97.98136393229167\n",
      "\t Epoch Loss  1.128549337387085\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  98.86691623263889\n",
      "\t Validation accuracy  97.84261067708333\n",
      "\t Epoch Loss  1.1257903575897217\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  98.91743977864583\n",
      "\t Validation accuracy  98.03243001302083\n",
      "\t Epoch Loss  1.1365437507629395\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  99.33139377170139\n",
      "\t Validation accuracy  98.13028971354167\n",
      "\t Epoch Loss  1.12752103805542\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  99.20430501302083\n",
      "\t Validation accuracy  97.99357096354167\n",
      "\t Epoch Loss  1.1243066787719727\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  99.45041232638889\n",
      "\t Validation accuracy  98.1427001953125\n",
      "\t Epoch Loss  1.123855471611023\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  99.54833984375\n",
      "\t Validation accuracy  98.10933430989583\n",
      "\t Epoch Loss  1.1188544034957886\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  99.24953884548611\n",
      "\t Validation accuracy  98.03263346354167\n",
      "\t Epoch Loss  1.1165482997894287\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  98.97182888454861\n",
      "\t Validation accuracy  98.16569010416667\n",
      "\t Epoch Loss  1.1183310747146606\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  99.20328776041667\n",
      "\t Validation accuracy  98.00435384114583\n",
      "\t Epoch Loss  1.12168550491333\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  99.20383029513889\n",
      "\t Validation accuracy  97.91585286458333\n",
      "\t Epoch Loss  1.117771863937378\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  99.37445746527777\n",
      "\t Validation accuracy  98.15104166666667\n",
      "\t Epoch Loss  1.1138231754302979\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  99.27734375\n",
      "\t Validation accuracy  98.0255126953125\n",
      "\t Epoch Loss  1.1113029718399048\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  98.9410400390625\n",
      "\t Validation accuracy  98.05257161458333\n",
      "\t Epoch Loss  1.1123371124267578\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  99.26947699652777\n",
      "\t Validation accuracy  98.1890869140625\n",
      "\t Epoch Loss  1.1166927814483643\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  99.16971842447917\n",
      "\t Validation accuracy  98.02652994791667\n",
      "\t Epoch Loss  1.110304832458496\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  99.3182373046875\n",
      "\t Validation accuracy  98.01045735677083\n",
      "\t Epoch Loss  1.1059825420379639\n",
      "Epoch Number :  216\n",
      "\t Training accuracy:  99.04242621527777\n",
      "\t Validation accuracy  97.86763509114583\n",
      "\t Epoch Loss  1.11001455783844\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  99.22397189670139\n",
      "\t Validation accuracy  98.01289876302083\n",
      "\t Epoch Loss  1.1068861484527588\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  99.08969455295139\n",
      "\t Validation accuracy  98.16914876302083\n",
      "\t Epoch Loss  1.1075630187988281\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  99.1845703125\n",
      "\t Validation accuracy  98.00089518229167\n",
      "\t Epoch Loss  1.1059672832489014\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  99.22966851128473\n",
      "\t Validation accuracy  98.03385416666667\n",
      "\t Epoch Loss  1.1080737113952637\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  99.34739854600694\n",
      "\t Validation accuracy  98.03609212239583\n",
      "\t Epoch Loss  1.10239839553833\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  99.34170193142361\n",
      "\t Validation accuracy  97.82430013020833\n",
      "\t Epoch Loss  1.1021687984466553\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  99.32895236545139\n",
      "\t Validation accuracy  97.95308430989583\n",
      "\t Epoch Loss  1.099290132522583\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  99.28412543402777\n",
      "\t Validation accuracy  98.04707845052083\n",
      "\t Epoch Loss  1.104285717010498\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  98.97732204861111\n",
      "\t Validation accuracy  97.92582194010417\n",
      "\t Epoch Loss  1.1003122329711914\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  98.858642578125\n",
      "\t Validation accuracy  98.04850260416667\n",
      "\t Epoch Loss  1.1015739440917969\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  99.46241590711806\n",
      "\t Validation accuracy  98.14595540364583\n",
      "\t Epoch Loss  1.098785161972046\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  99.37065972222223\n",
      "\t Validation accuracy  98.13496907552083\n",
      "\t Epoch Loss  1.0939466953277588\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  99.4635009765625\n",
      "\t Validation accuracy  98.11971028645833\n",
      "\t Epoch Loss  1.093395709991455\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  99.35919867621527\n",
      "\t Validation accuracy  97.9217529296875\n",
      "\t Epoch Loss  1.0912399291992188\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  98.88597276475694\n",
      "\t Validation accuracy  97.7178955078125\n",
      "\t Epoch Loss  1.0958858728408813\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  99.05198838975694\n",
      "\t Validation accuracy  98.14676920572917\n",
      "\t Epoch Loss  1.1019248962402344\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  99.44430881076389\n",
      "\t Validation accuracy  98.04423014322917\n",
      "\t Epoch Loss  1.095033049583435\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  99.29490831163194\n",
      "\t Validation accuracy  98.36751302083333\n",
      "\t Epoch Loss  1.0911051034927368\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  99.51117621527777\n",
      "\t Validation accuracy  98.12825520833333\n",
      "\t Epoch Loss  1.0916786193847656\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  99.36258951822917\n",
      "\t Validation accuracy  98.211669921875\n",
      "\t Epoch Loss  1.0891151428222656\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  99.35831705729167\n",
      "\t Validation accuracy  98.00252278645833\n",
      "\t Epoch Loss  1.0932905673980713\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  99.12712944878473\n",
      "\t Validation accuracy  98.0133056640625\n",
      "\t Epoch Loss  1.0915892124176025\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  99.29206000434027\n",
      "\t Validation accuracy  97.98604329427083\n",
      "\t Epoch Loss  1.0921331644058228\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  99.32115342881944\n",
      "\t Validation accuracy  98.05928548177083\n",
      "\t Epoch Loss  1.0930167436599731\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  99.08406575520833\n",
      "\t Validation accuracy  97.52054850260417\n",
      "\t Epoch Loss  1.0892431735992432\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  99.33349609375\n",
      "\t Validation accuracy  97.9010009765625\n",
      "\t Epoch Loss  1.0913019180297852\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  99.38530815972223\n",
      "\t Validation accuracy  98.08492024739583\n",
      "\t Epoch Loss  1.0890473127365112\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  99.30060492621527\n",
      "\t Validation accuracy  97.81840006510417\n",
      "\t Epoch Loss  1.0887755155563354\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  99.20023600260417\n",
      "\t Validation accuracy  98.12947591145833\n",
      "\t Epoch Loss  1.0912846326828003\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  99.19664171006944\n",
      "\t Validation accuracy  98.02510579427083\n",
      "\t Epoch Loss  1.089163064956665\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  99.03822157118056\n",
      "\t Validation accuracy  97.88818359375\n",
      "\t Epoch Loss  1.0897654294967651\n",
      "Epoch Number :  248\n",
      "\t Training accuracy:  99.34258355034723\n",
      "\t Validation accuracy  97.9058837890625\n",
      "\t Epoch Loss  1.0910974740982056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  249\n",
      "\t Training accuracy:  99.51117621527777\n",
      "\t Validation accuracy  97.97342936197917\n",
      "\t Epoch Loss  1.0855135917663574\n",
      "Epoch Number :  250\n",
      "\t Training accuracy:  99.30853949652777\n",
      "\t Validation accuracy  97.94169108072917\n",
      "\t Epoch Loss  1.0825648307800293\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  99.404296875\n",
      "\t Validation accuracy  98.17728678385417\n",
      "\t Epoch Loss  1.0858104228973389\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  99.4244384765625\n",
      "\t Validation accuracy  97.94596354166667\n",
      "\t Epoch Loss  1.0807527303695679\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  99.40504286024306\n",
      "\t Validation accuracy  98.07637532552083\n",
      "\t Epoch Loss  1.0830254554748535\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  99.371337890625\n",
      "\t Validation accuracy  97.97810872395833\n",
      "\t Epoch Loss  1.0806236267089844\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  99.40171983506944\n",
      "\t Validation accuracy  97.9241943359375\n",
      "\t Epoch Loss  1.0795643329620361\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  99.44288465711806\n",
      "\t Validation accuracy  97.98238118489583\n",
      "\t Epoch Loss  1.0810197591781616\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  99.38001844618056\n",
      "\t Validation accuracy  97.89306640625\n",
      "\t Epoch Loss  1.0764431953430176\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  99.28765190972223\n",
      "\t Validation accuracy  98.11258951822917\n",
      "\t Epoch Loss  1.0828949213027954\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  99.38483344184027\n",
      "\t Validation accuracy  97.879638671875\n",
      "\t Epoch Loss  1.0765461921691895\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  99.46729871961806\n",
      "\t Validation accuracy  98.03365071614583\n",
      "\t Epoch Loss  1.0770255327224731\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  99.30677625868056\n",
      "\t Validation accuracy  98.19722493489583\n",
      "\t Epoch Loss  1.0726453065872192\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  99.4000244140625\n",
      "\t Validation accuracy  97.97709147135417\n",
      "\t Epoch Loss  1.077256202697754\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  99.20796712239583\n",
      "\t Validation accuracy  97.78727213541667\n",
      "\t Epoch Loss  1.0736184120178223\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  99.40823025173611\n",
      "\t Validation accuracy  97.98685709635417\n",
      "\t Epoch Loss  1.0715371370315552\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  99.46241590711806\n",
      "\t Validation accuracy  98.05908203125\n",
      "\t Epoch Loss  1.074188470840454\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  99.3756103515625\n",
      "\t Validation accuracy  98.0059814453125\n",
      "\t Epoch Loss  1.0708889961242676\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  99.3585205078125\n",
      "\t Validation accuracy  97.87923177083333\n",
      "\t Epoch Loss  1.0707852840423584\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  98.90129937065973\n",
      "\t Validation accuracy  97.55533854166667\n",
      "\t Epoch Loss  1.0700727701187134\n",
      "Epoch Number :  269\n",
      "\t Training accuracy:  99.22376844618056\n",
      "\t Validation accuracy  97.99173990885417\n",
      "\t Epoch Loss  1.0719075202941895\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  99.42294650607639\n",
      "\t Validation accuracy  97.84932454427083\n",
      "\t Epoch Loss  1.0692654848098755\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  99.36367458767361\n",
      "\t Validation accuracy  97.97505696614583\n",
      "\t Epoch Loss  1.0647664070129395\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  99.40043131510417\n",
      "\t Validation accuracy  97.9766845703125\n",
      "\t Epoch Loss  1.0656670331954956\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  99.45638020833333\n",
      "\t Validation accuracy  98.16080729166667\n",
      "\t Epoch Loss  1.0646172761917114\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  99.44186740451389\n",
      "\t Validation accuracy  98.14982096354167\n",
      "\t Epoch Loss  1.0648906230926514\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  99.10942925347223\n",
      "\t Validation accuracy  97.92826334635417\n",
      "\t Epoch Loss  1.0667989253997803\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  99.21461317274306\n",
      "\t Validation accuracy  97.9498291015625\n",
      "\t Epoch Loss  1.0654078722000122\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  99.437255859375\n",
      "\t Validation accuracy  98.04768880208333\n",
      "\t Epoch Loss  1.0644093751907349\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  99.34733072916667\n",
      "\t Validation accuracy  98.00760904947917\n",
      "\t Epoch Loss  1.0599586963653564\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  99.52867296006944\n",
      "\t Validation accuracy  98.21431477864583\n",
      "\t Epoch Loss  1.0583343505859375\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  99.36815049913194\n",
      "\t Validation accuracy  98.0181884765625\n",
      "\t Epoch Loss  1.0620094537734985\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  99.27544487847223\n",
      "\t Validation accuracy  97.989501953125\n",
      "\t Epoch Loss  1.0575587749481201\n",
      "Epoch Number :  282\n",
      "\t Training accuracy:  99.35234917534723\n",
      "\t Validation accuracy  98.00760904947917\n",
      "\t Epoch Loss  1.0597598552703857\n"
     ]
    }
   ],
   "source": [
    "# Train network \n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target).long()  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True).long() # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    Noutputs = 1\n",
    "    \n",
    "Nbatches = int(math.ceil(Ntrain/batch_size)) #batch_size is defined above\n",
    "Nepochs = 1000\n",
    "Nrep = 1\n",
    "        \n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "#model = conv3DNet(grid_size, Noutputs, batch_size)\n",
    "model = UnetGenerator_3d(in_dim=1, out_dim=Noutputs, num_filter=4)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.90)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "#optimizer = optim.Rprop(model.parameters())\n",
    " \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True) #Reduces the learning rate if it did not decreased by more than 10^-4 in 10 steps\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_ep in range(Nepochs):\n",
    "    for b_start in range(0, Ntrain, batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "        if isinstance(criterion, nn.CrossEntropyLoss) or isinstance(criterion, nn.NLLLoss):\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "        else:\n",
    "            #if delta model is chosen\n",
    "            #batch_loss = criterion(output.view(bsize_eff*Noutputs), train_target.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output.view(bsize_eff,grid_size,grid_size,grid_size), train_target.narrow(0, b_start, bsize_eff))\n",
    "        ep_loss[i_ep] += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step(ep_loss[i_ep])\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target, batch_size, criterion)\n",
    "    nb_validation_errs = compute_nb_errors(model, validation_input, validation_target, batch_size, criterion)\n",
    "\n",
    "    Ntrain_nb = Ntrain*grid_size**3\n",
    "    Nvalidation_nb = Nvalidation*grid_size**3\n",
    "    print(\"Epoch Number : \", i_ep)\n",
    "    print(\"\\t Training accuracy: \", (100*(Ntrain_nb-nb_train_errs)/Ntrain_nb))\n",
    "    print(\"\\t Validation accuracy \",(100*(Nvalidation_nb-nb_validation_errs)/Nvalidation_nb))\n",
    "\n",
    "    print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "\n",
    "    train_errors[i_ep] = nb_train_errs\n",
    "    validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target[44,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[14,1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array(100*(Ntrain_nb-train_errors)/Ntrain_nb)\n",
    "validation_accurcy = np.array(100*(Nvalidation_nb-validation_errors)/Nvalidation_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accurcy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visualisation = output[14,1,:,:,:].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = np.array(test_visualisation.data)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels)\n",
    "fig.savefig('VoxelizedFinal.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def summary(input_size, model):\n",
    "        def register_hook(module):\n",
    "            def hook(module, input, output):\n",
    "                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "                module_idx = len(summary)\n",
    "\n",
    "                m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "                summary[m_key] = OrderedDict()\n",
    "                summary[m_key]['input_shape'] = list(input[0].size())\n",
    "                summary[m_key]['input_shape'][0] = -1\n",
    "                summary[m_key]['output_shape'] = list(output.size())\n",
    "                summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "                params = 0\n",
    "                if hasattr(module, 'weight'):\n",
    "                    params += th.prod(th.LongTensor(list(module.weight.size())))\n",
    "                    if module.weight.requires_grad:\n",
    "                        summary[m_key]['trainable'] = True\n",
    "                    else:\n",
    "                        summary[m_key]['trainable'] = False\n",
    "                if hasattr(module, 'bias'):\n",
    "                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n",
    "                summary[m_key]['nb_params'] = params\n",
    "                \n",
    "            if not isinstance(module, nn.Sequential) and \\\n",
    "               not isinstance(module, nn.ModuleList) and \\\n",
    "               not (module == model):\n",
    "                hooks.append(module.register_forward_hook(hook))\n",
    "                \n",
    "        dtype = th.cuda.FloatTensor\n",
    "        \n",
    "        # check if there are multiple inputs to the network\n",
    "        if isinstance(input_size[0], (list, tuple)):\n",
    "            x = [Variable(th.rand(1,*in_size)).type(dtype) for in_size in input_size]\n",
    "        else:\n",
    "            x = Variable(th.rand(1,*input_size)).type(dtype)\n",
    "            \n",
    "        print(x.shape)\n",
    "        print(type(x[0]))\n",
    "        # create properties\n",
    "        summary = OrderedDict()\n",
    "        hooks = []\n",
    "        # register hook\n",
    "        model.apply(register_hook)\n",
    "        # make a forward pass\n",
    "        model(x)\n",
    "        # remove these hooks\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        print('----------------------------------------------------------------')\n",
    "        line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shpae', 'Param #')\n",
    "        print(line_new)\n",
    "        print('================================================================')\n",
    "        total_params = 0\n",
    "        trainable_params = 0\n",
    "        for layer in summary:\n",
    "            ## input_shape, output_shape, trainable, nb_params\n",
    "            line_new = '{:>20}  {:>25} {:>15}'.format(layer, summary[layer]['output_shape'], summary[layer]['nb_params'])\n",
    "            total_params += summary[layer]['nb_params']\n",
    "            if 'trainable' in summary[layer]:\n",
    "                if summary[layer]['trainable'] == True:\n",
    "                    trainable_params += summary[layer]['nb_params']\n",
    "            print(line_new)\n",
    "        print('================================================================')\n",
    "        print('Total params: ' + str(total_params))\n",
    "        print('Trainable params: ' + str(trainable_params))\n",
    "        print('Non-trainable params: ' + str(total_params - trainable_params))\n",
    "        print('----------------------------------------------------------------')\n",
    "        return summary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
